{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(694, 3175)\n",
      "(169, 3175)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from decimal import Decimal\n",
    "import glob\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.svm \n",
    "import sklearn.metrics\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\n",
    "arch=\"v100\"\n",
    "\n",
    "y_label = []\n",
    "\n",
    "category = \"mybench\"\n",
    "dataName = \"%s/power-combine-feature-%s-%s.csv\"%(arch, category, arch)\n",
    "data0 = pd.read_csv(dataName, index_col=0 )\n",
    "category = \"risky\"\n",
    "dataName = \"%s/power-combine-feature-%s-%s.csv\"%(arch, category, arch)\n",
    "data1 = pd.read_csv(dataName, index_col=0 )\n",
    "\n",
    "for i in range(data0.shape[0]):\n",
    "    y_label.append(0)\n",
    "for i in range(data1.shape[0]):\n",
    "    y_label.append(1)\n",
    "print(data0.shape)\n",
    "print(data1.shape)\n",
    "X = pd.concat([data0, data1])\n",
    "print(\"done\")\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def tfnnClassify(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    #model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "   \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=X_train,y=y_train,\n",
    "            validation_split=0.25,\n",
    "            epochs=50,\n",
    "            batch_size = 256,\n",
    "            class_weight={1:5, 0:1})\n",
    "\n",
    "    loss,train_accuracy =  model.evaluate(x=X_train, y=y_train)\n",
    "    loss,test_accuracy = model.evaluate(x=X_test, y=y_test)\n",
    "    return train_accuracy,  test_accuracy\n",
    "\n",
    "def svmClassify(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "    clf = sklearn.svm.SVC(gamma=0.001, class_weight='balanced', C=1.0, probability=True, random_state=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_train)      \n",
    "    train_accuracy = sklearn.metrics.accuracy_score(y_train, y_pred)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    probas = clf.predict_proba(X_test)    \n",
    "    test_accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    return train_accuracy,  test_accuracy\n",
    "def knnClassify(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "  \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=X_train,y=y_train,\n",
    "            validation_split=0.25,\n",
    "            epochs=50,\n",
    "            batch_size = 256,\n",
    "            class_weight={1:5, 0:1})\n",
    "\n",
    "    loss,train_accuracy =  model.evaluate(x=X_train, y=y_train)\n",
    "    loss,test_accuracy = model.evaluate(x=X_test, y=y_test)\n",
    "    return train_accuracy,  test_accuracy\n",
    "\n",
    "def select_features(X, y, topN):\n",
    "    clf = sklearn.svm.SVC(kernel='linear')    \n",
    "    clf.fit(X, y)\n",
    "    coef_list = clf.coef_[0][:]\n",
    "    coef_list =abs(coef_list)\n",
    "    top_idx = (np.argsort(coef_list)[-topN:]).tolist()\n",
    "    top_idx.reverse()\n",
    "    return top_idx, clf.coef_[0][top_idx]\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(863, 3155)\n",
      "3155\n",
      "-0.034940668196799626\n",
      "Train on 485 samples, validate on 162 samples\n",
      "Epoch 1/50\n",
      "485/485 [==============================] - 0s 636us/sample - loss: 0.7851 - acc: 0.6784 - val_loss: 0.7392 - val_acc: 0.6914\n",
      "Epoch 2/50\n",
      "485/485 [==============================] - 0s 16us/sample - loss: 0.7121 - acc: 0.6948 - val_loss: 0.6897 - val_acc: 0.6852\n",
      "Epoch 3/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.6524 - acc: 0.6928 - val_loss: 0.6488 - val_acc: 0.7160\n",
      "Epoch 4/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.6046 - acc: 0.7237 - val_loss: 0.6150 - val_acc: 0.7160\n",
      "Epoch 5/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.5656 - acc: 0.7402 - val_loss: 0.5866 - val_acc: 0.7346\n",
      "Epoch 6/50\n",
      "485/485 [==============================] - 0s 15us/sample - loss: 0.5346 - acc: 0.7567 - val_loss: 0.5617 - val_acc: 0.7531\n",
      "Epoch 7/50\n",
      "485/485 [==============================] - 0s 15us/sample - loss: 0.5047 - acc: 0.7526 - val_loss: 0.5414 - val_acc: 0.7407\n",
      "Epoch 8/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.4793 - acc: 0.7649 - val_loss: 0.5241 - val_acc: 0.7407\n",
      "Epoch 9/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.4560 - acc: 0.7794 - val_loss: 0.5086 - val_acc: 0.7346\n",
      "Epoch 10/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.4333 - acc: 0.7938 - val_loss: 0.4950 - val_acc: 0.7469\n",
      "Epoch 11/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.4112 - acc: 0.8021 - val_loss: 0.4833 - val_acc: 0.7531\n",
      "Epoch 12/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.3915 - acc: 0.8144 - val_loss: 0.4728 - val_acc: 0.7654\n",
      "Epoch 13/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.3708 - acc: 0.8309 - val_loss: 0.4636 - val_acc: 0.7963\n",
      "Epoch 14/50\n",
      "485/485 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8454 - val_loss: 0.4556 - val_acc: 0.8025\n",
      "Epoch 15/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.3368 - acc: 0.8557 - val_loss: 0.4480 - val_acc: 0.8025\n",
      "Epoch 16/50\n",
      "485/485 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8619 - val_loss: 0.4414 - val_acc: 0.8148\n",
      "Epoch 17/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.3034 - acc: 0.8722 - val_loss: 0.4348 - val_acc: 0.8148\n",
      "Epoch 18/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.2885 - acc: 0.8866 - val_loss: 0.4284 - val_acc: 0.8148\n",
      "Epoch 19/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.2724 - acc: 0.8907 - val_loss: 0.4220 - val_acc: 0.8210\n",
      "Epoch 20/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.2587 - acc: 0.9072 - val_loss: 0.4161 - val_acc: 0.8210\n",
      "Epoch 21/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.2455 - acc: 0.9196 - val_loss: 0.4105 - val_acc: 0.8272\n",
      "Epoch 22/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.2330 - acc: 0.9278 - val_loss: 0.4058 - val_acc: 0.8333\n",
      "Epoch 23/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.2197 - acc: 0.9361 - val_loss: 0.4014 - val_acc: 0.8272\n",
      "Epoch 24/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.2087 - acc: 0.9381 - val_loss: 0.3976 - val_acc: 0.8272\n",
      "Epoch 25/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1978 - acc: 0.9464 - val_loss: 0.3942 - val_acc: 0.8272\n",
      "Epoch 26/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1869 - acc: 0.9526 - val_loss: 0.3915 - val_acc: 0.8272\n",
      "Epoch 27/50\n",
      "485/485 [==============================] - 0s 13us/sample - loss: 0.1776 - acc: 0.9567 - val_loss: 0.3893 - val_acc: 0.8272\n",
      "Epoch 28/50\n",
      "485/485 [==============================] - 0s 13us/sample - loss: 0.1677 - acc: 0.9588 - val_loss: 0.3867 - val_acc: 0.8395\n",
      "Epoch 29/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1583 - acc: 0.9649 - val_loss: 0.3847 - val_acc: 0.8457\n",
      "Epoch 30/50\n",
      "485/485 [==============================] - 0s 15us/sample - loss: 0.1497 - acc: 0.9670 - val_loss: 0.3827 - val_acc: 0.8580\n",
      "Epoch 31/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1417 - acc: 0.9732 - val_loss: 0.3809 - val_acc: 0.8580\n",
      "Epoch 32/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1340 - acc: 0.9753 - val_loss: 0.3796 - val_acc: 0.8519\n",
      "Epoch 33/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1264 - acc: 0.9773 - val_loss: 0.3779 - val_acc: 0.8519\n",
      "Epoch 34/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1199 - acc: 0.9794 - val_loss: 0.3769 - val_acc: 0.8519\n",
      "Epoch 35/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1132 - acc: 0.9835 - val_loss: 0.3762 - val_acc: 0.8580\n",
      "Epoch 36/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1071 - acc: 0.9835 - val_loss: 0.3757 - val_acc: 0.8642\n",
      "Epoch 37/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.1013 - acc: 0.9835 - val_loss: 0.3756 - val_acc: 0.8704\n",
      "Epoch 38/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0959 - acc: 0.9856 - val_loss: 0.3760 - val_acc: 0.8704\n",
      "Epoch 39/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0910 - acc: 0.9856 - val_loss: 0.3766 - val_acc: 0.8704\n",
      "Epoch 40/50\n",
      "485/485 [==============================] - 0s 13us/sample - loss: 0.0858 - acc: 0.9856 - val_loss: 0.3768 - val_acc: 0.8704\n",
      "Epoch 41/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0813 - acc: 0.9856 - val_loss: 0.3771 - val_acc: 0.8765\n",
      "Epoch 42/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0770 - acc: 0.9876 - val_loss: 0.3772 - val_acc: 0.8765\n",
      "Epoch 43/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0726 - acc: 0.9918 - val_loss: 0.3773 - val_acc: 0.8765\n",
      "Epoch 44/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0691 - acc: 0.9918 - val_loss: 0.3776 - val_acc: 0.8765\n",
      "Epoch 45/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0655 - acc: 0.9938 - val_loss: 0.3783 - val_acc: 0.8827\n",
      "Epoch 46/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0623 - acc: 0.9938 - val_loss: 0.3790 - val_acc: 0.8889\n",
      "Epoch 47/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0592 - acc: 0.9938 - val_loss: 0.3794 - val_acc: 0.8889\n",
      "Epoch 48/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0559 - acc: 0.9938 - val_loss: 0.3797 - val_acc: 0.8889\n",
      "Epoch 49/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0533 - acc: 0.9979 - val_loss: 0.3802 - val_acc: 0.8827\n",
      "Epoch 50/50\n",
      "485/485 [==============================] - 0s 14us/sample - loss: 0.0507 - acc: 0.9979 - val_loss: 0.3809 - val_acc: 0.8827\n",
      "647/647 [==============================] - 0s 162us/sample - loss: 0.1096 - acc: 0.9691\n",
      "216/216 [==============================] - 0s 27us/sample - loss: 0.2543 - acc: 0.8935\n",
      "nn 0.9690881 0.8935185\n",
      "Train on 485 samples, validate on 162 samples\n",
      "Epoch 1/50\n",
      "485/485 [==============================] - 0s 540us/sample - loss: 0.7353 - acc: 0.4804 - val_loss: 0.7545 - val_acc: 0.4630\n",
      "Epoch 2/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.7217 - acc: 0.4928 - val_loss: 0.7437 - val_acc: 0.4877\n",
      "Epoch 3/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.7110 - acc: 0.5134 - val_loss: 0.7333 - val_acc: 0.5062\n",
      "Epoch 4/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6982 - acc: 0.5237 - val_loss: 0.7231 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6888 - acc: 0.5361 - val_loss: 0.7132 - val_acc: 0.5247\n",
      "Epoch 6/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6775 - acc: 0.5443 - val_loss: 0.7038 - val_acc: 0.5309\n",
      "Epoch 7/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6668 - acc: 0.5526 - val_loss: 0.6948 - val_acc: 0.5309\n",
      "Epoch 8/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6563 - acc: 0.5526 - val_loss: 0.6861 - val_acc: 0.5309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6466 - acc: 0.5608 - val_loss: 0.6776 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.6392 - acc: 0.5670 - val_loss: 0.6695 - val_acc: 0.5679\n",
      "Epoch 11/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6279 - acc: 0.5814 - val_loss: 0.6616 - val_acc: 0.5617\n",
      "Epoch 12/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6197 - acc: 0.6021 - val_loss: 0.6541 - val_acc: 0.5617\n",
      "Epoch 13/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6114 - acc: 0.6144 - val_loss: 0.6468 - val_acc: 0.5679\n",
      "Epoch 14/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.6028 - acc: 0.6289 - val_loss: 0.6399 - val_acc: 0.5741\n",
      "Epoch 15/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5953 - acc: 0.6289 - val_loss: 0.6333 - val_acc: 0.5864\n",
      "Epoch 16/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5878 - acc: 0.6309 - val_loss: 0.6269 - val_acc: 0.5926\n",
      "Epoch 17/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5806 - acc: 0.6289 - val_loss: 0.6207 - val_acc: 0.5864\n",
      "Epoch 18/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5754 - acc: 0.6330 - val_loss: 0.6149 - val_acc: 0.5926\n",
      "Epoch 19/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5694 - acc: 0.6412 - val_loss: 0.6092 - val_acc: 0.5988\n",
      "Epoch 20/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5618 - acc: 0.6495 - val_loss: 0.6039 - val_acc: 0.6049\n",
      "Epoch 21/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5548 - acc: 0.6557 - val_loss: 0.5988 - val_acc: 0.6173\n",
      "Epoch 22/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5487 - acc: 0.6619 - val_loss: 0.5939 - val_acc: 0.6173\n",
      "Epoch 23/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5423 - acc: 0.6598 - val_loss: 0.5892 - val_acc: 0.6111\n",
      "Epoch 24/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5371 - acc: 0.6598 - val_loss: 0.5847 - val_acc: 0.6111\n",
      "Epoch 25/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5318 - acc: 0.6639 - val_loss: 0.5803 - val_acc: 0.6296\n",
      "Epoch 26/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5267 - acc: 0.6701 - val_loss: 0.5761 - val_acc: 0.6420\n",
      "Epoch 27/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.5221 - acc: 0.6742 - val_loss: 0.5721 - val_acc: 0.6420\n",
      "Epoch 28/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5176 - acc: 0.6784 - val_loss: 0.5682 - val_acc: 0.6481\n",
      "Epoch 29/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5126 - acc: 0.6784 - val_loss: 0.5644 - val_acc: 0.6543\n",
      "Epoch 30/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.5078 - acc: 0.6845 - val_loss: 0.5608 - val_acc: 0.6543\n",
      "Epoch 31/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.5053 - acc: 0.6845 - val_loss: 0.5574 - val_acc: 0.6667\n",
      "Epoch 32/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.4993 - acc: 0.6907 - val_loss: 0.5540 - val_acc: 0.6667\n",
      "Epoch 33/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4956 - acc: 0.6948 - val_loss: 0.5508 - val_acc: 0.6667\n",
      "Epoch 34/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4912 - acc: 0.6948 - val_loss: 0.5476 - val_acc: 0.6728\n",
      "Epoch 35/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4875 - acc: 0.6969 - val_loss: 0.5445 - val_acc: 0.6790\n",
      "Epoch 36/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4839 - acc: 0.6948 - val_loss: 0.5415 - val_acc: 0.6852\n",
      "Epoch 37/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4800 - acc: 0.6969 - val_loss: 0.5387 - val_acc: 0.6852\n",
      "Epoch 38/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4778 - acc: 0.7010 - val_loss: 0.5359 - val_acc: 0.6914\n",
      "Epoch 39/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4737 - acc: 0.7031 - val_loss: 0.5332 - val_acc: 0.6975\n",
      "Epoch 40/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.4709 - acc: 0.7072 - val_loss: 0.5305 - val_acc: 0.7037\n",
      "Epoch 41/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.4665 - acc: 0.7113 - val_loss: 0.5280 - val_acc: 0.7099\n",
      "Epoch 42/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.4634 - acc: 0.7134 - val_loss: 0.5255 - val_acc: 0.7099\n",
      "Epoch 43/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4608 - acc: 0.7155 - val_loss: 0.5230 - val_acc: 0.7222\n",
      "Epoch 44/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4569 - acc: 0.7155 - val_loss: 0.5207 - val_acc: 0.7284\n",
      "Epoch 45/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.4546 - acc: 0.7175 - val_loss: 0.5184 - val_acc: 0.7346\n",
      "Epoch 46/50\n",
      "485/485 [==============================] - 0s 12us/sample - loss: 0.4514 - acc: 0.7258 - val_loss: 0.5162 - val_acc: 0.7346\n",
      "Epoch 47/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4486 - acc: 0.7320 - val_loss: 0.5140 - val_acc: 0.7346\n",
      "Epoch 48/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4459 - acc: 0.7361 - val_loss: 0.5119 - val_acc: 0.7346\n",
      "Epoch 49/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4435 - acc: 0.7381 - val_loss: 0.5098 - val_acc: 0.7407\n",
      "Epoch 50/50\n",
      "485/485 [==============================] - 0s 11us/sample - loss: 0.4408 - acc: 0.7381 - val_loss: 0.5078 - val_acc: 0.7407\n",
      "647/647 [==============================] - 0s 166us/sample - loss: 0.5590 - acc: 0.7388\n",
      "216/216 [==============================] - 0s 24us/sample - loss: 0.5878 - acc: 0.7037\n",
      "knn 0.73879445 0.7037037\n",
      "svm 0.8918083462132921 0.875\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "y = y_label\n",
    "\n",
    "X = X.dropna(axis=1)\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "#for i in range(X.shape[1]):\n",
    "#for i in range(X.shape[1]):\n",
    "#    for j in X.values[:, i]:\n",
    "#        if not np.isfinite(j):\n",
    "#            print(X.columns[i])\n",
    "#            print(j)\n",
    "     \n",
    "print(X.shape)\n",
    "X_std =  StandardScaler().fit_transform(X.values)\n",
    "print(X_std.shape[1])\n",
    "\n",
    "topN = 100\n",
    "top_idx, coef_list = select_features(X_std, y, topN)\n",
    "print(coef_list[topN-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "topN_idx = top_idx[:topN]\n",
    "X_input = X_std[:, topN_idx]\n",
    "train_accuracy, test_accuracy = tfnnClassify(X_input, y)\n",
    "print(\"nn\", train_accuracy, test_accuracy)\n",
    "train_accuracy, test_accuracy = knnClassify(X_input, y)\n",
    "print(\"knn\",train_accuracy, test_accuracy)\n",
    "train_accuracy, test_accuracy = svmClassify(X_input, y)\n",
    "print(\"svm\",train_accuracy, test_accuracy)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5.1.0)",
   "language": "python",
   "name": "anaconda3-5.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
