{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "684\n",
      "169\n",
      "done\n",
      "[0, 440, 413, 0]\n",
      "(853, 1200, 4)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from decimal import Decimal\n",
    "import glob\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.svm \n",
    "import sklearn.metrics\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "counts=[0,0,0,0]\n",
    "def get_app_list(fileName):\n",
    "    \"\"\"get metrics list\n",
    "\n",
    "    Arguments:\n",
    "        fileName {string} -- the file name of application file with absolute path\n",
    "\n",
    "    Returns:\n",
    "        app {list} -- the app  list\n",
    "    \"\"\"\n",
    "    apps = []\n",
    "    with open(fileName) as f:\n",
    "        for line in f.readlines():\n",
    "            if not line.startswith('#'):\n",
    "                words = line.strip().split(',')\n",
    "                app = words[0].strip()\n",
    "                app_num = words[1].strip()\n",
    "                apps.append(app+app_num)\n",
    "        f.close()\n",
    "    return apps\n",
    "\n",
    "def load_mem_file(filepath, max_len):\n",
    "    if not os.path.exists(filepath):\n",
    "        print(filepath)\n",
    "        return \n",
    "    dataframe = pd.read_csv(filepath)\n",
    "    if (dataframe.isnull().values.any()):\n",
    "        print(filepath)\n",
    "    if (dataframe.shape[1] == 6 and dataframe.shape[0] == 0):\n",
    "        print(\"0\", filepath)\n",
    "        counts[0] +=1\n",
    "        return \n",
    "        #os.remove(filepath)\n",
    "        #pass\n",
    "    elif (dataframe.shape[1] == 6 and dataframe.shape[0] <=max_len):\n",
    "        counts[1] +=1\n",
    "        while (dataframe.shape[0] < max_len):\n",
    "            dataframe = pd.concat([dataframe, dataframe])\n",
    "        return dataframe.values[:max_len,:]\n",
    "    elif (dataframe.shape[1] == 6 and dataframe.shape[0] > max_len):\n",
    "        counts[2] +=1\n",
    "        return dataframe.values[:max_len,:]\n",
    "    else:\n",
    "        counts[3] +=1\n",
    "        print(\"1\", filepath)\n",
    "        return \n",
    "\n",
    "def load_resource_file(filepath, max_len):\n",
    "    \n",
    "    dataframe = pd.read_csv(filepath, index_col=0)\n",
    "    if (dataframe.shape[1] == 4 and dataframe.shape[0] >=max_len):\n",
    "        #if dataframe[\"u_gpu\"].sum() == 0:\n",
    "            #os.remove(filepath)\n",
    "        #    print(filepath)\n",
    "        #else:\n",
    "        return dataframe.values[:max_len,:]\n",
    "    else:\n",
    "        print(filepath)\n",
    "def load_group(arch):\n",
    "    y_label = []\n",
    "    data_mem_group = []\n",
    "    data_resource_group = []\n",
    "    \n",
    "    i=0\n",
    "    count = 0\n",
    "    for category in [\"mybench\", \"risky\"]:\n",
    "        mem_pathfolder = '/home/pzou/projects/Power_Signature/results_backup/%s/%s/mem_trace-combine'%(category, arch)\n",
    "        resource_pathfolder = '/home/pzou/projects/Power_Signature/results_backup/%s/%s/power-combine'%(category, arch)\n",
    "        app_list = app_list = get_app_list(\"/home/pzou/projects/Power_Signature/Scripts/applications-mem_%s.csv\"%(category))\n",
    "        for app in app_list:\n",
    "            if arch == \"k40\" and \"reductionMultiBlockCG\" in app:\n",
    "                continue\n",
    "            fileName =app+\".csv\"\n",
    "            data = load_mem_file(os.path.join(mem_pathfolder, fileName), mem_max_len)\n",
    "            data_mem_group.append(data)\n",
    "\n",
    "            fileName =app+\".pwr.csv\"\n",
    "            data = load_resource_file(os.path.join(resource_pathfolder, fileName), res_max_len)\n",
    "            data_resource_group.append(data)\n",
    "\n",
    "            y_label.append(i)\n",
    "            count += 1\n",
    "        i+=1\n",
    "        print(count)\n",
    "        count = 0\n",
    "    data_mem_group = np.asarray(data_mem_group)  \n",
    "    data_resource_group = np.asarray(data_resource_group)  \n",
    "    return data_resource_group,data_mem_group , y_label\n",
    "    \n",
    "res_max_len = 1200\n",
    "mem_max_len = 64\n",
    "arch=\"p100\"\n",
    "\n",
    "print(\"start\")\n",
    "data_resource_group,data_mem_group , y_label = load_group(arch)\n",
    "print(\"done\")\n",
    "print(counts)\n",
    "print(data_resource_group.shape)\n",
    "#%%\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "y_label = pd.Series(y_label)\n",
    "\n",
    "X_res_train, X_res_test, y_train, y_test = train_test_split(data_resource_group, y_label, test_size=0.25, random_state=2)\n",
    "train_index = y_train.index.tolist()\n",
    "test_index = y_test.index.tolist()\n",
    "\n",
    "X_mem_train = data_mem_group[train_index, :, :]\n",
    "X_mem_test = data_mem_group[test_index, :, :]\n",
    "X_train = [X_res_train, X_mem_train]\n",
    "X_test = [X_res_test, X_mem_test]\n",
    "\n",
    "#print(y_test)\n",
    "print(y_label[test_index]==y_test)\n",
    "inputRes = layers.Input(shape=(res_max_len,4))\n",
    "inputMem = layers.Input(shape=(mem_max_len,6))\n",
    "\n",
    "x = (layers.LSTM(256, input_shape=(res_max_len, 4)))(inputRes)\n",
    "x = (layers.Dropout(0.6))(x)\n",
    "x = (layers.Dense(128, activation='relu'))(x)\n",
    "x = (layers.Dense(8, activation='relu'))(x)\n",
    "x= Model(inputs=inputRes, outputs=x)\n",
    "\n",
    "\n",
    "y = (layers.LSTM(mem_max_len, input_shape=(mem_max_len, 6)))(inputMem)\n",
    "y = (layers.Dropout(0.2))(y)\n",
    "y = (layers.Dense(8, activation='relu'))(y)\n",
    "y = Model(inputs=inputMem, outputs=y)\n",
    "\n",
    "\n",
    "combined = layers.concatenate([x.output, y.output])\n",
    "\n",
    "out = layers.Dense(2, activation=\"relu\")(combined)\n",
    "out = layers.Dense(1, activation=\"sigmoid\")(out)\n",
    "\n",
    "    \n",
    "model = Model(inputs=[x.input, y.input], outputs=out)\n",
    "\n",
    "\n",
    "fileM = \"fusion\"\n",
    "checkpoint_path = \"%s/%s-%s.hdf5\"%(arch,fileM ,arch)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                             save_best_only=True,\n",
    "                                             monitor='val_loss', \n",
    "                                             mode='min')\n",
    "model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "hist= model.fit(x=X_train,y=y_train,\n",
    "        epochs=100,\n",
    "        validation_split=0.25,\n",
    "        callbacks = [cp_callback],\n",
    "        batch_size = 256,\n",
    "        class_weight={1:5, 0:1}\n",
    "         )\n",
    "\n",
    "df = pd.DataFrame.from_dict(hist.history)\n",
    "df.to_csv(\"%s/%s-%s-history.csv\"%(arch,fileM ,arch))\n",
    "\n",
    "\n",
    "fileM = \"fusion\"\n",
    "print(\"start\")\n",
    "checkpoint_path = \"%s/%s-%s.hdf5\"%(arch,fileM ,arch)\n",
    "model = tf.keras.models.load_model(checkpoint_path)    \n",
    "#loss, accuracy = model.evaluate(x=X_test, y=y_test)    \n",
    "#with open(\"%s/%s-%s-testAccurcy.txt\"%(arch,fileM ,arch), \"w+\") as f:\n",
    "#    f.write(str(accuracy))\n",
    "#    f.close()\n",
    "\n",
    "y_prob = model.predict([data_resource_group, data_mem_group])\n",
    "\n",
    "y_classes = [int(i>=0.5) for i in y_prob]\n",
    "\n",
    "print(y_classes)\n",
    "#y_predict = [ i[0] for i in y_predict.tolist()]\n",
    "df = pd.DataFrame.from_dict( {\"predict\":y_classes})\n",
    "print(\"done\")\n",
    "df.to_csv(\"%s/fusion-%s-all.csv\"%(arch,arch))\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5.1.0)",
   "language": "python",
   "name": "anaconda3-5.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
