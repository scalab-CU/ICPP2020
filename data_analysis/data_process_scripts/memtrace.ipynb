{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading\n",
      "0kernel /home/pzou/projects/Power_Signature/results_backup/mybench/p100/mem_trace-combine/gesummv5_kernel.csv\n",
      "0kernel /home/pzou/projects/Power_Signature/results_backup/mybench/p100/mem_trace-combine/gesummv7_kernel.csv\n",
      "0kernel /home/pzou/projects/Power_Signature/results_backup/mybench/p100/mem_trace-combine/heartwall2_kernel.csv\n",
      "684\n",
      "853\n",
      "[3, 1130, 573, 0]\n",
      "Done loading\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], [31, 32, 33, 34, 35, 36, 37, 38, 39, 40], [41, 42, 43, 44, 45, 46, 47, 48, 49, 50], [51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], [62, 63, 64, 65, 66, 67, 68, 69, 70, 71], [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82], [83, 84, 85, 86, 87, 88, 89, 90, 91, 92], [93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], [117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], [128, 129, 130, 131, 132, 133, 134, 135, 136, 137], [138, 139, 140], [141, 142, 143, 144], [145, 146, 147, 148, 149, 150, 151, 152, 153], [154, 155, 156, 157, 158, 159, 160, 161, 162, 163], [164, 165, 166, 167, 168, 169, 170, 171, 172, 173], [174, 175], [176, 177, 178, 179, 180, 181, 182, 183, 184, 185], [186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196], [197, 198, 199], [200, 201, 202, 203, 204, 205, 206, 207, 208, 209], [210, 211, 212, 213, 214, 215, 216, 217, 218, 219], [220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241], [242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252], [253, 254, 255, 256, 257, 258, 259, 260, 261, 262], [263, 264, 265, 266, 267, 268, 269, 270, 271, 272], [273, 274, 275, 276, 277, 278, 279, 280, 281, 282], [283, 284, 285, 286, 287, 288, 289, 290, 291, 292], [293, 294, 295, 296, 297, 298, 299, 300], [301, 302, 303, 304], [305, 306, 307, 308, 309, 310, 311, 312, 313], [314, 315, 316, 317], [318, 319, 320, 321, 322, 323, 324, 325, 326], [327, 328, 329, 330, 331, 332, 333, 334, 335], [336, 337, 338, 339, 340, 341, 342, 343, 344, 345], [346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356], [357, 358, 359, 360, 361, 362, 363, 364, 365, 366], [367, 368, 369, 370, 371, 372, 373, 374, 375, 376], [377], [378, 379], [380], [381, 382, 383, 384, 385, 386, 387, 388, 389], [390, 391, 392, 393, 394, 395, 396, 397, 398, 399], [400, 401, 402, 403, 404, 405, 406, 407, 408, 409], [410], [411, 412, 413, 414, 415, 416, 417, 418, 419, 420], [421, 422, 423, 424, 425, 426, 427, 428, 429, 430], [431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442], [443, 444, 445, 446, 447, 448, 449, 450, 451, 452], [453], [454, 455, 456, 457, 458, 459, 460, 461, 462, 463], [464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474], [475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488], [489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500], [501, 502, 503, 504, 505, 506, 507, 508, 509], [510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521], [522], [523, 524, 525, 526, 527, 528, 529, 530, 531, 532], [533, 534, 535, 536, 537, 538, 539, 540, 541, 542], [543, 544], [545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555], [556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567], [568, 569, 570, 571, 572, 573, 574, 575, 576, 577], [578, 579, 580, 581, 582, 583, 584, 585, 586, 587], [588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598], [599, 600, 601, 602], [603, 604], [605, 606, 607, 608, 609, 610, 611, 612, 613, 614], [615], [616, 617], [618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628], [629, 630, 631, 632, 633, 634, 635, 636, 637, 638], [639, 640, 641, 642, 643, 644, 645, 646, 647, 648], [649, 650, 651, 652, 653, 654, 655, 656, 657], [658, 659, 660, 661, 662, 663, 664, 665, 666], [667, 668, 669, 670, 671, 672, 673, 674, 675, 676], [677, 678, 679, 680, 681, 682, 683], [684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703], [704, 705, 706, 707, 708, 709, 710, 711, 712, 713], [714, 715, 716, 717, 718, 719, 720, 721, 722, 723], [724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734], [735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745], [746, 747, 748, 749, 750, 751, 752, 753, 754, 755], [756, 757, 758, 759, 760, 761, 762, 763, 764, 765], [766, 767, 768, 769, 770, 771, 772, 773, 774], [775, 776, 777, 778, 779, 780, 781, 782, 783, 784], [785, 786, 787, 788, 789, 790, 791, 792, 793], [794, 795, 796, 797, 798, 799, 800, 801, 802], [803, 804, 805, 806, 807, 808, 809, 810, 811, 812], [813, 814, 815, 816, 817, 818, 819, 820, 821], [822, 823, 824, 825, 826, 827, 828, 829, 830, 831], [832, 833, 834, 835, 836, 837, 838, 839, 840, 841], [842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852]]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from decimal import Decimal\n",
    "import glob\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.svm \n",
    "import sklearn.metrics\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "\n",
    "counts=[0,0,0,0]\n",
    "def get_app_list(fileName):\n",
    "    \"\"\"get metrics list\n",
    "\n",
    "    Arguments:\n",
    "        fileName {string} -- the file name of application file with absolute path\n",
    "\n",
    "    Returns:\n",
    "        app {list} -- the app  list\n",
    "    \"\"\"\n",
    "    apps = []\n",
    "    with open(fileName) as f:\n",
    "        for line in f.readlines():\n",
    "            if not line.startswith('#'):\n",
    "                words = line.strip().split(',')\n",
    "                app = words[0].strip()\n",
    "                app_num = words[1].strip()\n",
    "                apps.append([app, app_num])\n",
    "        f.close()\n",
    "    return apps\n",
    "\n",
    "\n",
    "def load_kernel_file(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        print(filepath)\n",
    "        return \n",
    "    dataframe = pd.read_csv(filepath)\n",
    "    if (dataframe.isnull().values.any()):\n",
    "        print(\"kernel\", filepath)\n",
    "    if (dataframe.shape[1] == 5 and dataframe.shape[0] == 0):\n",
    "        print(\"0kernel\", filepath)\n",
    "        counts[0] +=1\n",
    "        dataframe.loc[0] = [-1, -1, -1, -1, -1]\n",
    "        while (dataframe.shape[0] < max_len):\n",
    "            dataframe = pd.concat([dataframe, dataframe])\n",
    "        return dataframe.values[:max_len,:]\n",
    "        #os.remove(filepath)\n",
    "        #pass\n",
    "    elif (dataframe.shape[1] == 5 and dataframe.shape[0] <=max_len):\n",
    "        counts[1] +=1\n",
    "        while (dataframe.shape[0] < max_len):\n",
    "            dataframe = pd.concat([dataframe, dataframe])\n",
    "        return dataframe.values[:max_len,:]\n",
    "    elif (dataframe.shape[1] == 5 and dataframe.shape[0] > max_len):\n",
    "        counts[2] +=1\n",
    "        return dataframe.values[:max_len,:]\n",
    "    else:\n",
    "        counts[3] +=1\n",
    "        print(\"1kernel\", filepath)\n",
    "        return \n",
    "\n",
    "def load_transfer_file(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"transfer\", filepath)\n",
    "        return \n",
    "    dataframe = pd.read_csv(filepath)\n",
    "    if (dataframe.isnull().values.any()):\n",
    "        print(filepath)\n",
    "    if (dataframe.shape[1] == 4 and dataframe.shape[0] == 0):\n",
    "        print(\"0transfer\", filepath)\n",
    "        counts[0] +=1\n",
    "        return \n",
    "        #os.remove(filepath)\n",
    "        #pass\n",
    "    elif (dataframe.shape[1] == 4 and dataframe.shape[0] <=max_len):\n",
    "        counts[1] +=1\n",
    "        while (dataframe.shape[0] < max_len):\n",
    "            dataframe = pd.concat([dataframe, dataframe])\n",
    "        return dataframe.values[:max_len,:]\n",
    "    elif (dataframe.shape[1] == 4 and dataframe.shape[0] > max_len):\n",
    "        counts[2] +=1\n",
    "        return dataframe.values[:max_len,:]\n",
    "    else:\n",
    "        counts[3] +=1\n",
    "        print(\"1transfer\", filepath)\n",
    "        return \n",
    "    \n",
    "  \n",
    "def load_group(arch):\n",
    "    y_label = []\n",
    "    \n",
    "    data_kernel_group = []\n",
    "    data_transfer_group = []\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    count = 0\n",
    "    j = 0\n",
    "    prev_app = \"\"\n",
    "    temp_idx = []\n",
    "    for category in [\"mybench\", \"risky\"]:\n",
    "        pathfolder = '/home/pzou/projects/Power_Signature/results_backup/%s/%s/mem_trace-combine'%(category, arch)\n",
    "        app_list = get_app_list(\"/home/pzou/projects/Power_Signature/Scripts/applications-mem_%s.csv\"%(category))\n",
    "        for [app, num] in app_list:\n",
    "            \n",
    "            j += 1\n",
    "            if app == prev_app:\n",
    "                temp_idx.append(j-1)\n",
    "            else:\n",
    "                all_idx.append(temp_idx)\n",
    "                prev_app = app\n",
    "                temp_idx = [j-1]\n",
    "            \n",
    "            \n",
    "            if arch==\"k40\" and \"reductionMultiBlockCG\" in app:\n",
    "                continue\n",
    "            \n",
    "\n",
    "            kernel_fileName = app+num+\"_kernel.csv\"\n",
    "            data = load_kernel_file(os.path.join(pathfolder, kernel_fileName))\n",
    "            data_kernel_group.append(data)\n",
    "    \n",
    "\n",
    "            transfer_fileName = app+num+\"_transfer.csv\"\n",
    "            data = load_transfer_file(os.path.join(pathfolder, transfer_fileName))\n",
    "            data_transfer_group.append(data)\n",
    "\n",
    "            y_label.append(i)\n",
    "            count += 1\n",
    "        i += 1\n",
    "        print(count)\n",
    "    all_idx.append(temp_idx)\n",
    "    data_kernel_group = np.asarray(data_kernel_group)\n",
    "    data_transfer_group = np.asarray(data_transfer_group)\n",
    "    \n",
    "    return data_kernel_group, data_transfer_group, y_label\n",
    "\n",
    "\n",
    "all_idx = []\n",
    "print(\"start loading\")\n",
    "max_len = 64\n",
    "arch=\"p100\"\n",
    "if arch == \"Turing\":\n",
    "    data_group, y_label = load_group_Turing()\n",
    "else:\n",
    "    data_kernel_group, data_transfer_group, y_label = load_group(arch)\n",
    "\n",
    "all_idx = all_idx[1:]\n",
    "print(counts)\n",
    "print(\"Done loading\")\n",
    "print(all_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 68, 37, 84, 6, 92, 26, 40, 85, 69, 71, 21, 25, 33, 29, 56, 14, 94, 52, 70, 3, 43, 11, 95, 45, 82, 64, 86, 49, 74, 55, 19, 63, 38, 79, 2, 31, 81, 51, 72, 36, 4, 0, 58, 5, 93, 1, 90, 41, 9, 18, 88, 47, 65, 75, 77, 44, 89, 87, 53, 15, 76, 7, 80, 30, 27, 62, 8, 73, 16, 61, 78]\n",
      "[42, 57, 48, 32, 67, 22, 10, 20, 17, 28, 35, 34, 54, 24, 39, 60, 50, 83, 12, 66, 91, 46, 23, 13]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "n = len(all_idx)\n",
    "y_train, y_test = train_test_split(range(n), test_size=0.25, random_state=5)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "y_label = pd.Series(y_label)\n",
    "#y_train, y_test = train_test_split(y_label, test_size=0.25, random_state=5)\n",
    "\n",
    "\n",
    "#train_index4 = y_train.index.tolist()\n",
    "#test_index4 = y_test.index.tolist()\n",
    "\n",
    "#print(train_index4)\n",
    "#print(test_index4)\n",
    "\n",
    "model_eval = \"unseen\"\n",
    "\n",
    "if model_eval == \"seen\":\n",
    "    train_index5 = [355, 546, 7, 480, 279, 40, 140, 849, 738, 451, 477, 602, 143, 634, 347, 121, 757, 358, 150, 448, 702, 99, 805, 405, 635, 717, 574, 124, 642, 342, 577, 427, 141, 572, 166, 21, 794, 666, 599, 49, 283, 388, 689, 456, 588, 50, 450, 782, 454, 420, 309, 644, 26, 620, 253, 594, 686, 346, 730, 540, 272, 469, 240, 53, 555, 703, 806, 232, 155, 278, 370, 848, 300, 399, 518, 273, 62, 789, 811, 369, 330, 841, 443, 800, 111, 532, 673, 608, 843, 824, 445, 733, 509, 197, 583, 68, 483, 552, 680, 187, 470, 822, 313, 693, 652, 194, 765, 579, 224, 748, 51, 798, 242, 75, 219, 222, 385, 820, 696, 319, 513, 783, 4, 282, 6, 486, 248, 654, 15, 492, 562, 93, 318, 452, 56, 423, 517, 34, 426, 170, 747, 186, 10, 85, 580, 763, 325, 671, 115, 831, 189, 116, 419, 593, 57, 353, 438, 392, 481, 833, 259, 502, 336, 503, 125, 458, 357, 366, 46, 256, 106, 317, 821, 327, 617, 622, 576, 504, 780, 681, 741, 47, 157, 571, 468, 441, 234, 515, 668, 734, 626, 382, 218, 679, 674, 195, 90, 162, 246, 417, 54, 570, 636, 611, 16, 648, 464, 156, 505, 43, 510, 568, 591, 607, 512, 297, 305, 557, 612, 723, 573, 145, 790, 198, 812, 688, 495, 289, 650, 315, 514, 559, 98, 226, 801, 338, 381, 662, 303, 457, 772, 709, 277, 249, 321, 139, 746, 323, 436, 442, 127, 754, 554, 592, 533, 792, 762, 526, 846, 658, 361, 201, 541, 776, 556, 462, 537, 188, 409, 683, 732, 704, 128, 767, 122, 9, 604, 164, 292, 804, 851, 837, 101, 586, 351, 373, 59, 561, 48, 764, 721, 109, 810, 742, 133, 239, 422, 793, 76, 223, 544, 460, 311, 18, 191, 413, 663, 653, 280, 499, 328, 0, 563, 339, 182, 493, 839, 96, 55, 350, 39, 522, 761, 698, 304, 215, 298, 371, 538, 639, 237, 376, 88, 601, 529, 816, 268, 38, 152, 79, 429, 241, 781, 345, 174, 724, 506, 630, 24, 161, 119, 58, 262, 168, 81, 581, 813, 221, 756, 664, 647, 661, 83, 92, 301, 19, 558, 185, 227, 209, 333, 527, 231, 508, 428, 314, 836, 551, 238, 137, 25, 711, 753, 340, 61, 307, 158, 523, 471, 17, 67, 823, 627, 112, 705, 516, 785, 102, 415, 631, 487, 473, 619, 718, 291, 263, 251, 605, 678, 714, 1, 549, 375, 795, 643, 367, 402, 687, 2, 95, 535, 496, 778, 755, 284, 211, 410, 173, 287, 646, 142, 412, 192, 838, 401, 229, 712, 217, 597, 154, 430, 403, 181, 335, 751, 74, 414, 435, 852, 625, 640, 233, 20, 728, 750, 609, 589, 30, 290, 252, 69, 87, 114, 548, 91, 465, 167, 407, 616, 320, 784, 585, 77, 566, 531, 598, 690, 257, 255, 797, 497, 130, 100, 171, 796, 773, 453, 814, 655, 739, 200, 202, 660, 455, 633, 136, 520, 659, 569, 378, 706, 270, 606, 63, 393, 70, 534, 271, 543, 160, 845, 169, 36, 243, 82, 260, 372, 22, 337, 308, 826, 507, 220, 13, 819, 672, 584, 511, 177, 276, 547, 719, 476, 225, 632, 216, 29, 700, 722, 180, 745, 459, 766, 677, 638, 834, 474, 264, 64, 787, 214, 802, 786, 175, 398, 172, 332, 32, 31, 744, 235, 374, 397, 408, 699, 685, 418, 389, 817, 550, 265, 14, 94, 528, 391, 729, 78, 603, 387, 183, 449, 380, 491, 779, 190, 842, 621, 364, 135, 245, 274, 147, 105, 294, 324, 770, 799, 539, 691, 676, 110, 768, 5, 144, 103, 210, 446, 41, 362, 649, 377, 254, 146, 637, 86, 542, 431, 65, 715, 205, 44, 27, 80, 437, 113, 204, 519, 720, 670, 624, 411, 743, 740, 8, 73, 400, 118, 701, 206]\n",
    "    test_index5 = [176, 444, 159, 299, 657, 463, 11, 352, 803, 844, 281, 384, 725, 489, 286, 213, 275, 827, 466, 316, 614, 500, 344, 258, 360, 193, 179, 682, 288, 692, 615, 28, 383, 461, 656, 363, 760, 567, 667, 396, 295, 395, 467, 472, 208, 302, 331, 695, 368, 808, 329, 354, 60, 769, 434, 613, 830, 587, 126, 12, 117, 736, 203, 840, 425, 341, 553, 322, 829, 365, 433, 488, 178, 138, 832, 228, 545, 394, 707, 148, 390, 536, 72, 71, 498, 269, 645, 348, 349, 809, 758, 479, 37, 791, 716, 23, 165, 84, 343, 818, 525, 684, 482, 582, 737, 835, 485, 236, 432, 247, 306, 669, 727, 475, 610, 296, 575, 752, 212, 775, 815, 759, 379, 406, 665, 807, 777, 261, 628, 675, 196, 641, 697, 440, 735, 771, 749, 828, 524, 521, 207, 774, 250, 310, 623, 424, 590, 494, 42, 151, 123, 850, 501, 134, 564, 52, 104, 3, 285, 708, 386, 199, 129, 312, 726, 490, 731, 359, 595, 266, 439, 847, 484, 108, 33, 132, 825, 651, 244, 66, 149, 131, 618, 713, 447, 694, 596, 629, 97, 560, 710, 184, 416, 788, 267, 153, 163, 404, 45, 478, 578, 120, 293, 89, 530, 107, 421, 600, 230, 326, 356, 35, 565, 334]\n",
    "\n",
    "    train_index4 = [492, 473, 395, 444, 733, 328, 575, 273, 55, 702, 310, 747, 623, 402, 644, 163, 336, 379, 628, 465, 193, 526, 570, 133, 70, 340, 507, 785, 374, 350, 827, 213, 287, 404, 433, 31, 406, 167, 652, 459, 690, 364, 748, 437, 203, 347, 707, 745, 731, 135, 845, 714, 632, 300, 380, 622, 836, 476, 429, 489, 558, 290, 212, 8, 295, 108, 734, 571, 176, 524, 815, 248, 45, 159, 266, 651, 80, 738, 730, 268, 523, 666, 635, 267, 97, 408, 710, 249, 18, 840, 490, 166, 25, 475, 71, 275, 789, 568, 629, 169, 75, 756, 696, 305, 342, 787, 430, 546, 357, 68, 557, 276, 594, 175, 216, 337, 812, 701, 806, 725, 177, 202, 718, 3, 263, 431, 455, 446, 261, 251, 511, 482, 226, 24, 461, 432, 700, 200, 539, 15, 257, 14, 333, 229, 378, 663, 834, 376, 768, 517, 793, 99, 567, 797, 687, 646, 316, 792, 271, 57, 822, 604, 144, 802, 679, 158, 117, 399, 317, 88, 452, 753, 658, 382, 274, 6, 758, 4, 319, 40, 237, 210, 852, 211, 778, 715, 550, 464, 809, 303, 64, 595, 363, 311, 617, 265, 657, 98, 821, 673, 503, 338, 625, 277, 389, 103, 196, 576, 441, 752, 334, 162, 584, 583, 559, 231, 841, 134, 813, 341, 219, 814, 188, 192, 142, 410, 298, 472, 301, 692, 398, 614, 521, 128, 160, 356, 123, 805, 168, 847, 100, 496, 102, 105, 615, 654, 794, 235, 681, 683, 365, 795, 616, 803, 16, 682, 46, 512, 780, 344, 129, 269, 101, 440, 695, 348, 94, 468, 762, 742, 353, 293, 115, 1, 195, 613, 61, 332, 242, 582, 79, 35, 631, 43, 85, 289, 20, 574, 458, 205, 772, 206, 280, 538, 91, 425, 292, 93, 150, 674, 82, 87, 141, 256, 798, 339, 600, 39, 545, 766, 84, 230, 608, 826, 618, 314, 392, 451, 483, 172, 197, 722, 689, 449, 361, 201, 140, 312, 48, 368, 735, 96, 596, 241, 28, 232, 442, 751, 60, 12, 705, 829, 21, 779, 173, 38, 671, 469, 272, 349, 619, 69, 642, 245, 677, 329, 386, 817, 302, 703, 737, 130, 506, 346, 186, 355, 724, 438, 716, 137, 528, 323, 634, 453, 741, 415, 712, 204, 529, 849, 327, 532, 367, 400, 838, 41, 351, 199, 685, 721, 581, 223, 480, 837, 514, 369, 611, 182, 542, 185, 531, 132, 549, 234, 485, 672, 19, 407, 820, 560, 607, 403, 777, 450, 744, 116, 148, 556, 755, 246, 217, 111, 669, 37, 366, 118, 233, 759, 23, 258, 309, 602, 540, 377, 418, 547, 799, 207, 143, 81, 569, 773, 121, 454, 494, 26, 500, 396, 727, 516, 589, 774, 647, 318, 435, 218, 335, 732, 296, 667, 675, 791, 284, 22, 227, 2, 445, 548, 29, 498, 457, 5, 704, 281, 32, 421, 717, 627, 156, 833, 519, 790, 801, 586, 259, 297, 655, 502, 470, 553, 761, 10, 691, 7, 208, 660, 375, 598, 414, 291, 49, 686, 609, 448, 52, 308, 315, 488, 591, 391, 808, 501, 119, 848, 394, 831, 653, 527, 639, 86, 171, 27, 510, 662, 693, 491, 579, 736, 252, 552, 757, 131, 699, 626, 708, 565, 125, 9, 78, 543, 484, 767, 587, 54, 388, 670, 352, 487, 566, 250, 443, 165, 505, 264, 51, 107, 59, 478, 597, 796, 499, 181, 850, 466, 711, 749, 743, 198, 839, 279, 331, 786, 190, 534, 222, 114, 151, 460, 688, 187, 73, 729, 240, 145, 562, 255, 95, 610, 719, 371, 370, 515, 412, 493, 638, 800, 161, 426, 243, 680, 416, 343, 322, 561, 648, 30, 373, 851, 706, 56, 486, 509, 422, 713, 149, 533, 183, 0, 387, 564, 126, 294, 44, 676, 313, 823, 606, 109, 764, 58, 393, 818, 456, 599, 360, 709, 439, 174, 122]\n",
    "    test_index4 = [810, 698, 63, 720, 782, 411, 723, 214, 573, 520, 694, 138, 383, 157, 643, 401, 66, 788, 697, 471, 770, 215, 771, 72, 320, 155, 238, 236, 359, 508, 253, 846, 358, 307, 286, 544, 504, 77, 191, 170, 405, 637, 152, 67, 577, 282, 825, 147, 605, 124, 110, 154, 551, 620, 593, 678, 636, 630, 541, 304, 649, 665, 247, 270, 424, 178, 354, 153, 481, 164, 819, 220, 306, 447, 228, 345, 321, 74, 843, 769, 104, 572, 225, 811, 146, 11, 397, 324, 640, 739, 385, 650, 824, 807, 419, 262, 92, 578, 844, 804, 36, 835, 260, 288, 784, 224, 832, 112, 409, 603, 728, 830, 283, 62, 513, 726, 209, 127, 590, 423, 13, 194, 776, 47, 65, 76, 477, 518, 645, 842, 536, 781, 34, 763, 362, 525, 17, 588, 816, 33, 592, 522, 239, 89, 580, 775, 740, 179, 326, 828, 42, 612, 299, 381, 497, 563, 656, 436, 120, 661, 106, 113, 221, 136, 537, 413, 330, 180, 641, 783, 384, 664, 479, 754, 90, 390, 684, 428, 535, 467, 633, 760, 474, 244, 53, 659, 554, 463, 555, 746, 189, 254, 50, 750, 434, 285, 83, 462, 372, 668, 495, 278, 427, 765, 420, 601, 585, 621, 624, 139, 417, 325, 184, 530]\n",
    "\n",
    "    train_index3 = [487, 206, 843, 782, 115, 303, 535, 825, 19, 304, 107, 347, 530, 105, 842, 99, 317, 742, 459, 522, 723, 229, 109, 381, 702, 437, 713, 397, 610, 578, 238, 446, 314, 30, 691, 762, 682, 534, 233, 279, 606, 653, 729, 116, 68, 290, 556, 443, 567, 37, 594, 270, 106, 569, 251, 558, 354, 840, 215, 492, 717, 499, 169, 453, 53, 780, 743, 635, 151, 230, 661, 445, 593, 735, 188, 725, 669, 185, 43, 142, 552, 675, 621, 359, 806, 150, 67, 319, 427, 464, 697, 689, 350, 764, 432, 563, 706, 505, 131, 665, 296, 283, 711, 620, 130, 431, 322, 114, 477, 456, 428, 698, 271, 313, 512, 284, 129, 740, 389, 573, 210, 465, 523, 395, 424, 40, 306, 813, 204, 272, 8, 815, 70, 638, 790, 7, 710, 362, 709, 93, 491, 382, 79, 726, 342, 49, 250, 147, 814, 57, 442, 449, 407, 55, 440, 801, 450, 837, 472, 338, 419, 595, 25, 47, 174, 772, 59, 153, 518, 792, 161, 244, 707, 158, 411, 326, 832, 501, 498, 409, 639, 179, 651, 439, 736, 54, 654, 783, 168, 546, 615, 822, 417, 24, 298, 701, 671, 18, 667, 312, 254, 225, 87, 469, 528, 630, 222, 807, 570, 218, 680, 623, 490, 820, 529, 193, 831, 286, 66, 796, 71, 429, 412, 82, 775, 768, 703, 15, 781, 626, 514, 466, 406, 255, 584, 135, 683, 416, 29, 181, 227, 404, 364, 794, 104, 321, 268, 475, 828, 392, 542, 808, 241, 430, 574, 585, 203, 452, 757, 83, 118, 96, 467, 521, 166, 548, 189, 770, 705, 92, 366, 315, 261, 361, 138, 752, 276, 384, 56, 802, 829, 410, 88, 741, 582, 280, 756, 370, 139, 360, 460, 533, 287, 746, 539, 649, 202, 402, 340, 365, 23, 345, 800, 334, 310, 774, 353, 818, 240, 318, 633, 262, 98, 637, 769, 773, 89, 515, 331, 587, 433, 787, 624, 486, 550, 716, 850, 260, 305, 196, 140, 122, 494, 110, 84, 575, 513, 482, 589, 74, 821, 629, 273, 396, 154, 191, 788, 187, 50, 38, 418, 777, 208, 375, 463, 470, 517, 75, 248, 559, 302, 636, 817, 11, 485, 462, 835, 281, 253, 841, 617, 786, 577, 219, 425, 369, 687, 69, 580, 21, 77, 547, 849, 812, 125, 228, 42, 516, 572, 576, 798, 374, 205, 830, 6, 493, 809, 634, 259, 282, 590, 760, 833, 455, 320, 434, 299, 436, 696, 438, 325, 403, 265, 564, 602, 699, 278, 652, 553, 645, 799, 231, 245, 167, 502, 332, 426, 541, 162, 149, 226, 94, 221, 597, 473, 836, 601, 751, 34, 217, 72, 220, 213, 739, 394, 827, 367, 12, 753, 343, 198, 234, 420, 712, 608, 673, 297, 63, 607, 13, 435, 17, 708, 348, 207, 90, 307, 341, 380, 344, 471, 759, 551, 598, 32, 803, 657, 670, 172, 730, 791, 408, 846, 778, 200, 292, 583, 745, 510, 785, 724, 758, 834, 824, 489, 755, 750, 133, 60, 690, 26, 100, 531, 588, 852, 520, 363, 309, 604, 252, 544, 481, 441, 647, 476, 22, 62, 148, 483, 727, 776, 257, 52, 242, 173, 35, 178, 679, 738, 120, 275, 44, 300, 76, 720, 368, 212, 267, 311, 728, 444, 503, 495, 33, 9, 688, 160, 285, 295, 616, 625, 277, 779, 603, 484, 496, 182, 816, 684, 744, 36, 156, 2, 754, 508, 497, 308, 289, 560, 414, 421, 141, 223, 183, 804, 672, 511, 731, 611, 747, 117, 1, 113, 819, 686, 765, 165, 184, 677, 372, 274, 704, 0, 566, 540, 500, 718, 383, 405, 561, 20, 805, 176, 335, 379, 545, 171, 519, 507, 152, 618, 413, 609, 622, 581, 641, 316, 258, 662, 474, 337, 538, 504, 398, 423, 605, 660, 480, 422, 119, 650, 681, 714, 659, 789, 256, 643, 249, 664]\n",
    "    test_index3 = [175, 851, 85, 674, 693, 91, 237, 86, 126, 666, 164, 247, 108, 10, 339, 536, 627, 386, 732, 844, 61, 448, 524, 591, 797, 692, 748, 685, 810, 640, 177, 28, 401, 562, 293, 571, 143, 48, 27, 246, 144, 121, 451, 838, 352, 695, 192, 506, 771, 461, 51, 65, 263, 378, 527, 216, 400, 694, 199, 376, 826, 614, 157, 385, 848, 333, 235, 568, 351, 145, 619, 648, 371, 722, 458, 349, 592, 80, 58, 599, 41, 766, 845, 468, 195, 45, 81, 103, 358, 613, 124, 586, 543, 288, 642, 291, 269, 214, 355, 391, 655, 763, 600, 847, 101, 330, 646, 373, 554, 737, 163, 612, 180, 324, 236, 73, 336, 415, 137, 700, 78, 155, 532, 579, 328, 102, 346, 46, 4, 123, 266, 839, 194, 390, 631, 793, 197, 357, 232, 111, 201, 16, 134, 327, 509, 676, 146, 387, 377, 663, 239, 658, 795, 632, 454, 393, 596, 128, 557, 767, 399, 668, 356, 525, 537, 734, 447, 39, 555, 31, 761, 209, 784, 644, 526, 112, 190, 132, 95, 224, 549, 823, 479, 3, 388, 733, 329, 5, 721, 656, 243, 628, 211, 159, 488, 97, 719, 264, 323, 749, 565, 294, 186, 127, 715, 457, 301, 64, 14, 678, 170, 811, 136, 478]\n",
    "\n",
    "    train_index2 = [335, 706, 646, 791, 315, 108, 696, 802, 181, 230, 257, 804, 160, 371, 84, 747, 90, 513, 640, 309, 665, 393, 42, 776, 356, 552, 563, 157, 746, 321, 273, 656, 407, 387, 258, 111, 382, 453, 750, 452, 280, 694, 643, 291, 55, 669, 439, 340, 40, 838, 575, 286, 705, 178, 176, 691, 58, 338, 16, 310, 596, 763, 787, 473, 398, 384, 813, 542, 800, 29, 811, 295, 703, 826, 824, 203, 32, 377, 370, 156, 524, 397, 520, 751, 305, 3, 616, 130, 533, 712, 419, 591, 412, 376, 113, 48, 289, 594, 206, 330, 285, 634, 225, 518, 120, 402, 615, 221, 427, 171, 511, 653, 849, 423, 355, 704, 123, 333, 180, 161, 600, 784, 117, 818, 480, 573, 391, 737, 240, 134, 155, 139, 690, 60, 512, 165, 300, 443, 394, 297, 131, 314, 774, 627, 621, 464, 38, 249, 53, 194, 136, 378, 572, 281, 35, 521, 851, 476, 66, 470, 440, 623, 52, 608, 515, 815, 239, 246, 503, 28, 701, 265, 244, 103, 276, 110, 807, 159, 235, 597, 112, 463, 735, 532, 514, 329, 262, 223, 843, 728, 639, 535, 557, 167, 417, 241, 685, 475, 830, 24, 294, 731, 636, 715, 150, 41, 346, 94, 451, 217, 652, 381, 23, 268, 388, 352, 416, 292, 200, 173, 100, 489, 91, 642, 795, 709, 541, 502, 222, 214, 188, 354, 465, 822, 638, 353, 76, 242, 852, 73, 837, 556, 820, 425, 347, 118, 748, 114, 579, 581, 5, 667, 496, 505, 69, 14, 844, 526, 369, 78, 202, 154, 632, 553, 4, 571, 771, 54, 467, 266, 738, 293, 71, 559, 2, 25, 308, 216, 343, 740, 644, 166, 589, 839, 331, 177, 375, 437, 247, 373, 778, 472, 499, 543, 519, 832, 617, 658, 688, 307, 501, 234, 612, 430, 536, 191, 151, 435, 256, 654, 568, 662, 383, 145, 687, 752, 215, 719, 765, 567, 196, 718, 495, 17, 660, 27, 277, 395, 228, 320, 147, 806, 494, 449, 756, 106, 350, 523, 389, 448, 93, 259, 554, 754, 170, 254, 252, 306, 547, 829, 809, 428, 186, 269, 162, 413, 659, 672, 98, 6, 684, 726, 229, 264, 368, 593, 733, 744, 761, 403, 620, 189, 332, 303, 260, 144, 283, 727, 11, 695, 531, 469, 127, 624, 57, 33, 237, 782, 282, 586, 362, 243, 603, 92, 210, 337, 301, 85, 190, 39, 500, 507, 516, 104, 732, 233, 105, 341, 253, 408, 422, 208, 833, 739, 82, 497, 780, 583, 664, 87, 64, 270, 605, 274, 675, 770, 153, 613, 666, 410, 517, 44, 625, 390, 220, 140, 349, 357, 133, 261, 278, 79, 828, 115, 786, 713, 380, 792, 184, 673, 358, 36, 339, 753, 420, 149, 9, 45, 95, 767, 848, 548, 560, 298, 290, 415, 313, 421, 657, 122, 717, 698, 361, 336, 135, 724, 651, 367, 817, 769, 619, 8, 97, 825, 348, 509, 812, 21, 482, 821, 405, 840, 722, 478, 590, 491, 46, 364, 296, 49, 487, 224, 219, 801, 841, 647, 201, 562, 622, 845, 63, 604, 245, 442, 743, 574, 0, 539, 689, 187, 406, 148, 26, 461, 670, 655, 59, 714, 326, 424, 720, 477, 43, 661, 635, 528, 736, 483, 218, 741, 847, 783, 609, 485, 125, 768, 61, 81, 680, 324, 385, 846, 56, 19, 814, 86, 758, 649, 316, 34, 138, 766, 588, 498, 538, 555, 96, 83, 446, 474, 764, 366, 697, 585, 796, 760, 401, 759, 392, 797, 745, 271, 506, 850, 434, 648, 561, 207, 319, 834, 132, 50, 238, 564, 592, 450, 31, 121, 211, 351, 454, 302, 708, 88, 325, 323, 255, 570, 545, 550, 359, 51, 772, 102, 195, 679, 805, 628, 124, 404, 730, 287, 831, 47, 725, 587, 607, 433, 674, 263, 360, 75, 466, 299, 534, 584, 493, 527, 168]\n",
    "    test_index2 = [650, 602, 250, 457, 447, 599, 549, 400, 248, 15, 618, 418, 479, 671, 631, 67, 37, 525, 819, 460, 372, 158, 65, 68, 799, 504, 128, 577, 484, 174, 444, 99, 192, 779, 205, 396, 197, 101, 777, 723, 379, 365, 510, 537, 342, 798, 345, 141, 582, 317, 546, 164, 558, 172, 227, 630, 183, 213, 456, 70, 363, 20, 175, 835, 808, 566, 595, 142, 374, 793, 700, 74, 432, 755, 288, 551, 414, 459, 318, 137, 334, 681, 678, 775, 762, 803, 7, 182, 606, 304, 199, 827, 445, 481, 226, 193, 742, 279, 468, 455, 327, 251, 411, 143, 312, 152, 522, 471, 789, 109, 816, 810, 438, 565, 710, 544, 179, 576, 540, 436, 284, 344, 429, 645, 823, 682, 614, 62, 18, 462, 530, 169, 633, 146, 22, 399, 490, 386, 668, 431, 729, 458, 107, 716, 629, 611, 601, 580, 89, 80, 794, 699, 212, 30, 10, 721, 693, 204, 409, 785, 77, 626, 1, 492, 198, 209, 711, 707, 578, 116, 232, 426, 322, 185, 311, 486, 637, 781, 119, 788, 663, 757, 13, 773, 231, 676, 441, 328, 749, 569, 129, 790, 842, 126, 529, 163, 686, 692, 598, 267, 275, 610, 641, 836, 677, 702, 72, 488, 272, 734, 236, 683, 12, 508]\n",
    "\n",
    "\n",
    "    train_index1 = [783, 421, 598, 684, 501, 238, 681, 159, 428, 161, 518, 638, 399, 801, 525, 307, 13, 549, 679, 404, 430, 755, 92, 125, 114, 746, 415, 341, 76, 839, 819, 814, 189, 386, 132, 787, 837, 479, 349, 246, 255, 631, 40, 89, 429, 793, 68, 262, 139, 329, 118, 657, 789, 375, 445, 796, 453, 14, 82, 594, 529, 88, 273, 172, 434, 103, 639, 311, 45, 314, 541, 748, 613, 11, 214, 696, 147, 614, 700, 361, 676, 697, 578, 173, 305, 226, 31, 437, 803, 624, 285, 388, 781, 116, 841, 95, 363, 455, 345, 825, 459, 448, 62, 204, 761, 184, 91, 806, 426, 692, 29, 54, 674, 371, 576, 146, 221, 584, 766, 617, 449, 350, 165, 745, 80, 506, 310, 259, 323, 9, 579, 436, 671, 179, 27, 411, 720, 293, 443, 5, 197, 672, 670, 540, 261, 546, 122, 538, 38, 358, 733, 334, 666, 368, 162, 67, 124, 39, 4, 33, 403, 673, 335, 280, 592, 99, 622, 644, 236, 750, 528, 521, 464, 433, 641, 775, 537, 392, 352, 563, 507, 12, 186, 577, 844, 774, 374, 260, 484, 333, 153, 396, 587, 304, 200, 394, 815, 373, 800, 78, 312, 773, 794, 42, 446, 133, 516, 389, 573, 742, 555, 250, 601, 723, 527, 192, 220, 582, 636, 432, 603, 640, 30, 494, 581, 395, 157, 610, 272, 821, 512, 306, 747, 651, 102, 52, 156, 510, 402, 817, 97, 543, 128, 378, 177, 347, 110, 637, 379, 191, 419, 698, 343, 727, 142, 687, 6, 829, 267, 662, 237, 567, 531, 400, 383, 58, 689, 232, 784, 702, 442, 203, 602, 284, 98, 2, 836, 522, 487, 217, 360, 46, 820, 422, 225, 18, 168, 228, 292, 377, 517, 397, 227, 716, 643, 328, 283, 795, 658, 535, 93, 213, 337, 425, 682, 115, 158, 846, 112, 36, 105, 362, 365, 441, 351, 833, 249, 726, 677, 406, 729, 164, 843, 691, 708, 83, 649, 295, 70, 574, 790, 737, 553, 127, 717, 1, 558, 539, 308, 410, 171, 417, 680, 460, 739, 423, 315, 376, 524, 740, 438, 625, 150, 852, 556, 686, 409, 143, 526, 734, 705, 208, 440, 131, 380, 174, 533, 270, 407, 605, 123, 138, 51, 275, 826, 342, 256, 182, 300, 770, 240, 230, 326, 458, 465, 163, 167, 145, 206, 500, 188, 324, 724, 764, 575, 79, 688, 771, 721, 229, 725, 100, 290, 444, 810, 53, 391, 824, 851, 251, 499, 475, 271, 44, 113, 24, 211, 620, 169, 591, 830, 596, 520, 32, 611, 109, 136, 330, 222, 28, 287, 55, 827, 769, 48, 772, 835, 642, 545, 477, 547, 63, 413, 384, 759, 322, 451, 664, 234, 656, 557, 462, 424, 752, 303, 754, 219, 743, 296, 21, 420, 325, 199, 450, 137, 536, 646, 628, 212, 823, 799, 788, 505, 756, 231, 405, 568, 317, 183, 732, 730, 693, 609, 626, 485, 278, 630, 20, 170, 401, 791, 566, 176, 327, 706, 198, 470, 719, 694, 266, 615, 492, 130, 338, 758, 489, 572, 606, 193, 140, 416, 660, 476, 714, 152, 849, 10, 269, 96, 210, 842, 569, 548, 807, 532, 798, 332, 75, 712, 77, 263, 848, 149, 797, 514, 804, 469, 564, 461, 253, 369, 321, 695, 151, 813, 302, 190, 586, 348, 243, 87, 751, 655, 780, 418, 288, 648, 166, 595, 802, 155, 356, 381, 279, 126, 707, 777, 22, 616, 665, 282, 471, 738, 367, 25, 196, 64, 15, 466, 297, 621, 336, 26, 588, 43, 497, 792, 515, 818, 561, 454, 387, 71, 542, 456, 633, 431, 627, 653, 728, 264, 209, 316, 513, 313, 534, 319, 7, 393, 141, 86, 478, 503, 753, 215, 580, 562, 398, 668, 490, 252, 468, 357, 254, 276, 178, 281, 390, 508, 749, 583, 129, 144, 645, 715, 767, 72, 235, 37]\n",
    "    test_index1 = [711, 247, 480, 467, 320, 647, 845, 268, 744, 552, 8, 699, 776, 632, 241, 710, 331, 493, 180, 84, 736, 205, 618, 223, 340, 498, 372, 840, 763, 741, 809, 760, 768, 509, 435, 496, 17, 355, 81, 265, 593, 486, 257, 117, 634, 675, 570, 73, 364, 473, 56, 585, 289, 757, 201, 488, 34, 778, 194, 94, 811, 294, 822, 274, 832, 382, 242, 90, 722, 47, 366, 612, 19, 101, 224, 65, 344, 812, 258, 828, 50, 286, 652, 60, 154, 704, 544, 589, 847, 600, 447, 685, 298, 452, 731, 301, 439, 523, 85, 599, 709, 346, 635, 187, 111, 504, 481, 597, 678, 604, 202, 650, 762, 805, 107, 782, 49, 427, 245, 181, 491, 121, 619, 59, 408, 663, 239, 3, 207, 16, 148, 559, 765, 607, 218, 659, 277, 779, 106, 23, 69, 309, 175, 244, 550, 565, 119, 608, 808, 370, 412, 248, 216, 120, 590, 701, 195, 551, 463, 530, 414, 623, 713, 61, 502, 831, 571, 786, 735, 654, 683, 135, 339, 318, 134, 834, 104, 185, 233, 57, 483, 519, 560, 785, 482, 667, 354, 690, 703, 816, 35, 495, 299, 472, 718, 41, 838, 474, 385, 629, 108, 554, 850, 661, 511, 0, 353, 359, 74, 160, 669, 66, 291, 457]\n",
    "\n",
    "    \n",
    "    \n",
    "else:\n",
    "    \n",
    "    n = len(all_idx)\n",
    "    y_train, y_test = train_test_split(range(n), test_size=0.25, random_state=1)\n",
    "    \n",
    "    \n",
    "    train_idx5 = [59, 68, 37, 84, 6, 92, 26, 40, 85, 69, 71, 21, 25, 33, 29, 56, 14, 94, 52, 70, 3, 43, 11, 95, 45, 82, 64, 86, 49, 74, 55, 19, 63, 38, 79, 2, 31, 81, 51, 72, 36, 4, 0, 58, 5, 93, 1, 90, 41, 9, 18, 88, 47, 65, 75, 77, 44, 89, 87, 53, 15, 76, 7, 80, 30, 27, 62, 8, 73, 16, 61, 78]\n",
    "    test_idx5 = [42, 57, 48, 32, 67, 22, 10, 20, 17, 28, 35, 34, 54, 24, 39, 60, 50, 83, 12, 66, 91, 46, 23, 13]    \n",
    "    train_index5 = list(itertools.chain.from_iterable([all_idx[i] for i in train_idx5]))\n",
    "    test_index5 = list(itertools.chain.from_iterable([all_idx[i] for i in test_idx5]))\n",
    "    random.shuffle(train_index5)\n",
    "    \n",
    "    train_idx4 = [5, 67, 19, 39, 29, 27, 4, 79, 61, 74, 18, 84, 7, 6, 43, 11, 76, 22, 68, 23, 12, 88, 25, 70, 48, 17, 31, 34, 15, 62, 82, 78, 28, 60, 64, 33, 45, 42, 51, 40, 32, 91, 49, 8, 30, 95, 66, 56, 80, 73, 75, 21, 85, 0, 3, 52, 38, 44, 89, 36, 57, 86, 94, 58, 9, 50, 72, 87, 1, 69, 55, 46]\n",
    "    test_idx4 = [81, 14, 13, 53, 59, 20, 37, 10, 63, 2, 16, 24, 35, 92, 47, 54, 26, 90, 71, 65, 77, 83, 41, 93]\n",
    "    train_index4 = list(itertools.chain.from_iterable([all_idx[i] for i in train_idx4]))\n",
    "    test_index4 = list(itertools.chain.from_iterable([all_idx[i] for i in test_idx4]))\n",
    "    random.shuffle(train_index4)\n",
    "    \n",
    "    train_idx3 = [34, 17, 68, 82, 40, 5, 13, 31, 92, 11, 50, 47, 32, 84, 16, 27, 35, 36, 86, 59, 73, 65, 46, 88, 67, 75, 18, 87, 53, 91, 54, 55, 28, 52, 80, 85, 49, 30, 83, 37, 48, 33, 43, 7, 62, 95, 29, 69, 51, 1, 60, 63, 2, 66, 22, 26, 14, 39, 44, 20, 38, 90, 10, 41, 74, 19, 21, 0, 72, 56, 3, 24]\n",
    "    test_idx3 = [61, 23, 94, 9, 25, 6, 79, 71, 57, 64, 15, 77, 58, 70, 81, 45, 78, 89, 42, 93, 12, 8, 4, 76]\n",
    "    train_index3 = list(itertools.chain.from_iterable([all_idx[i] for i in train_idx3]))\n",
    "    test_index3 = list(itertools.chain.from_iterable([all_idx[i] for i in test_idx3]))\n",
    "    random.shuffle(train_index3)\n",
    "    \n",
    "    train_idx2 = [5, 73, 56, 95, 83, 1, 18, 24, 44, 35, 60, 6, 48, 87, 10, 12, 85, 65, 91, 32, 19, 62, 93, 53, 9, 92, 17, 57, 55, 41, 61, 45, 64, 8, 70, 79, 86, 94, 26, 77, 50, 52, 66, 90, 46, 68, 69, 78, 58, 33, 38, 51, 42, 4, 67, 39, 37, 20, 31, 63, 47, 89, 49, 34, 7, 75, 82, 43, 22, 72, 15, 40]\n",
    "    test_idx2 = [36, 28, 54, 23, 16, 80, 2, 25, 84, 13, 59, 88, 76, 14, 0, 21, 3, 27, 74, 71, 11, 81, 30, 29]\n",
    "    train_index2 = list(itertools.chain.from_iterable([all_idx[i] for i in train_idx2]))\n",
    "    test_index2 = list(itertools.chain.from_iterable([all_idx[i] for i in test_idx2]))\n",
    "    random.shuffle(train_index2)\n",
    "    \n",
    "    train_idx1 = [95, 35, 33, 48, 84, 67, 55, 36, 45, 53, 23, 34, 82, 66, 88, 15, 89, 41, 87, 26, 94, 43, 69, 4, 52, 49, 21, 83, 3, 70, 30, 73, 42, 47, 51, 93, 24, 8, 17, 60, 0, 86, 57, 22, 61, 63, 7, 92, 13, 68, 81, 14, 29, 28, 11, 18, 20, 50, 25, 6, 71, 76, 1, 16, 64, 79, 5, 75, 9, 72, 12, 37]\n",
    "    test_idx1 = [40, 31, 46, 59, 78, 74, 65, 44, 80, 85, 62, 27, 91, 77, 32, 56, 39, 10, 2, 38, 54, 58, 19, 90]\n",
    "    train_index1 = list(itertools.chain.from_iterable([all_idx[i] for i in train_idx1]))\n",
    "    test_index1 = list(itertools.chain.from_iterable([all_idx[i] for i in test_idx1]))\n",
    "    random.shuffle(train_index1)\n",
    "    \n",
    "cg_index = [501, 502, 503, 504, 505, 506, 507, 508, 509]\n",
    "if arch == \"k40\":\n",
    "        for k in range(len(train_index1)):\n",
    "            if train_index1[k] >= 510:\n",
    "                train_index1[k] -= 9\n",
    "        for k in range(len(train_index2)):\n",
    "            if train_index2[k] >= 510:\n",
    "                train_index2[k] -= 9\n",
    "        for k in range(len(train_index3)):\n",
    "            if train_index3[k] >= 510:\n",
    "                train_index3[k] -= 9\n",
    "        for k in range(len(train_index4)):\n",
    "            if train_index4[k] >= 510:\n",
    "                train_index4[k] -= 9\n",
    "        for k in range(len(train_index5)):\n",
    "            if train_index5[k] >= 510:\n",
    "                train_index5[k] -= 9\n",
    "        for k in range(len(test_index1)):\n",
    "            if test_index1[k] >= 510:\n",
    "                test_index1[k] -= 9\n",
    "        for k in range(len(test_index2)):\n",
    "            if test_index2[k] >= 510:\n",
    "                test_index2[k] -= 9\n",
    "        for k in range(len(test_index3)):\n",
    "            if test_index3[k] >= 510:\n",
    "                test_index3[k] -= 9\n",
    "        for k in range(len(test_index4)):\n",
    "            if test_index4[k] >= 510:\n",
    "                test_index4[k] -= 9\n",
    "        for k in range(len(test_index5)):\n",
    "            if test_index5[k] >= 510:\n",
    "                test_index5[k] -= 9\n",
    "\n",
    "\n",
    "\n",
    "        for j in cg_index:\n",
    "            if j in train_index1:\n",
    "                train_index1.remove(j)\n",
    "            if j in train_index2:\n",
    "                train_index2.remove(j)\n",
    "            if j in train_index3:\n",
    "                train_index3.remove(j)\n",
    "            if j in train_index4:\n",
    "                train_index4.remove(j)\n",
    "            if j in train_index5:\n",
    "                train_index5.remove(j)\n",
    "\n",
    "            if j in test_index1:\n",
    "                test_index1.remove(j)\n",
    "            if j in test_index2:\n",
    "                test_index2.remove(j)\n",
    "            if j in test_index3:\n",
    "                test_index3.remove(j)\n",
    "            if j in test_index4:\n",
    "                test_index4.remove(j)\n",
    "            if j in test_index5:\n",
    "                test_index5.remove(j)\n",
    "\n",
    " \n",
    "    \n",
    "    #list(itertools.chain.from_iterable\n",
    "    \n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 445 samples, validate on 149 samples\n",
      "Epoch 1/800\n",
      "445/445 [==============================] - 9s 20ms/sample - loss: 1.7151 - acc: 0.7798 - val_loss: 1.5212 - val_acc: 0.8255\n",
      "Epoch 2/800\n",
      "445/445 [==============================] - 0s 289us/sample - loss: 1.6487 - acc: 0.7663 - val_loss: 1.4926 - val_acc: 0.8121\n",
      "Epoch 3/800\n",
      "445/445 [==============================] - 0s 327us/sample - loss: 1.6233 - acc: 0.6629 - val_loss: 1.4844 - val_acc: 0.6242\n",
      "Epoch 4/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 1.6124 - acc: 0.6112 - val_loss: 1.4861 - val_acc: 0.4765\n",
      "Epoch 5/800\n",
      "445/445 [==============================] - 0s 290us/sample - loss: 1.5997 - acc: 0.5820 - val_loss: 1.4834 - val_acc: 0.4966\n",
      "Epoch 6/800\n",
      "445/445 [==============================] - 0s 334us/sample - loss: 1.5970 - acc: 0.6067 - val_loss: 1.4772 - val_acc: 0.5638\n",
      "Epoch 7/800\n",
      "445/445 [==============================] - 0s 292us/sample - loss: 1.5932 - acc: 0.6180 - val_loss: 1.4644 - val_acc: 0.7450\n",
      "Epoch 8/800\n",
      "445/445 [==============================] - 0s 352us/sample - loss: 1.5815 - acc: 0.7236 - val_loss: 1.4500 - val_acc: 0.7584\n",
      "Epoch 9/800\n",
      "445/445 [==============================] - 0s 329us/sample - loss: 1.5679 - acc: 0.7978 - val_loss: 1.4376 - val_acc: 0.8054\n",
      "Epoch 10/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 1.5457 - acc: 0.8584 - val_loss: 1.4383 - val_acc: 0.8322\n",
      "Epoch 11/800\n",
      "445/445 [==============================] - 0s 308us/sample - loss: 1.5549 - acc: 0.8607 - val_loss: 1.4332 - val_acc: 0.8658\n",
      "Epoch 12/800\n",
      "445/445 [==============================] - 0s 339us/sample - loss: 1.5486 - acc: 0.8652 - val_loss: 1.4167 - val_acc: 0.8523\n",
      "Epoch 13/800\n",
      "445/445 [==============================] - 0s 314us/sample - loss: 1.5299 - acc: 0.8674 - val_loss: 1.3976 - val_acc: 0.8523\n",
      "Epoch 14/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 1.4927 - acc: 0.8899 - val_loss: 1.3769 - val_acc: 0.8658\n",
      "Epoch 15/800\n",
      "445/445 [==============================] - 0s 299us/sample - loss: 1.4859 - acc: 0.8629 - val_loss: 1.3667 - val_acc: 0.8322\n",
      "Epoch 16/800\n",
      "445/445 [==============================] - 0s 292us/sample - loss: 1.4692 - acc: 0.8180 - val_loss: 1.3477 - val_acc: 0.8658\n",
      "Epoch 17/800\n",
      "445/445 [==============================] - 0s 290us/sample - loss: 1.4480 - acc: 0.8539 - val_loss: 1.3238 - val_acc: 0.8792\n",
      "Epoch 18/800\n",
      "445/445 [==============================] - 0s 350us/sample - loss: 1.4371 - acc: 0.8607 - val_loss: 1.2930 - val_acc: 0.8926\n",
      "Epoch 19/800\n",
      "445/445 [==============================] - 0s 293us/sample - loss: 1.4064 - acc: 0.8562 - val_loss: 1.2664 - val_acc: 0.9128\n",
      "Epoch 20/800\n",
      "445/445 [==============================] - 0s 330us/sample - loss: 1.3798 - acc: 0.8921 - val_loss: 1.2395 - val_acc: 0.8926\n",
      "Epoch 21/800\n",
      "445/445 [==============================] - 0s 291us/sample - loss: 1.3405 - acc: 0.8787 - val_loss: 1.2181 - val_acc: 0.8591\n",
      "Epoch 22/800\n",
      "445/445 [==============================] - 0s 304us/sample - loss: 1.3141 - acc: 0.8674 - val_loss: 1.1805 - val_acc: 0.8859\n",
      "Epoch 23/800\n",
      "445/445 [==============================] - 0s 291us/sample - loss: 1.2387 - acc: 0.9079 - val_loss: 1.1565 - val_acc: 0.8993\n",
      "Epoch 24/800\n",
      "445/445 [==============================] - 0s 331us/sample - loss: 1.2286 - acc: 0.9056 - val_loss: 1.0868 - val_acc: 0.9195\n",
      "Epoch 25/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 1.1587 - acc: 0.8899 - val_loss: 1.0711 - val_acc: 0.8456\n",
      "Epoch 26/800\n",
      "445/445 [==============================] - 0s 325us/sample - loss: 1.1574 - acc: 0.8382 - val_loss: 1.0187 - val_acc: 0.8456\n",
      "Epoch 27/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 1.0946 - acc: 0.8674 - val_loss: 1.0081 - val_acc: 0.8859\n",
      "Epoch 28/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 1.0393 - acc: 0.9079 - val_loss: 0.9222 - val_acc: 0.8792\n",
      "Epoch 29/800\n",
      "445/445 [==============================] - 0s 291us/sample - loss: 0.9942 - acc: 0.8899 - val_loss: 0.9052 - val_acc: 0.8725\n",
      "Epoch 30/800\n",
      "445/445 [==============================] - 0s 332us/sample - loss: 1.0072 - acc: 0.9101 - val_loss: 0.8643 - val_acc: 0.8859\n",
      "Epoch 31/800\n",
      "445/445 [==============================] - 0s 223us/sample - loss: 0.9272 - acc: 0.8719 - val_loss: 0.8829 - val_acc: 0.8054\n",
      "Epoch 32/800\n",
      "445/445 [==============================] - 0s 341us/sample - loss: 0.9443 - acc: 0.8180 - val_loss: 0.8579 - val_acc: 0.8054\n",
      "Epoch 33/800\n",
      "445/445 [==============================] - 0s 292us/sample - loss: 0.9475 - acc: 0.8360 - val_loss: 0.7955 - val_acc: 0.8859\n",
      "Epoch 34/800\n",
      "445/445 [==============================] - 0s 342us/sample - loss: 0.8838 - acc: 0.8966 - val_loss: 0.7784 - val_acc: 0.8792\n",
      "Epoch 35/800\n",
      "445/445 [==============================] - 0s 219us/sample - loss: 0.8274 - acc: 0.8742 - val_loss: 0.8366 - val_acc: 0.7718\n",
      "Epoch 36/800\n",
      "445/445 [==============================] - 0s 218us/sample - loss: 0.8965 - acc: 0.7865 - val_loss: 0.8475 - val_acc: 0.7584\n",
      "Epoch 37/800\n",
      "445/445 [==============================] - 0s 256us/sample - loss: 0.8703 - acc: 0.7528 - val_loss: 0.8314 - val_acc: 0.7584\n",
      "Epoch 38/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.8799 - acc: 0.7506 - val_loss: 0.8014 - val_acc: 0.7852\n",
      "Epoch 39/800\n",
      "445/445 [==============================] - 0s 286us/sample - loss: 0.8314 - acc: 0.7978 - val_loss: 0.7638 - val_acc: 0.8255\n",
      "Epoch 40/800\n",
      "445/445 [==============================] - 0s 353us/sample - loss: 0.7625 - acc: 0.8427 - val_loss: 0.7558 - val_acc: 0.8658\n",
      "Epoch 41/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.7544 - acc: 0.9011 - val_loss: 0.8704 - val_acc: 0.8926\n",
      "Epoch 42/800\n",
      "445/445 [==============================] - 0s 329us/sample - loss: 0.7622 - acc: 0.9169 - val_loss: 0.7110 - val_acc: 0.8725\n",
      "Epoch 43/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.7302 - acc: 0.9056 - val_loss: 0.6689 - val_acc: 0.8658\n",
      "Epoch 44/800\n",
      "445/445 [==============================] - 0s 254us/sample - loss: 0.6969 - acc: 0.8607 - val_loss: 0.6784 - val_acc: 0.8456\n",
      "Epoch 45/800\n",
      "445/445 [==============================] - 0s 338us/sample - loss: 0.7208 - acc: 0.8652 - val_loss: 0.6443 - val_acc: 0.8859\n",
      "Epoch 46/800\n",
      "445/445 [==============================] - 0s 294us/sample - loss: 0.6997 - acc: 0.9034 - val_loss: 0.6328 - val_acc: 0.8993\n",
      "Epoch 47/800\n",
      "445/445 [==============================] - 0s 221us/sample - loss: 0.6539 - acc: 0.9281 - val_loss: 0.6410 - val_acc: 0.8926\n",
      "Epoch 48/800\n",
      "445/445 [==============================] - 0s 343us/sample - loss: 0.6120 - acc: 0.9236 - val_loss: 0.6023 - val_acc: 0.8926\n",
      "Epoch 49/800\n",
      "445/445 [==============================] - 0s 285us/sample - loss: 0.6119 - acc: 0.9213 - val_loss: 0.5867 - val_acc: 0.8859\n",
      "Epoch 50/800\n",
      "445/445 [==============================] - 0s 224us/sample - loss: 0.5867 - acc: 0.9191 - val_loss: 0.5876 - val_acc: 0.8993\n",
      "Epoch 51/800\n",
      "445/445 [==============================] - 0s 263us/sample - loss: 0.5674 - acc: 0.9281 - val_loss: 0.6068 - val_acc: 0.8859\n",
      "Epoch 52/800\n",
      "445/445 [==============================] - 0s 303us/sample - loss: 0.5478 - acc: 0.9281 - val_loss: 0.5639 - val_acc: 0.8993\n",
      "Epoch 53/800\n",
      "445/445 [==============================] - 0s 279us/sample - loss: 0.5522 - acc: 0.9191 - val_loss: 0.5388 - val_acc: 0.8792\n",
      "Epoch 54/800\n",
      "445/445 [==============================] - 0s 324us/sample - loss: 0.5234 - acc: 0.9034 - val_loss: 0.5249 - val_acc: 0.8792\n",
      "Epoch 55/800\n",
      "445/445 [==============================] - 0s 281us/sample - loss: 0.5231 - acc: 0.9124 - val_loss: 0.4877 - val_acc: 0.8926\n",
      "Epoch 56/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.4945 - acc: 0.9258 - val_loss: 0.4814 - val_acc: 0.8859\n",
      "Epoch 57/800\n",
      "445/445 [==============================] - 0s 274us/sample - loss: 0.5026 - acc: 0.9169 - val_loss: 0.5067 - val_acc: 0.8523\n",
      "Epoch 58/800\n",
      "445/445 [==============================] - 0s 315us/sample - loss: 0.5047 - acc: 0.8944 - val_loss: 0.4602 - val_acc: 0.8859\n",
      "Epoch 59/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.5302 - acc: 0.9191 - val_loss: 0.4566 - val_acc: 0.8859\n",
      "Epoch 60/800\n",
      "445/445 [==============================] - 0s 293us/sample - loss: 0.4723 - acc: 0.9303 - val_loss: 0.4422 - val_acc: 0.8859\n",
      "Epoch 61/800\n",
      "445/445 [==============================] - 0s 317us/sample - loss: 0.4164 - acc: 0.9258 - val_loss: 0.4368 - val_acc: 0.8859\n",
      "Epoch 62/800\n",
      "445/445 [==============================] - 0s 279us/sample - loss: 0.4225 - acc: 0.9191 - val_loss: 0.4250 - val_acc: 0.8859\n",
      "Epoch 63/800\n",
      "445/445 [==============================] - 0s 292us/sample - loss: 0.4132 - acc: 0.9236 - val_loss: 0.4029 - val_acc: 0.8926\n",
      "Epoch 64/800\n",
      "445/445 [==============================] - 0s 335us/sample - loss: 0.3964 - acc: 0.9326 - val_loss: 0.3993 - val_acc: 0.8993\n",
      "Epoch 65/800\n",
      "445/445 [==============================] - 0s 256us/sample - loss: 0.4002 - acc: 0.9303 - val_loss: 0.4061 - val_acc: 0.8859\n",
      "Epoch 66/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.3946 - acc: 0.9124 - val_loss: 0.3953 - val_acc: 0.8993\n",
      "Epoch 67/800\n",
      "445/445 [==============================] - 0s 337us/sample - loss: 0.3773 - acc: 0.9213 - val_loss: 0.3651 - val_acc: 0.9060\n",
      "Epoch 68/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.3762 - acc: 0.9348 - val_loss: 0.5999 - val_acc: 0.8993\n",
      "Epoch 69/800\n",
      "445/445 [==============================] - 0s 253us/sample - loss: 0.4801 - acc: 0.8989 - val_loss: 0.5085 - val_acc: 0.8322\n",
      "Epoch 70/800\n",
      "445/445 [==============================] - 0s 254us/sample - loss: 0.5461 - acc: 0.8135 - val_loss: 0.5228 - val_acc: 0.8322\n",
      "Epoch 71/800\n",
      "445/445 [==============================] - 0s 267us/sample - loss: 0.5821 - acc: 0.8022 - val_loss: 0.5063 - val_acc: 0.8322\n",
      "Epoch 72/800\n",
      "445/445 [==============================] - 0s 282us/sample - loss: 0.5471 - acc: 0.8180 - val_loss: 0.4771 - val_acc: 0.8456\n",
      "Epoch 73/800\n",
      "445/445 [==============================] - 0s 255us/sample - loss: 0.4702 - acc: 0.8652 - val_loss: 0.3690 - val_acc: 0.9060\n",
      "Epoch 74/800\n",
      "445/445 [==============================] - 0s 217us/sample - loss: 0.3503 - acc: 0.9326 - val_loss: 0.4773 - val_acc: 0.8993\n",
      "Epoch 75/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.3725 - acc: 0.9326 - val_loss: 0.3934 - val_acc: 0.9060\n",
      "Epoch 76/800\n",
      "445/445 [==============================] - 0s 349us/sample - loss: 0.3589 - acc: 0.9348 - val_loss: 0.3549 - val_acc: 0.8993\n",
      "Epoch 77/800\n",
      "445/445 [==============================] - 0s 244us/sample - loss: 0.3529 - acc: 0.9326 - val_loss: 0.3688 - val_acc: 0.8859\n",
      "Epoch 78/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.3502 - acc: 0.9169 - val_loss: 0.3599 - val_acc: 0.8926\n",
      "Epoch 79/800\n",
      "445/445 [==============================] - 0s 341us/sample - loss: 0.3335 - acc: 0.9146 - val_loss: 0.3151 - val_acc: 0.9060\n",
      "Epoch 80/800\n",
      "445/445 [==============================] - 0s 253us/sample - loss: 0.2912 - acc: 0.9348 - val_loss: 0.3524 - val_acc: 0.9463\n",
      "Epoch 81/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.3121 - acc: 0.9416 - val_loss: 0.3184 - val_acc: 0.9128\n",
      "Epoch 82/800\n",
      "445/445 [==============================] - 0s 220us/sample - loss: 0.3084 - acc: 0.9213 - val_loss: 0.3393 - val_acc: 0.8993\n",
      "Epoch 83/800\n",
      "445/445 [==============================] - 0s 327us/sample - loss: 0.3311 - acc: 0.9124 - val_loss: 0.3147 - val_acc: 0.9128\n",
      "Epoch 84/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.2775 - acc: 0.9326 - val_loss: 0.3305 - val_acc: 0.9329\n",
      "Epoch 85/800\n",
      "445/445 [==============================] - 0s 290us/sample - loss: 0.3119 - acc: 0.9416 - val_loss: 0.2982 - val_acc: 0.9195\n",
      "Epoch 86/800\n",
      "445/445 [==============================] - 0s 261us/sample - loss: 0.2848 - acc: 0.9281 - val_loss: 0.3377 - val_acc: 0.8993\n",
      "Epoch 87/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.3133 - acc: 0.9079 - val_loss: 0.3192 - val_acc: 0.8993\n",
      "Epoch 88/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.2820 - acc: 0.9191 - val_loss: 0.2588 - val_acc: 0.9329\n",
      "Epoch 89/800\n",
      "445/445 [==============================] - 0s 251us/sample - loss: 0.2591 - acc: 0.9416 - val_loss: 0.3059 - val_acc: 0.9463\n",
      "Epoch 90/800\n",
      "445/445 [==============================] - 0s 308us/sample - loss: 0.2935 - acc: 0.9371 - val_loss: 0.2554 - val_acc: 0.9329\n",
      "Epoch 91/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.2494 - acc: 0.9326 - val_loss: 0.2755 - val_acc: 0.9128\n",
      "Epoch 92/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.3156 - acc: 0.9281 - val_loss: 0.2669 - val_acc: 0.9262\n",
      "Epoch 93/800\n",
      "445/445 [==============================] - 0s 249us/sample - loss: 0.2541 - acc: 0.9371 - val_loss: 0.2783 - val_acc: 0.9463\n",
      "Epoch 94/800\n",
      "445/445 [==============================] - 0s 262us/sample - loss: 0.2881 - acc: 0.9461 - val_loss: 0.2616 - val_acc: 0.9329\n",
      "Epoch 95/800\n",
      "445/445 [==============================] - 0s 231us/sample - loss: 0.2430 - acc: 0.9416 - val_loss: 0.2772 - val_acc: 0.9128\n",
      "Epoch 96/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.2616 - acc: 0.9213 - val_loss: 0.2815 - val_acc: 0.9128\n",
      "Epoch 97/800\n",
      "445/445 [==============================] - 0s 299us/sample - loss: 0.2611 - acc: 0.9303 - val_loss: 0.2519 - val_acc: 0.9262\n",
      "Epoch 98/800\n",
      "445/445 [==============================] - 0s 723us/sample - loss: 0.2390 - acc: 0.9506 - val_loss: 0.2323 - val_acc: 0.9396\n",
      "Epoch 99/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.2256 - acc: 0.9506 - val_loss: 0.2479 - val_acc: 0.9463\n",
      "Epoch 100/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.2222 - acc: 0.9483 - val_loss: 0.2359 - val_acc: 0.9329\n",
      "Epoch 101/800\n",
      "445/445 [==============================] - 0s 252us/sample - loss: 0.2475 - acc: 0.9393 - val_loss: 0.2599 - val_acc: 0.9262\n",
      "Epoch 102/800\n",
      "445/445 [==============================] - 0s 250us/sample - loss: 0.2227 - acc: 0.9416 - val_loss: 0.2496 - val_acc: 0.9329\n",
      "Epoch 103/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.2079 - acc: 0.9461 - val_loss: 0.2315 - val_acc: 0.9329\n",
      "Epoch 104/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.2192 - acc: 0.9438 - val_loss: 0.2542 - val_acc: 0.9463\n",
      "Epoch 105/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.2099 - acc: 0.9551 - val_loss: 0.2327 - val_acc: 0.9463\n",
      "Epoch 106/800\n",
      "445/445 [==============================] - 0s 299us/sample - loss: 0.2288 - acc: 0.9528 - val_loss: 0.2297 - val_acc: 0.9329\n",
      "Epoch 107/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.2147 - acc: 0.9438 - val_loss: 0.2357 - val_acc: 0.9329\n",
      "Epoch 108/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.2004 - acc: 0.9416 - val_loss: 0.2167 - val_acc: 0.9329\n",
      "Epoch 109/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.1866 - acc: 0.9483 - val_loss: 0.1975 - val_acc: 0.9396\n",
      "Epoch 110/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.2032 - acc: 0.9483 - val_loss: 0.2165 - val_acc: 0.9463\n",
      "Epoch 111/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.2342 - acc: 0.9506 - val_loss: 0.2661 - val_acc: 0.8993\n",
      "Epoch 112/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.2838 - acc: 0.9169 - val_loss: 0.2736 - val_acc: 0.8993\n",
      "Epoch 113/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.2236 - acc: 0.9371 - val_loss: 0.2127 - val_acc: 0.9396\n",
      "Epoch 114/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.4827 - acc: 0.9506 - val_loss: 0.2086 - val_acc: 0.9329\n",
      "Epoch 115/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.2019 - acc: 0.9461 - val_loss: 0.3302 - val_acc: 0.8725\n",
      "Epoch 116/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.3988 - acc: 0.8449 - val_loss: 0.3066 - val_acc: 0.8725\n",
      "Epoch 117/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.2771 - acc: 0.8944 - val_loss: 0.1938 - val_acc: 0.9396\n",
      "Epoch 118/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.2682 - acc: 0.9483 - val_loss: 0.1960 - val_acc: 0.9396\n",
      "Epoch 119/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 229us/sample - loss: 0.1967 - acc: 0.9483 - val_loss: 0.2613 - val_acc: 0.8926\n",
      "Epoch 120/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.3022 - acc: 0.8944 - val_loss: 0.2671 - val_acc: 0.8926\n",
      "Epoch 121/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.2904 - acc: 0.9056 - val_loss: 0.2494 - val_acc: 0.9463\n",
      "Epoch 122/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.1952 - acc: 0.9596 - val_loss: 0.3215 - val_acc: 0.9396\n",
      "Epoch 123/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.2471 - acc: 0.9618 - val_loss: 0.3542 - val_acc: 0.9396\n",
      "Epoch 124/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.2283 - acc: 0.9528 - val_loss: 0.2392 - val_acc: 0.9262\n",
      "Epoch 125/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.1951 - acc: 0.9461 - val_loss: 0.2308 - val_acc: 0.9262\n",
      "Epoch 126/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.2054 - acc: 0.9438 - val_loss: 0.2224 - val_acc: 0.9262\n",
      "Epoch 127/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.1999 - acc: 0.9528 - val_loss: 0.2130 - val_acc: 0.9329\n",
      "Epoch 128/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.1779 - acc: 0.9573 - val_loss: 0.2092 - val_acc: 0.9396\n",
      "Epoch 129/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.1710 - acc: 0.9618 - val_loss: 0.1953 - val_acc: 0.9396\n",
      "Epoch 130/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.2001 - acc: 0.9573 - val_loss: 0.1824 - val_acc: 0.9329\n",
      "Epoch 131/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.1655 - acc: 0.9551 - val_loss: 0.1779 - val_acc: 0.9329\n",
      "Epoch 132/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.1822 - acc: 0.9596 - val_loss: 0.1730 - val_acc: 0.9329\n",
      "Epoch 133/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.1742 - acc: 0.9528 - val_loss: 0.1670 - val_acc: 0.9396\n",
      "Epoch 134/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.1593 - acc: 0.9640 - val_loss: 0.1585 - val_acc: 0.9463\n",
      "Epoch 135/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.1777 - acc: 0.9618 - val_loss: 0.1540 - val_acc: 0.9463\n",
      "Epoch 136/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.1546 - acc: 0.9640 - val_loss: 0.1488 - val_acc: 0.9664\n",
      "Epoch 137/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.1676 - acc: 0.9596 - val_loss: 0.1485 - val_acc: 0.9664\n",
      "Epoch 138/800\n",
      "445/445 [==============================] - 0s 322us/sample - loss: 0.1417 - acc: 0.9708 - val_loss: 0.1402 - val_acc: 0.9664\n",
      "Epoch 139/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.1420 - acc: 0.9753 - val_loss: 0.1332 - val_acc: 0.9664\n",
      "Epoch 140/800\n",
      "445/445 [==============================] - 0s 250us/sample - loss: 0.1326 - acc: 0.9640 - val_loss: 0.1367 - val_acc: 0.9463\n",
      "Epoch 141/800\n",
      "445/445 [==============================] - 0s 338us/sample - loss: 0.1532 - acc: 0.9573 - val_loss: 0.1311 - val_acc: 0.9597\n",
      "Epoch 142/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.1335 - acc: 0.9663 - val_loss: 0.1240 - val_acc: 0.9732\n",
      "Epoch 143/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.1524 - acc: 0.9663 - val_loss: 0.1216 - val_acc: 0.9732\n",
      "Epoch 144/800\n",
      "445/445 [==============================] - 0s 239us/sample - loss: 0.1341 - acc: 0.9730 - val_loss: 0.1402 - val_acc: 0.9396\n",
      "Epoch 145/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.1485 - acc: 0.9573 - val_loss: 0.1634 - val_acc: 0.9329\n",
      "Epoch 146/800\n",
      "445/445 [==============================] - 0s 245us/sample - loss: 0.1408 - acc: 0.9618 - val_loss: 0.1510 - val_acc: 0.9530\n",
      "Epoch 147/800\n",
      "445/445 [==============================] - 0s 239us/sample - loss: 0.1339 - acc: 0.9753 - val_loss: 0.1321 - val_acc: 0.9597\n",
      "Epoch 148/800\n",
      "445/445 [==============================] - 0s 253us/sample - loss: 0.1250 - acc: 0.9730 - val_loss: 0.1298 - val_acc: 0.9664\n",
      "Epoch 149/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.1584 - acc: 0.9708 - val_loss: 0.1218 - val_acc: 0.9799\n",
      "Epoch 150/800\n",
      "445/445 [==============================] - 0s 323us/sample - loss: 0.1376 - acc: 0.9708 - val_loss: 0.1182 - val_acc: 0.9799\n",
      "Epoch 151/800\n",
      "445/445 [==============================] - 0s 308us/sample - loss: 0.1262 - acc: 0.9753 - val_loss: 0.1095 - val_acc: 0.9799\n",
      "Epoch 152/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.1121 - acc: 0.9775 - val_loss: 0.1000 - val_acc: 0.9866\n",
      "Epoch 153/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.1094 - acc: 0.9820 - val_loss: 0.1055 - val_acc: 0.9866\n",
      "Epoch 154/800\n",
      "445/445 [==============================] - 0s 274us/sample - loss: 0.1410 - acc: 0.9775 - val_loss: 0.1037 - val_acc: 0.9799\n",
      "Epoch 155/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.1082 - acc: 0.9798 - val_loss: 0.1458 - val_acc: 0.9664\n",
      "Epoch 156/800\n",
      "445/445 [==============================] - 0s 274us/sample - loss: 0.1543 - acc: 0.9640 - val_loss: 0.1424 - val_acc: 0.9664\n",
      "Epoch 157/800\n",
      "445/445 [==============================] - 0s 239us/sample - loss: 0.1108 - acc: 0.9798 - val_loss: 0.1066 - val_acc: 0.9732\n",
      "Epoch 158/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.1001 - acc: 0.9820 - val_loss: 0.1056 - val_acc: 0.9866\n",
      "Epoch 159/800\n",
      "445/445 [==============================] - 0s 336us/sample - loss: 0.1462 - acc: 0.9775 - val_loss: 0.0994 - val_acc: 0.9799\n",
      "Epoch 160/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.1235 - acc: 0.9685 - val_loss: 0.1893 - val_acc: 0.9396\n",
      "Epoch 161/800\n",
      "445/445 [==============================] - 0s 246us/sample - loss: 0.1853 - acc: 0.9438 - val_loss: 0.1391 - val_acc: 0.9530\n",
      "Epoch 162/800\n",
      "445/445 [==============================] - 0s 239us/sample - loss: 0.1479 - acc: 0.9596 - val_loss: 0.1017 - val_acc: 0.9866\n",
      "Epoch 163/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.1200 - acc: 0.9775 - val_loss: 0.1240 - val_acc: 0.9866\n",
      "Epoch 164/800\n",
      "445/445 [==============================] - 0s 348us/sample - loss: 0.1416 - acc: 0.9798 - val_loss: 0.0915 - val_acc: 0.9866\n",
      "Epoch 165/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.1288 - acc: 0.9753 - val_loss: 0.1576 - val_acc: 0.9597\n",
      "Epoch 166/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.2190 - acc: 0.9393 - val_loss: 0.1743 - val_acc: 0.9530\n",
      "Epoch 167/800\n",
      "445/445 [==============================] - 0s 254us/sample - loss: 0.2152 - acc: 0.9393 - val_loss: 0.1042 - val_acc: 0.9866\n",
      "Epoch 168/800\n",
      "445/445 [==============================] - 0s 304us/sample - loss: 0.2099 - acc: 0.9798 - val_loss: 0.0990 - val_acc: 0.9866\n",
      "Epoch 169/800\n",
      "445/445 [==============================] - 0s 237us/sample - loss: 0.1275 - acc: 0.9730 - val_loss: 0.1994 - val_acc: 0.9396\n",
      "Epoch 170/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.2499 - acc: 0.9124 - val_loss: 0.1615 - val_acc: 0.9597\n",
      "Epoch 171/800\n",
      "445/445 [==============================] - 0s 326us/sample - loss: 0.1492 - acc: 0.9551 - val_loss: 0.0892 - val_acc: 0.9866\n",
      "Epoch 172/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.1211 - acc: 0.9798 - val_loss: 0.8744 - val_acc: 0.9530\n",
      "Epoch 173/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.6495 - acc: 0.9281 - val_loss: 0.6286 - val_acc: 0.7919\n",
      "Epoch 174/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.7623 - acc: 0.7528 - val_loss: 1.0526 - val_acc: 0.6913\n",
      "Epoch 175/800\n",
      "445/445 [==============================] - 0s 258us/sample - loss: 1.1553 - acc: 0.6517 - val_loss: 1.1877 - val_acc: 0.6443\n",
      "Epoch 176/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 1.2373 - acc: 0.6112 - val_loss: 1.1399 - val_acc: 0.6376\n",
      "Epoch 177/800\n",
      "445/445 [==============================] - 0s 272us/sample - loss: 1.1342 - acc: 0.6022 - val_loss: 1.0917 - val_acc: 0.6309\n",
      "Epoch 178/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 282us/sample - loss: 1.0710 - acc: 0.6022 - val_loss: 0.8158 - val_acc: 0.6242\n",
      "Epoch 179/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.8785 - acc: 0.6944 - val_loss: 0.8032 - val_acc: 0.9262\n",
      "Epoch 180/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.7938 - acc: 0.8539 - val_loss: 0.8345 - val_acc: 0.9195\n",
      "Epoch 181/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.8153 - acc: 0.8090 - val_loss: 0.6589 - val_acc: 0.6846\n",
      "Epoch 182/800\n",
      "445/445 [==============================] - 0s 275us/sample - loss: 0.7974 - acc: 0.6966 - val_loss: 0.7708 - val_acc: 0.6376\n",
      "Epoch 183/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.8754 - acc: 0.6404 - val_loss: 0.6678 - val_acc: 0.6577\n",
      "Epoch 184/800\n",
      "445/445 [==============================] - 0s 263us/sample - loss: 0.8292 - acc: 0.6562 - val_loss: 0.6058 - val_acc: 0.7047\n",
      "Epoch 185/800\n",
      "445/445 [==============================] - 0s 263us/sample - loss: 0.7343 - acc: 0.7124 - val_loss: 0.5607 - val_acc: 0.7852\n",
      "Epoch 186/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.6391 - acc: 0.7910 - val_loss: 0.5289 - val_acc: 0.8322\n",
      "Epoch 187/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.5811 - acc: 0.8270 - val_loss: 0.5392 - val_acc: 0.8926\n",
      "Epoch 188/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.6099 - acc: 0.8539 - val_loss: 0.5593 - val_acc: 0.9060\n",
      "Epoch 189/800\n",
      "445/445 [==============================] - 0s 284us/sample - loss: 0.5628 - acc: 0.8966 - val_loss: 0.5026 - val_acc: 0.8993\n",
      "Epoch 190/800\n",
      "445/445 [==============================] - 0s 245us/sample - loss: 0.5513 - acc: 0.8674 - val_loss: 0.4571 - val_acc: 0.8456\n",
      "Epoch 191/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.5152 - acc: 0.8697 - val_loss: 0.4413 - val_acc: 0.8725\n",
      "Epoch 192/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.5660 - acc: 0.8584 - val_loss: 0.4607 - val_acc: 0.8591\n",
      "Epoch 193/800\n",
      "445/445 [==============================] - 0s 254us/sample - loss: 0.4803 - acc: 0.8719 - val_loss: 0.4452 - val_acc: 0.8456\n",
      "Epoch 194/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.5539 - acc: 0.8787 - val_loss: 0.4072 - val_acc: 0.8658\n",
      "Epoch 195/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.4536 - acc: 0.8787 - val_loss: 0.4038 - val_acc: 0.8792\n",
      "Epoch 196/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.5058 - acc: 0.8494 - val_loss: 0.4043 - val_acc: 0.8591\n",
      "Epoch 197/800\n",
      "445/445 [==============================] - 0s 262us/sample - loss: 0.4643 - acc: 0.8135 - val_loss: 0.4051 - val_acc: 0.8658\n",
      "Epoch 198/800\n",
      "445/445 [==============================] - 0s 285us/sample - loss: 0.4525 - acc: 0.8247 - val_loss: 0.4060 - val_acc: 0.8591\n",
      "Epoch 199/800\n",
      "445/445 [==============================] - 0s 311us/sample - loss: 0.4406 - acc: 0.8449 - val_loss: 0.4311 - val_acc: 0.8658\n",
      "Epoch 200/800\n",
      "445/445 [==============================] - 0s 270us/sample - loss: 0.4107 - acc: 0.8831 - val_loss: 0.7727 - val_acc: 0.8725\n",
      "Epoch 201/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.4958 - acc: 0.9034 - val_loss: 0.4057 - val_acc: 0.8591\n",
      "Epoch 202/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.3879 - acc: 0.8764 - val_loss: 0.3818 - val_acc: 0.8591\n",
      "Epoch 203/800\n",
      "445/445 [==============================] - 0s 317us/sample - loss: 0.4660 - acc: 0.8157 - val_loss: 0.3956 - val_acc: 0.8591\n",
      "Epoch 204/800\n",
      "445/445 [==============================] - 0s 267us/sample - loss: 0.4850 - acc: 0.8180 - val_loss: 0.4051 - val_acc: 0.8322\n",
      "Epoch 205/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.5246 - acc: 0.8045 - val_loss: 0.3895 - val_acc: 0.8389\n",
      "Epoch 206/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.4606 - acc: 0.8135 - val_loss: 0.3812 - val_acc: 0.8725\n",
      "Epoch 207/800\n",
      "445/445 [==============================] - 0s 275us/sample - loss: 0.4805 - acc: 0.8315 - val_loss: 0.3664 - val_acc: 0.8725\n",
      "Epoch 208/800\n",
      "445/445 [==============================] - 0s 281us/sample - loss: 0.4108 - acc: 0.8584 - val_loss: 0.3588 - val_acc: 0.8792\n",
      "Epoch 209/800\n",
      "445/445 [==============================] - 0s 289us/sample - loss: 0.3573 - acc: 0.8899 - val_loss: 0.3608 - val_acc: 0.8792\n",
      "Epoch 210/800\n",
      "445/445 [==============================] - 0s 254us/sample - loss: 0.3385 - acc: 0.9079 - val_loss: 0.3670 - val_acc: 0.8792\n",
      "Epoch 211/800\n",
      "445/445 [==============================] - 0s 262us/sample - loss: 0.3537 - acc: 0.8989 - val_loss: 0.3577 - val_acc: 0.8926\n",
      "Epoch 212/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.3283 - acc: 0.9213 - val_loss: 0.3508 - val_acc: 0.8993\n",
      "Epoch 213/800\n",
      "445/445 [==============================] - 0s 247us/sample - loss: 0.3494 - acc: 0.9146 - val_loss: 0.3398 - val_acc: 0.9060\n",
      "Epoch 214/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.3416 - acc: 0.8989 - val_loss: 0.3174 - val_acc: 0.9128\n",
      "Epoch 215/800\n",
      "445/445 [==============================] - 0s 251us/sample - loss: 0.3386 - acc: 0.9079 - val_loss: 0.2941 - val_acc: 0.9128\n",
      "Epoch 216/800\n",
      "445/445 [==============================] - 0s 267us/sample - loss: 0.2942 - acc: 0.9146 - val_loss: 0.2878 - val_acc: 0.9195\n",
      "Epoch 217/800\n",
      "445/445 [==============================] - 0s 303us/sample - loss: 0.2946 - acc: 0.9281 - val_loss: 0.2938 - val_acc: 0.9195\n",
      "Epoch 218/800\n",
      "445/445 [==============================] - 0s 309us/sample - loss: 0.2622 - acc: 0.9258 - val_loss: 0.2550 - val_acc: 0.9128\n",
      "Epoch 219/800\n",
      "445/445 [==============================] - 0s 277us/sample - loss: 0.2583 - acc: 0.9124 - val_loss: 0.2531 - val_acc: 0.9128\n",
      "Epoch 220/800\n",
      "445/445 [==============================] - 0s 288us/sample - loss: 0.2910 - acc: 0.9146 - val_loss: 0.2821 - val_acc: 0.9396\n",
      "Epoch 221/800\n",
      "445/445 [==============================] - 0s 308us/sample - loss: 0.2563 - acc: 0.9191 - val_loss: 0.2827 - val_acc: 0.9396\n",
      "Epoch 222/800\n",
      "445/445 [==============================] - 0s 262us/sample - loss: 0.2627 - acc: 0.9348 - val_loss: 0.2762 - val_acc: 0.9396\n",
      "Epoch 223/800\n",
      "445/445 [==============================] - 0s 271us/sample - loss: 0.2521 - acc: 0.9348 - val_loss: 0.2826 - val_acc: 0.9396\n",
      "Epoch 224/800\n",
      "445/445 [==============================] - 0s 267us/sample - loss: 0.2549 - acc: 0.9258 - val_loss: 0.2634 - val_acc: 0.9396\n",
      "Epoch 225/800\n",
      "445/445 [==============================] - 0s 273us/sample - loss: 0.2417 - acc: 0.9326 - val_loss: 0.2292 - val_acc: 0.9530\n",
      "Epoch 226/800\n",
      "445/445 [==============================] - 0s 257us/sample - loss: 0.2391 - acc: 0.9326 - val_loss: 0.2278 - val_acc: 0.9597\n",
      "Epoch 227/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.1756 - acc: 0.9618 - val_loss: 0.2549 - val_acc: 0.9597\n",
      "Epoch 228/800\n",
      "445/445 [==============================] - 0s 266us/sample - loss: 0.2277 - acc: 0.9551 - val_loss: 0.2046 - val_acc: 0.9597\n",
      "Epoch 229/800\n",
      "445/445 [==============================] - 0s 247us/sample - loss: 0.2497 - acc: 0.9461 - val_loss: 0.1908 - val_acc: 0.9597\n",
      "Epoch 230/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.2209 - acc: 0.9416 - val_loss: 0.1823 - val_acc: 0.9664\n",
      "Epoch 231/800\n",
      "445/445 [==============================] - 0s 277us/sample - loss: 0.1738 - acc: 0.9640 - val_loss: 0.1855 - val_acc: 0.9664\n",
      "Epoch 232/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.1602 - acc: 0.9618 - val_loss: 0.1647 - val_acc: 0.9664\n",
      "Epoch 233/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.1722 - acc: 0.9640 - val_loss: 0.1572 - val_acc: 0.9597\n",
      "Epoch 234/800\n",
      "445/445 [==============================] - 0s 268us/sample - loss: 0.1654 - acc: 0.9596 - val_loss: 0.2708 - val_acc: 0.9597\n",
      "Epoch 235/800\n",
      "445/445 [==============================] - 0s 250us/sample - loss: 0.1994 - acc: 0.9730 - val_loss: 0.3534 - val_acc: 0.9530\n",
      "Epoch 236/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.2289 - acc: 0.9708 - val_loss: 0.2544 - val_acc: 0.9530\n",
      "Epoch 237/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 251us/sample - loss: 0.2560 - acc: 0.9303 - val_loss: 0.2346 - val_acc: 0.9597\n",
      "Epoch 238/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.2681 - acc: 0.9169 - val_loss: 0.2344 - val_acc: 0.9597\n",
      "Epoch 239/800\n",
      "445/445 [==============================] - 0s 260us/sample - loss: 0.2170 - acc: 0.9393 - val_loss: 0.2339 - val_acc: 0.9530\n",
      "Epoch 240/800\n",
      "445/445 [==============================] - 0s 252us/sample - loss: 0.2132 - acc: 0.9551 - val_loss: 0.2475 - val_acc: 0.9530\n",
      "Epoch 241/800\n",
      "445/445 [==============================] - 0s 276us/sample - loss: 0.1816 - acc: 0.9596 - val_loss: 0.2299 - val_acc: 0.9597\n",
      "Epoch 242/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.1750 - acc: 0.9640 - val_loss: 0.1888 - val_acc: 0.9597\n",
      "Epoch 243/800\n",
      "445/445 [==============================] - 0s 244us/sample - loss: 0.2127 - acc: 0.9551 - val_loss: 0.1702 - val_acc: 0.9530\n",
      "Epoch 244/800\n",
      "445/445 [==============================] - 0s 312us/sample - loss: 0.1688 - acc: 0.9573 - val_loss: 0.1671 - val_acc: 0.9597\n",
      "Epoch 245/800\n",
      "445/445 [==============================] - 0s 310us/sample - loss: 0.1640 - acc: 0.9551 - val_loss: 0.1599 - val_acc: 0.9732\n",
      "Epoch 246/800\n",
      "445/445 [==============================] - 0s 307us/sample - loss: 0.1388 - acc: 0.9685 - val_loss: 0.2495 - val_acc: 0.9597\n",
      "Epoch 247/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.1492 - acc: 0.9708 - val_loss: 0.2206 - val_acc: 0.9597\n",
      "Epoch 248/800\n",
      "445/445 [==============================] - 0s 286us/sample - loss: 0.1095 - acc: 0.9753 - val_loss: 0.1423 - val_acc: 0.9664\n",
      "Epoch 249/800\n",
      "445/445 [==============================] - 0s 269us/sample - loss: 0.1600 - acc: 0.9663 - val_loss: 0.1336 - val_acc: 0.9664\n",
      "Epoch 250/800\n",
      "445/445 [==============================] - 0s 283us/sample - loss: 0.1056 - acc: 0.9730 - val_loss: 0.1238 - val_acc: 0.9732\n",
      "Epoch 251/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.1191 - acc: 0.9820 - val_loss: 0.1532 - val_acc: 0.9463\n",
      "Epoch 252/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.1692 - acc: 0.9483 - val_loss: 0.2874 - val_acc: 0.8859\n",
      "Epoch 253/800\n",
      "445/445 [==============================] - 0s 308us/sample - loss: 0.3502 - acc: 0.8742 - val_loss: 0.1860 - val_acc: 0.9396\n",
      "Epoch 254/800\n",
      "445/445 [==============================] - 0s 285us/sample - loss: 0.1656 - acc: 0.9416 - val_loss: 0.1649 - val_acc: 0.9732\n",
      "Epoch 255/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.2052 - acc: 0.9730 - val_loss: 0.2023 - val_acc: 0.9597\n",
      "Epoch 256/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.1068 - acc: 0.9798 - val_loss: 0.1554 - val_acc: 0.9530\n",
      "Epoch 257/800\n",
      "445/445 [==============================] - 0s 274us/sample - loss: 0.2452 - acc: 0.9326 - val_loss: 0.1575 - val_acc: 0.9597\n",
      "Epoch 258/800\n",
      "445/445 [==============================] - 0s 312us/sample - loss: 0.1875 - acc: 0.9438 - val_loss: 0.1511 - val_acc: 0.9732\n",
      "Epoch 259/800\n",
      "445/445 [==============================] - 0s 288us/sample - loss: 0.1212 - acc: 0.9618 - val_loss: 0.1876 - val_acc: 0.9664\n",
      "Epoch 260/800\n",
      "445/445 [==============================] - 0s 269us/sample - loss: 0.1271 - acc: 0.9798 - val_loss: 0.2312 - val_acc: 0.9664\n",
      "Epoch 261/800\n",
      "445/445 [==============================] - 0s 280us/sample - loss: 0.1375 - acc: 0.9730 - val_loss: 0.1724 - val_acc: 0.9732\n",
      "Epoch 262/800\n",
      "445/445 [==============================] - 0s 271us/sample - loss: 0.0935 - acc: 0.9820 - val_loss: 0.1448 - val_acc: 0.9732\n",
      "Epoch 263/800\n",
      "445/445 [==============================] - 0s 293us/sample - loss: 0.0944 - acc: 0.9798 - val_loss: 0.1326 - val_acc: 0.9732\n",
      "Epoch 264/800\n",
      "445/445 [==============================] - 0s 276us/sample - loss: 0.0989 - acc: 0.9753 - val_loss: 0.1260 - val_acc: 0.9732\n",
      "Epoch 265/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.1237 - acc: 0.9753 - val_loss: 0.1201 - val_acc: 0.9732\n",
      "Epoch 266/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0943 - acc: 0.9798 - val_loss: 0.1146 - val_acc: 0.9732\n",
      "Epoch 267/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0949 - acc: 0.9753 - val_loss: 0.1100 - val_acc: 0.9732\n",
      "Epoch 268/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0774 - acc: 0.9820 - val_loss: 0.1053 - val_acc: 0.9732\n",
      "Epoch 269/800\n",
      "445/445 [==============================] - 0s 265us/sample - loss: 0.0837 - acc: 0.9843 - val_loss: 0.1001 - val_acc: 0.9799\n",
      "Epoch 270/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.1274 - acc: 0.9865 - val_loss: 0.0957 - val_acc: 0.9799\n",
      "Epoch 271/800\n",
      "445/445 [==============================] - 0s 344us/sample - loss: 0.0741 - acc: 0.9843 - val_loss: 0.0887 - val_acc: 0.9799\n",
      "Epoch 272/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.0749 - acc: 0.9843 - val_loss: 0.0837 - val_acc: 0.9799\n",
      "Epoch 273/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.0898 - acc: 0.9753 - val_loss: 0.0824 - val_acc: 0.9799\n",
      "Epoch 274/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0773 - acc: 0.9775 - val_loss: 0.0784 - val_acc: 0.9866\n",
      "Epoch 275/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0753 - acc: 0.9798 - val_loss: 0.0748 - val_acc: 0.9866\n",
      "Epoch 276/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.1081 - acc: 0.9775 - val_loss: 0.0753 - val_acc: 0.9866\n",
      "Epoch 277/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.0627 - acc: 0.9888 - val_loss: 0.0769 - val_acc: 0.9866\n",
      "Epoch 278/800\n",
      "445/445 [==============================] - 0s 267us/sample - loss: 0.0563 - acc: 0.9865 - val_loss: 0.0751 - val_acc: 0.9866\n",
      "Epoch 279/800\n",
      "445/445 [==============================] - 0s 304us/sample - loss: 0.0577 - acc: 0.9865 - val_loss: 0.0734 - val_acc: 0.9866\n",
      "Epoch 280/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0641 - acc: 0.9888 - val_loss: 0.0698 - val_acc: 0.9866\n",
      "Epoch 281/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0543 - acc: 0.9843 - val_loss: 0.0686 - val_acc: 0.9799\n",
      "Epoch 282/800\n",
      "445/445 [==============================] - 0s 251us/sample - loss: 0.0698 - acc: 0.9843 - val_loss: 0.0688 - val_acc: 0.9799\n",
      "Epoch 283/800\n",
      "445/445 [==============================] - 0s 352us/sample - loss: 0.0560 - acc: 0.9820 - val_loss: 0.0681 - val_acc: 0.9799\n",
      "Epoch 284/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.0560 - acc: 0.9843 - val_loss: 0.0670 - val_acc: 0.9799\n",
      "Epoch 285/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.0639 - acc: 0.9865 - val_loss: 0.0652 - val_acc: 0.9866\n",
      "Epoch 286/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.0577 - acc: 0.9820 - val_loss: 0.0639 - val_acc: 0.9866\n",
      "Epoch 287/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.0628 - acc: 0.9865 - val_loss: 0.0622 - val_acc: 0.9866\n",
      "Epoch 288/800\n",
      "445/445 [==============================] - 0s 317us/sample - loss: 0.0520 - acc: 0.9865 - val_loss: 0.0608 - val_acc: 0.9866\n",
      "Epoch 289/800\n",
      "445/445 [==============================] - 0s 315us/sample - loss: 0.0633 - acc: 0.9865 - val_loss: 0.0597 - val_acc: 0.9866\n",
      "Epoch 290/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.0577 - acc: 0.9865 - val_loss: 0.0586 - val_acc: 0.9866\n",
      "Epoch 291/800\n",
      "445/445 [==============================] - 0s 309us/sample - loss: 0.0555 - acc: 0.9843 - val_loss: 0.0571 - val_acc: 0.9866\n",
      "Epoch 292/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.0557 - acc: 0.9865 - val_loss: 0.0565 - val_acc: 0.9866\n",
      "Epoch 293/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.0724 - acc: 0.9843 - val_loss: 0.0564 - val_acc: 0.9866\n",
      "Epoch 294/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0425 - acc: 0.9888 - val_loss: 0.0561 - val_acc: 0.9866\n",
      "Epoch 295/800\n",
      "445/445 [==============================] - 0s 335us/sample - loss: 0.0487 - acc: 0.9843 - val_loss: 0.0556 - val_acc: 0.9866\n",
      "Epoch 296/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 300us/sample - loss: 0.0509 - acc: 0.9865 - val_loss: 0.0554 - val_acc: 0.9866\n",
      "Epoch 297/800\n",
      "445/445 [==============================] - 0s 308us/sample - loss: 0.0535 - acc: 0.9888 - val_loss: 0.0553 - val_acc: 0.9866\n",
      "Epoch 298/800\n",
      "445/445 [==============================] - 0s 324us/sample - loss: 0.0453 - acc: 0.9910 - val_loss: 0.0551 - val_acc: 0.9866\n",
      "Epoch 299/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.0502 - acc: 0.9843 - val_loss: 0.0550 - val_acc: 0.9866\n",
      "Epoch 300/800\n",
      "445/445 [==============================] - 0s 231us/sample - loss: 0.0408 - acc: 0.9910 - val_loss: 0.0552 - val_acc: 0.9866\n",
      "Epoch 301/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.0408 - acc: 0.9888 - val_loss: 0.0552 - val_acc: 0.9866\n",
      "Epoch 302/800\n",
      "445/445 [==============================] - 0s 264us/sample - loss: 0.0362 - acc: 0.9910 - val_loss: 0.0553 - val_acc: 0.9866\n",
      "Epoch 303/800\n",
      "445/445 [==============================] - 0s 282us/sample - loss: 0.0470 - acc: 0.9865 - val_loss: 0.0554 - val_acc: 0.9866\n",
      "Epoch 304/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0402 - acc: 0.9888 - val_loss: 0.0553 - val_acc: 0.9866\n",
      "Epoch 305/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0550 - acc: 0.9888 - val_loss: 0.0554 - val_acc: 0.9866\n",
      "Epoch 306/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0505 - acc: 0.9910 - val_loss: 0.0555 - val_acc: 0.9866\n",
      "Epoch 307/800\n",
      "445/445 [==============================] - 0s 234us/sample - loss: 0.0506 - acc: 0.9865 - val_loss: 0.0553 - val_acc: 0.9866\n",
      "Epoch 308/800\n",
      "445/445 [==============================] - 0s 224us/sample - loss: 0.0482 - acc: 0.9888 - val_loss: 0.0557 - val_acc: 0.9866\n",
      "Epoch 309/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0390 - acc: 0.9910 - val_loss: 0.0563 - val_acc: 0.9866\n",
      "Epoch 310/800\n",
      "445/445 [==============================] - 0s 237us/sample - loss: 0.0393 - acc: 0.9888 - val_loss: 0.0562 - val_acc: 0.9866\n",
      "Epoch 311/800\n",
      "445/445 [==============================] - 0s 246us/sample - loss: 0.0472 - acc: 0.9865 - val_loss: 0.0560 - val_acc: 0.9866\n",
      "Epoch 312/800\n",
      "445/445 [==============================] - 0s 266us/sample - loss: 0.0457 - acc: 0.9865 - val_loss: 0.0557 - val_acc: 0.9866\n",
      "Epoch 313/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.0391 - acc: 0.9910 - val_loss: 0.0555 - val_acc: 0.9866\n",
      "Epoch 314/800\n",
      "445/445 [==============================] - 0s 266us/sample - loss: 0.0419 - acc: 0.9865 - val_loss: 0.0551 - val_acc: 0.9866\n",
      "Epoch 315/800\n",
      "445/445 [==============================] - 0s 318us/sample - loss: 0.0323 - acc: 0.9888 - val_loss: 0.0549 - val_acc: 0.9866\n",
      "Epoch 316/800\n",
      "445/445 [==============================] - 0s 313us/sample - loss: 0.0384 - acc: 0.9910 - val_loss: 0.0548 - val_acc: 0.9866\n",
      "Epoch 317/800\n",
      "445/445 [==============================] - 0s 314us/sample - loss: 0.0454 - acc: 0.9843 - val_loss: 0.0545 - val_acc: 0.9866\n",
      "Epoch 318/800\n",
      "445/445 [==============================] - 0s 304us/sample - loss: 0.0481 - acc: 0.9888 - val_loss: 0.0540 - val_acc: 0.9866\n",
      "Epoch 319/800\n",
      "445/445 [==============================] - 0s 294us/sample - loss: 0.0384 - acc: 0.9865 - val_loss: 0.0538 - val_acc: 0.9866\n",
      "Epoch 320/800\n",
      "445/445 [==============================] - 0s 318us/sample - loss: 0.0410 - acc: 0.9910 - val_loss: 0.0538 - val_acc: 0.9866\n",
      "Epoch 321/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.0477 - acc: 0.9888 - val_loss: 0.0543 - val_acc: 0.9866\n",
      "Epoch 322/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0357 - acc: 0.9865 - val_loss: 0.0550 - val_acc: 0.9866\n",
      "Epoch 323/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0405 - acc: 0.9865 - val_loss: 0.0524 - val_acc: 0.9866\n",
      "Epoch 324/800\n",
      "445/445 [==============================] - 0s 314us/sample - loss: 0.0355 - acc: 0.9910 - val_loss: 0.0510 - val_acc: 0.9866\n",
      "Epoch 325/800\n",
      "445/445 [==============================] - 0s 304us/sample - loss: 0.0367 - acc: 0.9910 - val_loss: 0.0507 - val_acc: 0.9866\n",
      "Epoch 326/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.0356 - acc: 0.9910 - val_loss: 0.0504 - val_acc: 0.9866\n",
      "Epoch 327/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.0391 - acc: 0.9888 - val_loss: 0.0504 - val_acc: 0.9866\n",
      "Epoch 328/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.0352 - acc: 0.9910 - val_loss: 0.0508 - val_acc: 0.9866\n",
      "Epoch 329/800\n",
      "445/445 [==============================] - 0s 231us/sample - loss: 0.0382 - acc: 0.9843 - val_loss: 0.0507 - val_acc: 0.9866\n",
      "Epoch 330/800\n",
      "445/445 [==============================] - 0s 310us/sample - loss: 0.0310 - acc: 0.9910 - val_loss: 0.0502 - val_acc: 0.9866\n",
      "Epoch 331/800\n",
      "445/445 [==============================] - 0s 353us/sample - loss: 0.0330 - acc: 0.9910 - val_loss: 0.0497 - val_acc: 0.9866\n",
      "Epoch 332/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.0377 - acc: 0.9865 - val_loss: 0.0491 - val_acc: 0.9866\n",
      "Epoch 333/800\n",
      "445/445 [==============================] - 0s 303us/sample - loss: 0.0339 - acc: 0.9888 - val_loss: 0.0485 - val_acc: 0.9866\n",
      "Epoch 334/800\n",
      "445/445 [==============================] - 0s 299us/sample - loss: 0.0357 - acc: 0.9888 - val_loss: 0.0480 - val_acc: 0.9866\n",
      "Epoch 335/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0303 - acc: 0.9910 - val_loss: 0.0478 - val_acc: 0.9866\n",
      "Epoch 336/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0327 - acc: 0.9888 - val_loss: 0.0478 - val_acc: 0.9866\n",
      "Epoch 337/800\n",
      "445/445 [==============================] - 0s 349us/sample - loss: 0.0317 - acc: 0.9888 - val_loss: 0.0478 - val_acc: 0.9866\n",
      "Epoch 338/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0408 - acc: 0.9888 - val_loss: 0.0480 - val_acc: 0.9866\n",
      "Epoch 339/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0383 - acc: 0.9888 - val_loss: 0.0482 - val_acc: 0.9866\n",
      "Epoch 340/800\n",
      "445/445 [==============================] - 0s 237us/sample - loss: 0.0345 - acc: 0.9910 - val_loss: 0.0486 - val_acc: 0.9866\n",
      "Epoch 341/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0291 - acc: 0.9910 - val_loss: 0.0486 - val_acc: 0.9866\n",
      "Epoch 342/800\n",
      "445/445 [==============================] - 0s 263us/sample - loss: 0.0268 - acc: 0.9910 - val_loss: 0.0486 - val_acc: 0.9866\n",
      "Epoch 343/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0291 - acc: 0.9910 - val_loss: 0.0484 - val_acc: 0.9866\n",
      "Epoch 344/800\n",
      "445/445 [==============================] - 0s 225us/sample - loss: 0.0277 - acc: 0.9910 - val_loss: 0.0481 - val_acc: 0.9866\n",
      "Epoch 345/800\n",
      "445/445 [==============================] - 0s 299us/sample - loss: 0.0283 - acc: 0.9910 - val_loss: 0.0477 - val_acc: 0.9866\n",
      "Epoch 346/800\n",
      "445/445 [==============================] - 0s 299us/sample - loss: 0.0277 - acc: 0.9910 - val_loss: 0.0473 - val_acc: 0.9866\n",
      "Epoch 347/800\n",
      "445/445 [==============================] - 0s 301us/sample - loss: 0.0276 - acc: 0.9910 - val_loss: 0.0468 - val_acc: 0.9866\n",
      "Epoch 348/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.0546 - acc: 0.9865 - val_loss: 0.0465 - val_acc: 0.9866\n",
      "Epoch 349/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0462 - val_acc: 0.9866\n",
      "Epoch 350/800\n",
      "445/445 [==============================] - 0s 301us/sample - loss: 0.0274 - acc: 0.9910 - val_loss: 0.0458 - val_acc: 0.9866\n",
      "Epoch 351/800\n",
      "445/445 [==============================] - 0s 301us/sample - loss: 0.0256 - acc: 0.9910 - val_loss: 0.0455 - val_acc: 0.9866\n",
      "Epoch 352/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0326 - acc: 0.9888 - val_loss: 0.0452 - val_acc: 0.9866\n",
      "Epoch 353/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.0271 - acc: 0.9888 - val_loss: 0.0450 - val_acc: 0.9866\n",
      "Epoch 354/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.0249 - acc: 0.9910 - val_loss: 0.0448 - val_acc: 0.9866\n",
      "Epoch 355/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 299us/sample - loss: 0.0285 - acc: 0.9910 - val_loss: 0.0447 - val_acc: 0.9866\n",
      "Epoch 356/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0236 - acc: 0.9910 - val_loss: 0.0447 - val_acc: 0.9866\n",
      "Epoch 357/800\n",
      "445/445 [==============================] - 0s 224us/sample - loss: 0.0500 - acc: 0.9865 - val_loss: 0.0448 - val_acc: 0.9866\n",
      "Epoch 358/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.0286 - acc: 0.9888 - val_loss: 0.0447 - val_acc: 0.9866\n",
      "Epoch 359/800\n",
      "445/445 [==============================] - 0s 322us/sample - loss: 0.0256 - acc: 0.9910 - val_loss: 0.0445 - val_acc: 0.9866\n",
      "Epoch 360/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0231 - acc: 0.9910 - val_loss: 0.0444 - val_acc: 0.9866\n",
      "Epoch 361/800\n",
      "445/445 [==============================] - 0s 269us/sample - loss: 0.0342 - acc: 0.9910 - val_loss: 0.0445 - val_acc: 0.9866\n",
      "Epoch 362/800\n",
      "445/445 [==============================] - 0s 284us/sample - loss: 0.0296 - acc: 0.9843 - val_loss: 0.0445 - val_acc: 0.9866\n",
      "Epoch 363/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.0282 - acc: 0.9910 - val_loss: 0.0445 - val_acc: 0.9866\n",
      "Epoch 364/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0261 - acc: 0.9910 - val_loss: 0.0447 - val_acc: 0.9866\n",
      "Epoch 365/800\n",
      "445/445 [==============================] - 0s 334us/sample - loss: 0.0239 - acc: 0.9888 - val_loss: 0.0443 - val_acc: 0.9866\n",
      "Epoch 366/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0245 - acc: 0.9933 - val_loss: 0.0442 - val_acc: 0.9866\n",
      "Epoch 367/800\n",
      "445/445 [==============================] - 0s 309us/sample - loss: 0.0305 - acc: 0.9910 - val_loss: 0.0440 - val_acc: 0.9866\n",
      "Epoch 368/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0279 - acc: 0.9910 - val_loss: 0.0440 - val_acc: 0.9866\n",
      "Epoch 369/800\n",
      "445/445 [==============================] - 0s 309us/sample - loss: 0.0227 - acc: 0.9910 - val_loss: 0.0437 - val_acc: 0.9866\n",
      "Epoch 370/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0217 - acc: 0.9933 - val_loss: 0.0433 - val_acc: 0.9866\n",
      "Epoch 371/800\n",
      "445/445 [==============================] - 0s 328us/sample - loss: 0.0205 - acc: 0.9910 - val_loss: 0.0427 - val_acc: 0.9866\n",
      "Epoch 372/800\n",
      "445/445 [==============================] - 0s 334us/sample - loss: 0.0203 - acc: 0.9955 - val_loss: 0.0422 - val_acc: 0.9866\n",
      "Epoch 373/800\n",
      "445/445 [==============================] - 0s 312us/sample - loss: 0.0207 - acc: 0.9910 - val_loss: 0.0416 - val_acc: 0.9866\n",
      "Epoch 374/800\n",
      "445/445 [==============================] - 0s 307us/sample - loss: 0.0204 - acc: 0.9955 - val_loss: 0.0411 - val_acc: 0.9866\n",
      "Epoch 375/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9866\n",
      "Epoch 376/800\n",
      "445/445 [==============================] - 0s 260us/sample - loss: 0.0247 - acc: 0.9933 - val_loss: 0.0408 - val_acc: 0.9866\n",
      "Epoch 377/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.0285 - acc: 0.9888 - val_loss: 0.0408 - val_acc: 0.9866\n",
      "Epoch 378/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.0234 - acc: 0.9910 - val_loss: 0.0404 - val_acc: 0.9866\n",
      "Epoch 379/800\n",
      "445/445 [==============================] - 0s 309us/sample - loss: 0.0237 - acc: 0.9910 - val_loss: 0.0398 - val_acc: 0.9866\n",
      "Epoch 380/800\n",
      "445/445 [==============================] - 0s 338us/sample - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0392 - val_acc: 0.9866\n",
      "Epoch 381/800\n",
      "445/445 [==============================] - 0s 303us/sample - loss: 0.0182 - acc: 0.9955 - val_loss: 0.0388 - val_acc: 0.9866\n",
      "Epoch 382/800\n",
      "445/445 [==============================] - 0s 301us/sample - loss: 0.0178 - acc: 0.9978 - val_loss: 0.0384 - val_acc: 0.9866\n",
      "Epoch 383/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0235 - acc: 0.9933 - val_loss: 0.0380 - val_acc: 0.9866\n",
      "Epoch 384/800\n",
      "445/445 [==============================] - 0s 314us/sample - loss: 0.0180 - acc: 0.9955 - val_loss: 0.0378 - val_acc: 0.9933\n",
      "Epoch 385/800\n",
      "445/445 [==============================] - 0s 310us/sample - loss: 0.0253 - acc: 0.9955 - val_loss: 0.0376 - val_acc: 0.9933\n",
      "Epoch 386/800\n",
      "445/445 [==============================] - 0s 314us/sample - loss: 0.0228 - acc: 0.9955 - val_loss: 0.0374 - val_acc: 0.9933\n",
      "Epoch 387/800\n",
      "445/445 [==============================] - 0s 301us/sample - loss: 0.0237 - acc: 0.9978 - val_loss: 0.0370 - val_acc: 0.9933\n",
      "Epoch 388/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.0158 - acc: 0.9978 - val_loss: 0.0362 - val_acc: 0.9933\n",
      "Epoch 389/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.0148 - acc: 0.9978 - val_loss: 0.0353 - val_acc: 0.9933\n",
      "Epoch 390/800\n",
      "445/445 [==============================] - 0s 301us/sample - loss: 0.0178 - acc: 0.9955 - val_loss: 0.0344 - val_acc: 0.9933\n",
      "Epoch 391/800\n",
      "445/445 [==============================] - 0s 294us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9933\n",
      "Epoch 392/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.0348 - acc: 0.9955 - val_loss: 0.0335 - val_acc: 0.9933\n",
      "Epoch 393/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9933\n",
      "Epoch 394/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 0.9933\n",
      "Epoch 395/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.0138 - acc: 0.9978 - val_loss: 0.0337 - val_acc: 0.9933\n",
      "Epoch 396/800\n",
      "445/445 [==============================] - 0s 252us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 0.9933\n",
      "Epoch 397/800\n",
      "445/445 [==============================] - 0s 266us/sample - loss: 0.0139 - acc: 0.9978 - val_loss: 0.0342 - val_acc: 0.9933\n",
      "Epoch 398/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0193 - acc: 0.9933 - val_loss: 0.0342 - val_acc: 0.9933\n",
      "Epoch 399/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9933\n",
      "Epoch 400/800\n",
      "445/445 [==============================] - 0s 243us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9933\n",
      "Epoch 401/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 0.9933\n",
      "Epoch 402/800\n",
      "445/445 [==============================] - 0s 280us/sample - loss: 0.0142 - acc: 0.9955 - val_loss: 0.0395 - val_acc: 0.9866\n",
      "Epoch 403/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0588 - val_acc: 0.9866\n",
      "Epoch 404/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.0127 - acc: 0.9978 - val_loss: 0.0689 - val_acc: 0.9866\n",
      "Epoch 405/800\n",
      "445/445 [==============================] - 0s 224us/sample - loss: 0.0148 - acc: 0.9978 - val_loss: 0.0726 - val_acc: 0.9866\n",
      "Epoch 406/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.0125 - acc: 0.9978 - val_loss: 0.0736 - val_acc: 0.9866\n",
      "Epoch 407/800\n",
      "445/445 [==============================] - 0s 263us/sample - loss: 0.0167 - acc: 0.9978 - val_loss: 0.0728 - val_acc: 0.9866\n",
      "Epoch 408/800\n",
      "445/445 [==============================] - 0s 246us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 0.9866\n",
      "Epoch 409/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.0148 - acc: 0.9955 - val_loss: 0.0655 - val_acc: 0.9866\n",
      "Epoch 410/800\n",
      "445/445 [==============================] - 0s 277us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9866\n",
      "Epoch 411/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0346 - acc: 0.9933 - val_loss: 0.0759 - val_acc: 0.9866\n",
      "Epoch 412/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9866\n",
      "Epoch 413/800\n",
      "445/445 [==============================] - 0s 237us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9866\n",
      "Epoch 414/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 232us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9866\n",
      "Epoch 415/800\n",
      "445/445 [==============================] - 0s 252us/sample - loss: 0.0140 - acc: 0.9978 - val_loss: 0.0340 - val_acc: 0.9933\n",
      "Epoch 416/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.0423 - acc: 0.9955 - val_loss: 0.3645 - val_acc: 0.9195\n",
      "Epoch 417/800\n",
      "445/445 [==============================] - 0s 234us/sample - loss: 0.6175 - acc: 0.8719 - val_loss: 0.5660 - val_acc: 0.8456\n",
      "Epoch 418/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.6538 - acc: 0.8584 - val_loss: 0.2761 - val_acc: 0.9396\n",
      "Epoch 419/800\n",
      "445/445 [==============================] - 0s 247us/sample - loss: 0.2758 - acc: 0.9393 - val_loss: 0.6660 - val_acc: 0.9799\n",
      "Epoch 420/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.1727 - acc: 0.9888 - val_loss: 1.0074 - val_acc: 0.9597\n",
      "Epoch 421/800\n",
      "445/445 [==============================] - 0s 265us/sample - loss: 0.3981 - acc: 0.9798 - val_loss: 0.5191 - val_acc: 0.9732\n",
      "Epoch 422/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.1693 - acc: 0.9708 - val_loss: 0.2411 - val_acc: 0.9195\n",
      "Epoch 423/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.1978 - acc: 0.9191 - val_loss: 0.2087 - val_acc: 0.9195\n",
      "Epoch 424/800\n",
      "445/445 [==============================] - 0s 225us/sample - loss: 0.2849 - acc: 0.8899 - val_loss: 0.1979 - val_acc: 0.9128\n",
      "Epoch 425/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.2480 - acc: 0.8966 - val_loss: 0.1664 - val_acc: 0.9396\n",
      "Epoch 426/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.1901 - acc: 0.9281 - val_loss: 0.1729 - val_acc: 0.9664\n",
      "Epoch 427/800\n",
      "445/445 [==============================] - 0s 225us/sample - loss: 0.1515 - acc: 0.9618 - val_loss: 0.2215 - val_acc: 0.9732\n",
      "Epoch 428/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.1661 - acc: 0.9820 - val_loss: 0.2287 - val_acc: 0.9732\n",
      "Epoch 429/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.1409 - acc: 0.9865 - val_loss: 0.1685 - val_acc: 0.9933\n",
      "Epoch 430/800\n",
      "445/445 [==============================] - 0s 223us/sample - loss: 0.0841 - acc: 0.9888 - val_loss: 0.0989 - val_acc: 0.9933\n",
      "Epoch 431/800\n",
      "445/445 [==============================] - 0s 266us/sample - loss: 0.0858 - acc: 0.9843 - val_loss: 0.0776 - val_acc: 0.9933\n",
      "Epoch 432/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0637 - acc: 0.9888 - val_loss: 0.0715 - val_acc: 0.9933\n",
      "Epoch 433/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0761 - acc: 0.9798 - val_loss: 0.0670 - val_acc: 0.9933\n",
      "Epoch 434/800\n",
      "445/445 [==============================] - 0s 264us/sample - loss: 0.0523 - acc: 0.9933 - val_loss: 0.0623 - val_acc: 0.9933\n",
      "Epoch 435/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.0654 - acc: 0.9843 - val_loss: 0.0570 - val_acc: 0.9933\n",
      "Epoch 436/800\n",
      "445/445 [==============================] - 0s 265us/sample - loss: 0.0611 - acc: 0.9888 - val_loss: 0.0520 - val_acc: 0.9933\n",
      "Epoch 437/800\n",
      "445/445 [==============================] - 0s 269us/sample - loss: 0.0566 - acc: 0.9910 - val_loss: 0.0489 - val_acc: 0.9933\n",
      "Epoch 438/800\n",
      "445/445 [==============================] - 0s 234us/sample - loss: 0.0595 - acc: 0.9865 - val_loss: 0.0471 - val_acc: 0.9933\n",
      "Epoch 439/800\n",
      "445/445 [==============================] - 0s 284us/sample - loss: 0.0429 - acc: 0.9910 - val_loss: 0.0458 - val_acc: 0.9933\n",
      "Epoch 440/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0448 - acc: 0.9910 - val_loss: 0.0453 - val_acc: 0.9933\n",
      "Epoch 441/800\n",
      "445/445 [==============================] - 0s 253us/sample - loss: 0.0414 - acc: 0.9955 - val_loss: 0.0460 - val_acc: 0.9933\n",
      "Epoch 442/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.0397 - acc: 0.9910 - val_loss: 0.0426 - val_acc: 0.9933\n",
      "Epoch 443/800\n",
      "445/445 [==============================] - 0s 257us/sample - loss: 0.0379 - acc: 0.9933 - val_loss: 0.0399 - val_acc: 0.9933\n",
      "Epoch 444/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0383 - acc: 0.9910 - val_loss: 0.0376 - val_acc: 0.9933\n",
      "Epoch 445/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.0283 - acc: 0.9955 - val_loss: 0.0363 - val_acc: 0.9933\n",
      "Epoch 446/800\n",
      "445/445 [==============================] - 0s 268us/sample - loss: 0.0320 - acc: 0.9910 - val_loss: 0.0355 - val_acc: 0.9933\n",
      "Epoch 447/800\n",
      "445/445 [==============================] - 0s 307us/sample - loss: 0.0240 - acc: 0.9978 - val_loss: 0.0350 - val_acc: 0.9933\n",
      "Epoch 448/800\n",
      "445/445 [==============================] - 0s 280us/sample - loss: 0.0291 - acc: 0.9978 - val_loss: 0.0344 - val_acc: 0.9933\n",
      "Epoch 449/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0220 - acc: 0.9955 - val_loss: 0.0335 - val_acc: 0.9933\n",
      "Epoch 450/800\n",
      "445/445 [==============================] - 0s 374us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 0.9933\n",
      "Epoch 451/800\n",
      "445/445 [==============================] - 0s 379us/sample - loss: 0.0237 - acc: 0.9978 - val_loss: 0.0323 - val_acc: 0.9933\n",
      "Epoch 452/800\n",
      "445/445 [==============================] - 0s 299us/sample - loss: 0.0251 - acc: 0.9933 - val_loss: 0.0316 - val_acc: 0.9933\n",
      "Epoch 453/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.0284 - acc: 0.9933 - val_loss: 0.0310 - val_acc: 0.9933\n",
      "Epoch 454/800\n",
      "445/445 [==============================] - 0s 303us/sample - loss: 0.0276 - acc: 0.9978 - val_loss: 0.0305 - val_acc: 0.9933\n",
      "Epoch 455/800\n",
      "445/445 [==============================] - 0s 326us/sample - loss: 0.0275 - acc: 0.9955 - val_loss: 0.0298 - val_acc: 0.9933\n",
      "Epoch 456/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0404 - acc: 0.9955 - val_loss: 0.0292 - val_acc: 0.9933\n",
      "Epoch 457/800\n",
      "445/445 [==============================] - 0s 307us/sample - loss: 0.0252 - acc: 0.9933 - val_loss: 0.0286 - val_acc: 0.9933\n",
      "Epoch 458/800\n",
      "445/445 [==============================] - 0s 317us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 0.9933\n",
      "Epoch 459/800\n",
      "445/445 [==============================] - 0s 321us/sample - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0271 - val_acc: 0.9933\n",
      "Epoch 460/800\n",
      "445/445 [==============================] - 0s 300us/sample - loss: 0.0247 - acc: 0.9955 - val_loss: 0.0264 - val_acc: 0.9933\n",
      "Epoch 461/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0224 - acc: 0.9955 - val_loss: 0.0257 - val_acc: 0.9933\n",
      "Epoch 462/800\n",
      "445/445 [==============================] - 0s 299us/sample - loss: 0.0299 - acc: 0.9933 - val_loss: 0.0251 - val_acc: 0.9933\n",
      "Epoch 463/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0178 - acc: 0.9978 - val_loss: 0.0246 - val_acc: 0.9933\n",
      "Epoch 464/800\n",
      "445/445 [==============================] - 0s 307us/sample - loss: 0.0212 - acc: 0.9978 - val_loss: 0.0241 - val_acc: 0.9933\n",
      "Epoch 465/800\n",
      "445/445 [==============================] - 0s 297us/sample - loss: 0.0214 - acc: 0.9955 - val_loss: 0.0239 - val_acc: 0.9933\n",
      "Epoch 466/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.0173 - acc: 0.9978 - val_loss: 0.0235 - val_acc: 0.9933\n",
      "Epoch 467/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0232 - acc: 0.9955 - val_loss: 0.0234 - val_acc: 0.9933\n",
      "Epoch 468/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.0178 - acc: 0.9978 - val_loss: 0.0237 - val_acc: 0.9933\n",
      "Epoch 469/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.0178 - acc: 0.9978 - val_loss: 0.0229 - val_acc: 0.9933\n",
      "Epoch 470/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0325 - acc: 0.9955 - val_loss: 0.0231 - val_acc: 0.9933\n",
      "Epoch 471/800\n",
      "445/445 [==============================] - 0s 247us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9933\n",
      "Epoch 472/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.0174 - acc: 0.9978 - val_loss: 0.0233 - val_acc: 0.9933\n",
      "Epoch 473/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 244us/sample - loss: 0.0223 - acc: 0.9933 - val_loss: 0.0233 - val_acc: 0.9933\n",
      "Epoch 474/800\n",
      "445/445 [==============================] - 0s 261us/sample - loss: 0.0119 - acc: 0.9978 - val_loss: 0.0233 - val_acc: 0.9933\n",
      "Epoch 475/800\n",
      "445/445 [==============================] - 0s 253us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9933\n",
      "Epoch 476/800\n",
      "445/445 [==============================] - 0s 225us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9933\n",
      "Epoch 477/800\n",
      "445/445 [==============================] - 0s 264us/sample - loss: 0.0147 - acc: 0.9933 - val_loss: 0.0236 - val_acc: 0.9933\n",
      "Epoch 478/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.0235 - acc: 0.9978 - val_loss: 0.0238 - val_acc: 0.9933\n",
      "Epoch 479/800\n",
      "445/445 [==============================] - 0s 245us/sample - loss: 0.0171 - acc: 0.9978 - val_loss: 0.0237 - val_acc: 0.9933\n",
      "Epoch 480/800\n",
      "445/445 [==============================] - 0s 246us/sample - loss: 0.0176 - acc: 0.9933 - val_loss: 0.0234 - val_acc: 0.9933\n",
      "Epoch 481/800\n",
      "445/445 [==============================] - 0s 273us/sample - loss: 0.0147 - acc: 0.9978 - val_loss: 0.0231 - val_acc: 0.9933\n",
      "Epoch 482/800\n",
      "445/445 [==============================] - 0s 283us/sample - loss: 0.0168 - acc: 0.9978 - val_loss: 0.0226 - val_acc: 0.9933\n",
      "Epoch 483/800\n",
      "445/445 [==============================] - 0s 336us/sample - loss: 0.0209 - acc: 0.9955 - val_loss: 0.0222 - val_acc: 0.9933\n",
      "Epoch 484/800\n",
      "445/445 [==============================] - 0s 292us/sample - loss: 0.0170 - acc: 0.9933 - val_loss: 0.0216 - val_acc: 0.9933\n",
      "Epoch 485/800\n",
      "445/445 [==============================] - 0s 329us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 0.9933\n",
      "Epoch 486/800\n",
      "445/445 [==============================] - 0s 286us/sample - loss: 0.0198 - acc: 0.9978 - val_loss: 0.0207 - val_acc: 0.9933\n",
      "Epoch 487/800\n",
      "445/445 [==============================] - 0s 310us/sample - loss: 0.0179 - acc: 0.9955 - val_loss: 0.0203 - val_acc: 0.9933\n",
      "Epoch 488/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0159 - acc: 0.9933 - val_loss: 0.0197 - val_acc: 0.9933\n",
      "Epoch 489/800\n",
      "445/445 [==============================] - 0s 304us/sample - loss: 0.0155 - acc: 0.9978 - val_loss: 0.0190 - val_acc: 0.9933\n",
      "Epoch 490/800\n",
      "445/445 [==============================] - 0s 319us/sample - loss: 0.0177 - acc: 0.9955 - val_loss: 0.0183 - val_acc: 0.9933\n",
      "Epoch 491/800\n",
      "445/445 [==============================] - 0s 315us/sample - loss: 0.0179 - acc: 0.9933 - val_loss: 0.0176 - val_acc: 0.9933\n",
      "Epoch 492/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.0152 - acc: 0.9978 - val_loss: 0.0169 - val_acc: 0.9933\n",
      "Epoch 493/800\n",
      "445/445 [==============================] - 0s 298us/sample - loss: 0.0199 - acc: 0.9978 - val_loss: 0.0163 - val_acc: 0.9933\n",
      "Epoch 494/800\n",
      "445/445 [==============================] - 0s 307us/sample - loss: 0.0143 - acc: 0.9978 - val_loss: 0.0157 - val_acc: 0.9933\n",
      "Epoch 495/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0152 - val_acc: 0.9933\n",
      "Epoch 496/800\n",
      "445/445 [==============================] - 0s 318us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9933\n",
      "Epoch 497/800\n",
      "445/445 [==============================] - 0s 291us/sample - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0144 - val_acc: 0.9933\n",
      "Epoch 498/800\n",
      "445/445 [==============================] - 0s 312us/sample - loss: 0.0110 - acc: 0.9978 - val_loss: 0.0141 - val_acc: 0.9933\n",
      "Epoch 499/800\n",
      "445/445 [==============================] - 0s 290us/sample - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0139 - val_acc: 0.9933\n",
      "Epoch 500/800\n",
      "445/445 [==============================] - 0s 289us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9933\n",
      "Epoch 501/800\n",
      "445/445 [==============================] - 0s 264us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9933\n",
      "Epoch 502/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0149 - acc: 0.9978 - val_loss: 0.0138 - val_acc: 0.9933\n",
      "Epoch 503/800\n",
      "445/445 [==============================] - 0s 244us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 0.9933\n",
      "Epoch 504/800\n",
      "445/445 [==============================] - 0s 220us/sample - loss: 0.0114 - acc: 0.9978 - val_loss: 0.0149 - val_acc: 0.9933\n",
      "Epoch 505/800\n",
      "445/445 [==============================] - 0s 225us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 0.9933\n",
      "Epoch 506/800\n",
      "445/445 [==============================] - 0s 282us/sample - loss: 0.0173 - acc: 0.9978 - val_loss: 0.0159 - val_acc: 0.9933\n",
      "Epoch 507/800\n",
      "445/445 [==============================] - 0s 269us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9933\n",
      "Epoch 508/800\n",
      "445/445 [==============================] - 0s 244us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9933\n",
      "Epoch 509/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0148 - acc: 0.9978 - val_loss: 0.0170 - val_acc: 0.9933\n",
      "Epoch 510/800\n",
      "445/445 [==============================] - 0s 223us/sample - loss: 0.0105 - acc: 0.9978 - val_loss: 0.0172 - val_acc: 0.9933\n",
      "Epoch 511/800\n",
      "445/445 [==============================] - 0s 269us/sample - loss: 0.0130 - acc: 0.9955 - val_loss: 0.0170 - val_acc: 0.9933\n",
      "Epoch 512/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0119 - acc: 0.9955 - val_loss: 0.0163 - val_acc: 0.9933\n",
      "Epoch 513/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0157 - val_acc: 0.9933\n",
      "Epoch 514/800\n",
      "445/445 [==============================] - 0s 251us/sample - loss: 0.0132 - acc: 0.9978 - val_loss: 0.0153 - val_acc: 0.9933\n",
      "Epoch 515/800\n",
      "445/445 [==============================] - 0s 243us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9933\n",
      "Epoch 516/800\n",
      "445/445 [==============================] - 0s 222us/sample - loss: 0.0084 - acc: 0.9978 - val_loss: 0.0144 - val_acc: 0.9933\n",
      "Epoch 517/800\n",
      "445/445 [==============================] - 0s 244us/sample - loss: 0.0141 - acc: 0.9978 - val_loss: 0.0138 - val_acc: 0.9933\n",
      "Epoch 518/800\n",
      "445/445 [==============================] - 0s 307us/sample - loss: 0.0209 - acc: 0.9955 - val_loss: 0.0129 - val_acc: 0.9933\n",
      "Epoch 519/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0163 - acc: 0.9978 - val_loss: 0.0121 - val_acc: 0.9933\n",
      "Epoch 520/800\n",
      "445/445 [==============================] - 0s 293us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9933\n",
      "Epoch 521/800\n",
      "445/445 [==============================] - 0s 282us/sample - loss: 0.0106 - acc: 0.9955 - val_loss: 0.0115 - val_acc: 0.9933\n",
      "Epoch 522/800\n",
      "445/445 [==============================] - 0s 357us/sample - loss: 0.0094 - acc: 0.9955 - val_loss: 0.0111 - val_acc: 0.9933\n",
      "Epoch 523/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9933\n",
      "Epoch 524/800\n",
      "445/445 [==============================] - 0s 290us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9933\n",
      "Epoch 525/800\n",
      "445/445 [==============================] - 0s 246us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9933\n",
      "Epoch 526/800\n",
      "445/445 [==============================] - 0s 222us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9933\n",
      "Epoch 527/800\n",
      "445/445 [==============================] - 0s 224us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9933\n",
      "Epoch 528/800\n",
      "445/445 [==============================] - 0s 271us/sample - loss: 0.0109 - acc: 0.9978 - val_loss: 0.0118 - val_acc: 0.9933\n",
      "Epoch 529/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0104 - acc: 0.9978 - val_loss: 0.0122 - val_acc: 0.9933\n",
      "Epoch 530/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9933\n",
      "Epoch 531/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9933\n",
      "Epoch 532/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 274us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9933\n",
      "Epoch 533/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9933\n",
      "Epoch 534/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0116 - acc: 0.9955 - val_loss: 0.0122 - val_acc: 0.9933\n",
      "Epoch 535/800\n",
      "445/445 [==============================] - 0s 220us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9933\n",
      "Epoch 536/800\n",
      "445/445 [==============================] - 0s 318us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9933\n",
      "Epoch 537/800\n",
      "445/445 [==============================] - 0s 231us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9933\n",
      "Epoch 538/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0113 - val_acc: 0.9933\n",
      "Epoch 539/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9933\n",
      "Epoch 540/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9933\n",
      "Epoch 541/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9933\n",
      "Epoch 542/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0121 - val_acc: 0.9933\n",
      "Epoch 543/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9933\n",
      "Epoch 544/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0102 - acc: 0.9978 - val_loss: 0.0110 - val_acc: 0.9933\n",
      "Epoch 545/800\n",
      "445/445 [==============================] - 0s 309us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9933\n",
      "Epoch 546/800\n",
      "445/445 [==============================] - 0s 321us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9933\n",
      "Epoch 547/800\n",
      "445/445 [==============================] - 0s 316us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9933\n",
      "Epoch 548/800\n",
      "445/445 [==============================] - 0s 322us/sample - loss: 0.0127 - acc: 0.9978 - val_loss: 0.0087 - val_acc: 0.9933\n",
      "Epoch 549/800\n",
      "445/445 [==============================] - 0s 301us/sample - loss: 0.0112 - acc: 0.9978 - val_loss: 0.0083 - val_acc: 0.9933\n",
      "Epoch 550/800\n",
      "445/445 [==============================] - 0s 224us/sample - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0083 - val_acc: 0.9933\n",
      "Epoch 551/800\n",
      "445/445 [==============================] - 0s 352us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9933\n",
      "Epoch 552/800\n",
      "445/445 [==============================] - 0s 288us/sample - loss: 0.0087 - acc: 0.9955 - val_loss: 0.0078 - val_acc: 0.9933\n",
      "Epoch 553/800\n",
      "445/445 [==============================] - 0s 355us/sample - loss: 0.0084 - acc: 0.9978 - val_loss: 0.0074 - val_acc: 0.9933\n",
      "Epoch 554/800\n",
      "445/445 [==============================] - 0s 315us/sample - loss: 0.0184 - acc: 0.9978 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 555/800\n",
      "445/445 [==============================] - 0s 323us/sample - loss: 0.0060 - acc: 0.9978 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 556/800\n",
      "445/445 [==============================] - 0s 291us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 557/800\n",
      "445/445 [==============================] - 0s 336us/sample - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 558/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 559/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0077 - acc: 0.9955 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 560/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 561/800\n",
      "445/445 [==============================] - 0s 247us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9933\n",
      "Epoch 562/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9933\n",
      "Epoch 563/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0157 - acc: 0.9933 - val_loss: 0.0140 - val_acc: 0.9933\n",
      "Epoch 564/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0150 - val_acc: 0.9933\n",
      "Epoch 565/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0121 - acc: 0.9978 - val_loss: 0.0154 - val_acc: 0.9933\n",
      "Epoch 566/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0062 - acc: 0.9978 - val_loss: 0.0155 - val_acc: 0.9933\n",
      "Epoch 567/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9933\n",
      "Epoch 568/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0121 - acc: 0.9978 - val_loss: 0.0150 - val_acc: 0.9933\n",
      "Epoch 569/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 0.9933\n",
      "Epoch 570/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9933\n",
      "Epoch 571/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9933\n",
      "Epoch 572/800\n",
      "445/445 [==============================] - 0s 273us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 0.9933\n",
      "Epoch 573/800\n",
      "445/445 [==============================] - 0s 249us/sample - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0141 - val_acc: 0.9933\n",
      "Epoch 574/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9933\n",
      "Epoch 575/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9933\n",
      "Epoch 576/800\n",
      "445/445 [==============================] - 0s 256us/sample - loss: 0.0061 - acc: 0.9978 - val_loss: 0.0134 - val_acc: 0.9933\n",
      "Epoch 577/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9933\n",
      "Epoch 578/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9933\n",
      "Epoch 579/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9933\n",
      "Epoch 580/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9933\n",
      "Epoch 581/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9933\n",
      "Epoch 582/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0062 - acc: 0.9978 - val_loss: 0.0111 - val_acc: 0.9933\n",
      "Epoch 583/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9933\n",
      "Epoch 584/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9933\n",
      "Epoch 585/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.0045 - acc: 0.9978 - val_loss: 0.0097 - val_acc: 0.9933\n",
      "Epoch 586/800\n",
      "445/445 [==============================] - 0s 262us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9933\n",
      "Epoch 587/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9933\n",
      "Epoch 588/800\n",
      "445/445 [==============================] - 0s 234us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9933\n",
      "Epoch 589/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9933\n",
      "Epoch 590/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9933\n",
      "Epoch 591/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 261us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9933\n",
      "Epoch 592/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9933\n",
      "Epoch 593/800\n",
      "445/445 [==============================] - 0s 267us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9933\n",
      "Epoch 594/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9933\n",
      "Epoch 595/800\n",
      "445/445 [==============================] - 0s 239us/sample - loss: 0.0075 - acc: 0.9955 - val_loss: 0.0084 - val_acc: 0.9933\n",
      "Epoch 596/800\n",
      "445/445 [==============================] - 0s 237us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9933\n",
      "Epoch 597/800\n",
      "445/445 [==============================] - 0s 245us/sample - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0075 - val_acc: 0.9933\n",
      "Epoch 598/800\n",
      "445/445 [==============================] - 0s 266us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9933\n",
      "Epoch 599/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9933\n",
      "Epoch 600/800\n",
      "445/445 [==============================] - 0s 357us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9933\n",
      "Epoch 601/800\n",
      "445/445 [==============================] - 0s 289us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 602/800\n",
      "445/445 [==============================] - 0s 339us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 603/800\n",
      "445/445 [==============================] - 0s 285us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 604/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 605/800\n",
      "445/445 [==============================] - 0s 330us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 606/800\n",
      "445/445 [==============================] - 0s 287us/sample - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 607/800\n",
      "445/445 [==============================] - 0s 329us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 608/800\n",
      "445/445 [==============================] - 0s 223us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 609/800\n",
      "445/445 [==============================] - 0s 277us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 610/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 611/800\n",
      "445/445 [==============================] - 0s 256us/sample - loss: 0.0053 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 612/800\n",
      "445/445 [==============================] - 0s 250us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 613/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 614/800\n",
      "445/445 [==============================] - 0s 262us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 615/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 616/800\n",
      "445/445 [==============================] - 0s 225us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 617/800\n",
      "445/445 [==============================] - 0s 277us/sample - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 618/800\n",
      "445/445 [==============================] - 0s 251us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 619/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 620/800\n",
      "445/445 [==============================] - 0s 250us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 621/800\n",
      "445/445 [==============================] - 0s 331us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 622/800\n",
      "445/445 [==============================] - 0s 335us/sample - loss: 0.0043 - acc: 0.9978 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 623/800\n",
      "445/445 [==============================] - 0s 305us/sample - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 624/800\n",
      "445/445 [==============================] - 0s 293us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 625/800\n",
      "445/445 [==============================] - 0s 272us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 626/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 627/800\n",
      "445/445 [==============================] - 0s 239us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 628/800\n",
      "445/445 [==============================] - 0s 237us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 629/800\n",
      "445/445 [==============================] - 0s 256us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 630/800\n",
      "445/445 [==============================] - 0s 255us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 631/800\n",
      "445/445 [==============================] - 0s 243us/sample - loss: 0.0041 - acc: 0.9978 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 632/800\n",
      "445/445 [==============================] - 0s 264us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 633/800\n",
      "445/445 [==============================] - 0s 245us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 634/800\n",
      "445/445 [==============================] - 0s 252us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 635/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0036 - acc: 0.9978 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 636/800\n",
      "445/445 [==============================] - 0s 325us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 637/800\n",
      "445/445 [==============================] - 0s 311us/sample - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 638/800\n",
      "445/445 [==============================] - 0s 306us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 639/800\n",
      "445/445 [==============================] - 0s 323us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 640/800\n",
      "445/445 [==============================] - 0s 343us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 641/800\n",
      "445/445 [==============================] - 0s 319us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 642/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 643/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 644/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 645/800\n",
      "445/445 [==============================] - 0s 274us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 646/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 647/800\n",
      "445/445 [==============================] - 0s 264us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 648/800\n",
      "445/445 [==============================] - 0s 283us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 649/800\n",
      "445/445 [==============================] - 0s 245us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 650/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 266us/sample - loss: 0.0252 - acc: 0.9978 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 651/800\n",
      "445/445 [==============================] - 0s 247us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 652/800\n",
      "445/445 [==============================] - 0s 292us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 653/800\n",
      "445/445 [==============================] - 0s 249us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 654/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9933\n",
      "Epoch 655/800\n",
      "445/445 [==============================] - 0s 276us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9933\n",
      "Epoch 656/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9933\n",
      "Epoch 657/800\n",
      "445/445 [==============================] - 0s 252us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9933\n",
      "Epoch 658/800\n",
      "445/445 [==============================] - 0s 254us/sample - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 659/800\n",
      "445/445 [==============================] - 0s 247us/sample - loss: 0.0058 - acc: 0.9978 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 660/800\n",
      "445/445 [==============================] - 0s 257us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 661/800\n",
      "445/445 [==============================] - 0s 261us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 662/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0090 - acc: 0.9955 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 663/800\n",
      "445/445 [==============================] - 0s 325us/sample - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 664/800\n",
      "445/445 [==============================] - 0s 318us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 665/800\n",
      "445/445 [==============================] - 0s 329us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 666/800\n",
      "445/445 [==============================] - 0s 315us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 667/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 668/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 669/800\n",
      "445/445 [==============================] - 0s 255us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 670/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 671/800\n",
      "445/445 [==============================] - 0s 268us/sample - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 672/800\n",
      "445/445 [==============================] - 0s 248us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 673/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 674/800\n",
      "445/445 [==============================] - 0s 272us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 675/800\n",
      "445/445 [==============================] - 0s 246us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 676/800\n",
      "445/445 [==============================] - 0s 263us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 677/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 678/800\n",
      "445/445 [==============================] - 0s 232us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 679/800\n",
      "445/445 [==============================] - 0s 293us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 680/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 681/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 682/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 683/800\n",
      "445/445 [==============================] - 0s 264us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 684/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 685/800\n",
      "445/445 [==============================] - 0s 238us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 686/800\n",
      "445/445 [==============================] - 0s 257us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9933\n",
      "Epoch 687/800\n",
      "445/445 [==============================] - 0s 254us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9933\n",
      "Epoch 688/800\n",
      "445/445 [==============================] - 0s 275us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9933\n",
      "Epoch 689/800\n",
      "445/445 [==============================] - 0s 251us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9933\n",
      "Epoch 690/800\n",
      "445/445 [==============================] - 0s 273us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9933\n",
      "Epoch 691/800\n",
      "445/445 [==============================] - 0s 273us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9933\n",
      "Epoch 692/800\n",
      "445/445 [==============================] - 0s 271us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 693/800\n",
      "445/445 [==============================] - 0s 282us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 694/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 695/800\n",
      "445/445 [==============================] - 0s 258us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 696/800\n",
      "445/445 [==============================] - 0s 221us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 697/800\n",
      "445/445 [==============================] - 0s 235us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 698/800\n",
      "445/445 [==============================] - 0s 261us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 699/800\n",
      "445/445 [==============================] - 0s 265us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 700/800\n",
      "445/445 [==============================] - 0s 219us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 701/800\n",
      "445/445 [==============================] - 0s 222us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 702/800\n",
      "445/445 [==============================] - 0s 263us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 703/800\n",
      "445/445 [==============================] - 0s 249us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 704/800\n",
      "445/445 [==============================] - 0s 246us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 705/800\n",
      "445/445 [==============================] - 0s 274us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 706/800\n",
      "445/445 [==============================] - 0s 240us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 707/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 708/800\n",
      "445/445 [==============================] - 0s 221us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 709/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 0s 273us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 710/800\n",
      "445/445 [==============================] - 0s 281us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9933\n",
      "Epoch 711/800\n",
      "445/445 [==============================] - 0s 249us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9933\n",
      "Epoch 712/800\n",
      "445/445 [==============================] - 0s 262us/sample - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0070 - val_acc: 0.9933\n",
      "Epoch 713/800\n",
      "445/445 [==============================] - 0s 268us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9933\n",
      "Epoch 714/800\n",
      "445/445 [==============================] - 0s 222us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9933\n",
      "Epoch 715/800\n",
      "445/445 [==============================] - 0s 264us/sample - loss: 0.0042 - acc: 0.9978 - val_loss: 0.0060 - val_acc: 0.9933\n",
      "Epoch 716/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.0050 - acc: 0.9978 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 717/800\n",
      "445/445 [==============================] - 0s 269us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 718/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 719/800\n",
      "445/445 [==============================] - 0s 258us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 720/800\n",
      "445/445 [==============================] - 0s 255us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 721/800\n",
      "445/445 [==============================] - 0s 222us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 722/800\n",
      "445/445 [==============================] - 0s 280us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 723/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 724/800\n",
      "445/445 [==============================] - 0s 277us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 725/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 726/800\n",
      "445/445 [==============================] - 0s 329us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 727/800\n",
      "445/445 [==============================] - 0s 286us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 728/800\n",
      "445/445 [==============================] - 0s 336us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 729/800\n",
      "445/445 [==============================] - 0s 245us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 730/800\n",
      "445/445 [==============================] - 0s 219us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 731/800\n",
      "445/445 [==============================] - 0s 230us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 732/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 733/800\n",
      "445/445 [==============================] - 0s 286us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 734/800\n",
      "445/445 [==============================] - 0s 234us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 735/800\n",
      "445/445 [==============================] - 0s 261us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 736/800\n",
      "445/445 [==============================] - 0s 229us/sample - loss: 0.0043 - acc: 0.9978 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 737/800\n",
      "445/445 [==============================] - 0s 283us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 738/800\n",
      "445/445 [==============================] - 0s 244us/sample - loss: 0.0038 - acc: 0.9978 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 739/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 740/800\n",
      "445/445 [==============================] - 0s 234us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 741/800\n",
      "445/445 [==============================] - 0s 246us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 742/800\n",
      "445/445 [==============================] - 0s 282us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 743/800\n",
      "445/445 [==============================] - 0s 266us/sample - loss: 8.8162e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 744/800\n",
      "445/445 [==============================] - 0s 314us/sample - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 745/800\n",
      "445/445 [==============================] - 0s 335us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 746/800\n",
      "445/445 [==============================] - 0s 303us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 747/800\n",
      "445/445 [==============================] - 0s 296us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 748/800\n",
      "445/445 [==============================] - 0s 349us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 749/800\n",
      "445/445 [==============================] - 0s 224us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 750/800\n",
      "445/445 [==============================] - 0s 265us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 751/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 752/800\n",
      "445/445 [==============================] - 0s 271us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 753/800\n",
      "445/445 [==============================] - 0s 226us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 754/800\n",
      "445/445 [==============================] - 0s 269us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 755/800\n",
      "445/445 [==============================] - 0s 243us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 756/800\n",
      "445/445 [==============================] - 0s 231us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 757/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 8.4433e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 758/800\n",
      "445/445 [==============================] - 0s 245us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 759/800\n",
      "445/445 [==============================] - 0s 254us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 760/800\n",
      "445/445 [==============================] - 0s 263us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 761/800\n",
      "445/445 [==============================] - 0s 259us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 762/800\n",
      "445/445 [==============================] - 0s 227us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 763/800\n",
      "445/445 [==============================] - 0s 272us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 764/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 765/800\n",
      "445/445 [==============================] - 0s 267us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 766/800\n",
      "445/445 [==============================] - 0s 258us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 767/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.0029 - acc: 0.9978 - val_loss: 0.0030 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/800\n",
      "445/445 [==============================] - 0s 277us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 769/800\n",
      "445/445 [==============================] - 0s 276us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 770/800\n",
      "445/445 [==============================] - 0s 228us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 771/800\n",
      "445/445 [==============================] - 0s 219us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 772/800\n",
      "445/445 [==============================] - 0s 261us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 773/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 774/800\n",
      "445/445 [==============================] - 0s 286us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 775/800\n",
      "445/445 [==============================] - 0s 270us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 776/800\n",
      "445/445 [==============================] - 0s 247us/sample - loss: 0.0038 - acc: 0.9978 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 777/800\n",
      "445/445 [==============================] - 0s 281us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 778/800\n",
      "445/445 [==============================] - 0s 261us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 779/800\n",
      "445/445 [==============================] - 0s 236us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 780/800\n",
      "445/445 [==============================] - 0s 267us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 781/800\n",
      "445/445 [==============================] - 0s 356us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 782/800\n",
      "445/445 [==============================] - 0s 290us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 783/800\n",
      "445/445 [==============================] - 0s 320us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 784/800\n",
      "445/445 [==============================] - 0s 318us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 785/800\n",
      "445/445 [==============================] - 0s 330us/sample - loss: 9.9526e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 786/800\n",
      "445/445 [==============================] - 0s 289us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 787/800\n",
      "445/445 [==============================] - 0s 324us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 788/800\n",
      "445/445 [==============================] - 0s 325us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 789/800\n",
      "445/445 [==============================] - 0s 295us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 790/800\n",
      "445/445 [==============================] - 0s 321us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 791/800\n",
      "445/445 [==============================] - 0s 302us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 792/800\n",
      "445/445 [==============================] - 0s 338us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 793/800\n",
      "445/445 [==============================] - 0s 290us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 9.8397e-04 - val_acc: 1.0000\n",
      "Epoch 794/800\n",
      "445/445 [==============================] - 0s 350us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 9.6625e-04 - val_acc: 1.0000\n",
      "Epoch 795/800\n",
      "445/445 [==============================] - 0s 301us/sample - loss: 8.8216e-04 - acc: 1.0000 - val_loss: 9.6264e-04 - val_acc: 1.0000\n",
      "Epoch 796/800\n",
      "445/445 [==============================] - 0s 241us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 9.7306e-04 - val_acc: 1.0000\n",
      "Epoch 797/800\n",
      "445/445 [==============================] - 0s 272us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 9.7900e-04 - val_acc: 1.0000\n",
      "Epoch 798/800\n",
      "445/445 [==============================] - 0s 250us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 9.8104e-04 - val_acc: 1.0000\n",
      "Epoch 799/800\n",
      "445/445 [==============================] - 0s 242us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 800/800\n",
      "445/445 [==============================] - 0s 233us/sample - loss: 8.4924e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "230/230 [==============================] - 1s 3ms/sample - loss: 1.4861 - acc: 0.8696\n",
      "Accuracy 0.8695652\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "#%%    \n",
    "\n",
    "train_index = train_index1\n",
    "test_index = test_index1\n",
    "#print(train_index)\n",
    "\n",
    "y_train = y_label[train_index]\n",
    "y_test = y_label[test_index]\n",
    "X_kernel_train = data_kernel_group[train_index]\n",
    "X_kernel_test = data_kernel_group[test_index]\n",
    "X_transfer_train = data_transfer_group[train_index]\n",
    "X_transfer_test = data_transfer_group[test_index]\n",
    "\n",
    "\n",
    "data_X = []\n",
    "\n",
    "X_train = [X_kernel_train, X_transfer_train]\n",
    "X_test = [X_kernel_test, X_transfer_test]\n",
    "\n",
    "inputKernel = layers.Input(shape=(max_len,5))\n",
    "inputTransfer = layers.Input(shape=(max_len,4))\n",
    "\n",
    "\n",
    "x = (layers.LSTM(max_len, input_shape=(max_len, 5)))(inputKernel)\n",
    "x = (layers.Dropout(0.2))(x)\n",
    "x = (layers.Dense(8, activation='relu'))(x)\n",
    "x= Model(inputs=inputKernel, outputs=x)\n",
    "\n",
    "\n",
    "y = (layers.LSTM(max_len, input_shape=(max_len, 4)))(inputTransfer)\n",
    "y = (layers.Dropout(0.2))(y)\n",
    "y = (layers.Dense(8, activation='relu'))(y)\n",
    "y = Model(inputs=inputTransfer, outputs=y)\n",
    "\n",
    "\n",
    "combined = layers.concatenate([x.output, y.output])\n",
    "\n",
    "out = layers.Dense(4, activation=\"relu\")(combined)\n",
    "out = layers.Dense(1, activation=\"sigmoid\")(out)\n",
    "\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=out)\n",
    "fileM = \"DoubleLSTM\"\n",
    "checkpoint_path = \"%s/%s-%s.hdf5\"%(arch,fileM ,arch)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                             save_best_only=True,\n",
    "                                             monitor='val_loss', \n",
    "                                             mode='min')\n",
    "model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "hist= model.fit(x=X_train,y=y_train,\n",
    "        epochs=800,\n",
    "        validation_split=0.25,\n",
    "        callbacks = [cp_callback],\n",
    "        batch_size = 256,\n",
    "        class_weight={1:8, 0:1}\n",
    "         )\n",
    "\n",
    "df = pd.DataFrame.from_dict(hist.history)\n",
    "df.to_csv(\"%s/%s-%s-history.csv\"%(arch,fileM ,arch))\n",
    "\n",
    "loss, accuracy = model.evaluate(x=X_test, y=y_test)    \n",
    "print(\"Accuracy\", accuracy)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict_classes(data_X)\n",
    "print(y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5.1.0)",
   "language": "python",
   "name": "anaconda3-5.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
