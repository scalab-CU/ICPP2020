{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start\n",
      "brutehash1 gst_requested_throughput.perf.txt other\n",
      "brutehash1 l2_write_throughput.perf.txt other\n",
      "brutehash1 atomic_transactions_per_request.perf.txt other\n",
      "brutehash2 shared_store_transactions.perf.txt other\n",
      "brutehash2 local_hit_rate.perf.txt other\n",
      "brutehash2 gst_requested_throughput.perf.txt other\n",
      "brutehash2 l2_write_throughput.perf.txt other\n",
      "brutehash2 stall_constant_memory_dependency.perf.txt other\n",
      "brutehash2 atomic_transactions_per_request.perf.txt other\n",
      "brutehash2 half_precision_fu_utilization.perf.txt other\n",
      "brutehash3 shared_store_transactions.perf.txt other\n",
      "brutehash3 gst_requested_throughput.perf.txt other\n",
      "brutehash3 l2_write_throughput.perf.txt other\n",
      "brutehash3 atomic_transactions_per_request.perf.txt other\n",
      "brutehash4 local_hit_rate.perf.txt other\n",
      "brutehash4 gst_requested_throughput.perf.txt other\n",
      "brutehash4 l2_write_throughput.perf.txt other\n",
      "brutehash4 atomic_transactions_per_request.perf.txt other\n",
      "brutehash4 half_precision_fu_utilization.perf.txt other\n",
      "brutehash5 gst_requested_throughput.perf.txt other\n",
      "brutehash5 l2_write_throughput.perf.txt other\n",
      "brutehash5 atomic_transactions_per_request.perf.txt other\n",
      "brutehash5 half_precision_fu_utilization.perf.txt other\n",
      "brutehash6 shared_store_transactions.perf.txt other\n",
      "brutehash6 gst_requested_throughput.perf.txt other\n",
      "brutehash6 l2_write_throughput.perf.txt other\n",
      "brutehash6 stall_constant_memory_dependency.perf.txt other\n",
      "brutehash6 atomic_transactions_per_request.perf.txt other\n",
      "brutehash6 half_precision_fu_utilization.perf.txt other\n",
      "brutehash7 gst_requested_throughput.perf.txt other\n",
      "brutehash7 l2_write_throughput.perf.txt other\n",
      "brutehash7 atomic_transactions_per_request.perf.txt other\n",
      "brutehash7 half_precision_fu_utilization.perf.txt other\n",
      "brutehash8 shared_store_transactions.perf.txt other\n",
      "brutehash8 gst_requested_throughput.perf.txt other\n",
      "brutehash8 l2_write_throughput.perf.txt other\n",
      "brutehash8 atomic_transactions_per_request.perf.txt other\n",
      "brutehash8 half_precision_fu_utilization.perf.txt other\n",
      "brutehash9 gst_requested_throughput.perf.txt other\n",
      "brutehash9 l2_write_throughput.perf.txt other\n",
      "brutehash9 atomic_transactions_per_request.perf.txt other\n",
      "brutehash10 shared_store_transactions\n",
      "brutehash10 gst_requested_throughput.perf.txt other\n",
      "brutehash10 l2_write_throughput.perf.txt other\n",
      "brutehash10 stall_constant_memory_dependency.perf.txt other\n",
      "brutehash10 atomic_transactions_per_request.perf.txt other\n",
      "brutehash10 half_precision_fu_utilization.perf.txt other\n",
      "aes1 gst_requested_throughput\n",
      "aes1 l2_write_throughput\n",
      "aes1 atomic_transactions_per_request\n",
      "aes1 half_precision_fu_utilization\n",
      "aes2 gst_requested_throughput\n",
      "aes2 l2_write_throughput\n",
      "aes2 atomic_transactions_per_request\n",
      "aes3 shared_store_transactions\n",
      "aes3 gst_requested_throughput\n",
      "aes3 l2_write_throughput\n",
      "aes3 stall_constant_memory_dependency\n",
      "aes3 atomic_transactions_per_request\n",
      "aes3 half_precision_fu_utilization\n",
      "aes4 shared_store_transactions\n",
      "aes4 gst_requested_throughput\n",
      "aes4 l2_write_throughput\n",
      "aes4 stall_constant_memory_dependency\n",
      "aes4 atomic_transactions_per_request\n",
      "aes4 half_precision_fu_utilization\n",
      "aes5 shared_store_transactions\n",
      "aes5 gst_requested_throughput\n",
      "aes5 l2_write_throughput\n",
      "aes5 stall_constant_memory_dependency\n",
      "aes5 atomic_transactions_per_request\n",
      "aes5 half_precision_fu_utilization\n",
      "aes6 shared_store_transactions\n",
      "aes6 local_hit_rate\n",
      "aes6 gst_requested_throughput\n",
      "aes6 l2_write_throughput\n",
      "aes6 atomic_transactions_per_request\n",
      "aes6 half_precision_fu_utilization\n",
      "aes7 gst_requested_throughput\n",
      "aes7 l2_write_throughput\n",
      "aes7 stall_constant_memory_dependency\n",
      "aes7 atomic_transactions_per_request\n",
      "aes8 shared_store_transactions\n",
      "aes8 gst_requested_throughput\n",
      "aes8 l2_write_throughput\n",
      "aes8 atomic_transactions_per_request\n",
      "aes8 half_precision_fu_utilization\n",
      "aes9 shared_store_transactions\n",
      "aes9 gst_requested_throughput\n",
      "aes9 l2_write_throughput\n",
      "aes9 atomic_transactions_per_request\n",
      "aes9 half_precision_fu_utilization\n",
      "aes10 gst_requested_throughput\n",
      "aes10 l2_write_throughput\n",
      "aes10 atomic_transactions_per_request\n",
      "aes10 half_precision_fu_utilization\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from decimal import Decimal\n",
    "from csv import reader\n",
    "numeric_const_pattern = r'[-+]? (?: (?: \\d* \\. \\d+ ) | (?: \\d+ \\.? ) )(?: [Ee] [+-]? \\d+ ) ?'\n",
    "rx = re.compile(numeric_const_pattern, re.VERBOSE)\n",
    "\n",
    "def get_metrics_list(fileName):\n",
    "    \"\"\"get metrics list\n",
    "\n",
    "    Arguments:\n",
    "        fileName {string} -- the file name of metric file with absolute path\n",
    "\n",
    "    Returns:\n",
    "        data {list} -- the metric  list\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(fileName) as f:\n",
    "        for line in f.readlines():\n",
    "            if not line.startswith('#'):\n",
    "                metric=line.split(',')[0].strip()\n",
    "                data.append(metric)\n",
    "        f.close()\n",
    "    return data\n",
    "\n",
    "def get_app_list(fileName):\n",
    "    \"\"\"get metrics list\n",
    "\n",
    "    Arguments:\n",
    "        fileName {string} -- the file name of application file with absolute path\n",
    "\n",
    "    Returns:\n",
    "        app {list} -- the app  list\n",
    "    \"\"\"\n",
    "    apps = []\n",
    "    with open(fileName) as f:\n",
    "        for line in f.readlines():\n",
    "            if not line.startswith('#'):\n",
    "                words = line.strip().split(',')\n",
    "                app = words[0].strip()\n",
    "                app_num = words[1].strip()\n",
    "                apps.append(app+app_num)\n",
    "        f.close()\n",
    "    return apps\n",
    "def get_kernel_names(fileName):\n",
    "    \"\"\"Get the list of kernels\n",
    "\n",
    "    Arguments:\n",
    "        fileName {string} -- the file name with absolute path\n",
    "\n",
    "    Returns:\n",
    "        data {list} -- the kernel names list\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(fileName) as f:\n",
    "        lines = f.readlines()\n",
    "        nLine = len(lines)\n",
    "        startX = 0\n",
    "        for line in lines:\n",
    "            if line.rstrip(\"\\r\\n\") == '\"Device\",\"Kernel\",\"Invocations\",\"Metric Name\",\"Metric Description\",\"Min\",\"Max\",\"Avg\"':\n",
    "                break\n",
    "            startX += 1\n",
    "                \n",
    "        if startX == nLine:   \n",
    "            return False\n",
    "        for i in range(startX+1, nLine):\n",
    "            temp = list(reader([lines[i].rstrip(\"\\r\\n\")],delimiter=','))[0]\n",
    "            if len(temp) != 8 and nLine == startX +1:\n",
    "                return False\n",
    "            elif len(temp) != 8:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                data.append(list(reader([lines[i].rstrip(\"\\r\\n\")],delimiter=','))[0][1])\n",
    "        f.close()\n",
    "    return data\n",
    "\n",
    "def perf_read(app_list, metrics, pathfolder, errorFile, outFile):\n",
    "    data = []\n",
    "    errorData = []\n",
    "    for app in app_list:\n",
    "        kernel_list = get_kernel_names(os.path.join(pathfolder, app, \"flop_count_sp_add.perf.txt\"))\n",
    "        if not kernel_list:\n",
    "            print(app)\n",
    "            continue\n",
    "        data_rows = []\n",
    "        for kernel in kernel_list:\n",
    "            temp_row = []\n",
    "            temp_row.append(app)\n",
    "            temp_row.append(kernel)\n",
    "            data_rows.append(temp_row)\n",
    "        for metric in metrics:\n",
    "            metric_file = \"{}.perf.txt\".format(metric)\n",
    "            if not os.path.exists(os.path.join(pathfolder, app, metric_file)):\n",
    "                print(app, metric)\n",
    "                errorData.append([app, metric, \"Non Exist\"])\n",
    "                continue\n",
    "            if os.stat(os.path.join(pathfolder, app, metric_file)).st_size == 0:\n",
    "                print(app, metric)\n",
    "                errorData.append([app, metric, \"Size 0\"])\n",
    "                continue\n",
    "            temp_data, errorRecord = perf_read_C(os.path.join(pathfolder, app, metric_file), len(kernel_list))\n",
    "            if errorRecord != \"No Error\":\n",
    "                errorData.append([app, metric, errorRecord])\n",
    "            for i in range(len(kernel_list)):\n",
    "                data_rows[i].append(temp_data[i])\n",
    "        for i in range(len(kernel_list)):\n",
    "            data.append(data_rows[i])\n",
    "\n",
    "    columns= metrics\n",
    "    columns.insert(0, \"app\")\n",
    "    columns.insert(1, \"kernel\")\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    writer = pd.ExcelWriter(outFile,engine='xlsxwriter')\n",
    "    df.to_excel(writer, sheet_name=\"perf\", index=False)\n",
    "    writer.save()\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data=errorData, columns=[\"app\", \"metric\", \"errorType\"])\n",
    "\n",
    "    df.to_csv(errorFile, index=False)\n",
    "  \n",
    "def perf_read_C(fileName, n):\n",
    "    \"\"\"This is a function to extract GPU metrics from output raw file\n",
    "\n",
    "    Arguments:\n",
    "        fileName {string} -- the file name with absolute path\n",
    "        n {integter} -- the number of kernels for the application\n",
    "\n",
    "    Returns:\n",
    "        data {list} -- the extracted metrics\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    errorRecord = \"Unknown\"\n",
    "    with open(fileName) as f:\n",
    "      \n",
    "\n",
    "        lines = f.readlines()\n",
    "        nLine = len(lines)\n",
    "        if nLine == 1:\n",
    "            if lines[0].rstrip(\"\\r\\n\") == \"======== Error: internal error.\":\n",
    "                #rint(fileName.split(\"/\")[-2],fileName.split(\"/\")[-1], \"Internel error\")\n",
    "                for i in range(0, n):\n",
    "                    data.append('Internal Error')\n",
    "                errorRecord = 'Internal Error'\n",
    "            elif lines[0].rstrip(\"\\r\\n\") == \"======== Error: Application returned non-zero code 1\":\n",
    "                #rint(fileName.split(\"/\")[-2],fileName.split(\"/\")[-1], \"non-zero\")\n",
    "                for i in range(0, n):\n",
    "                    data.append('non-zero')\n",
    "                errorRecord = 'non-zero'\n",
    "            else:\n",
    "                print(fileName.split(\"/\")[-2],fileName.split(\"/\")[-1], \"other\")\n",
    "                for i in range(0, n):\n",
    "                    data.append('other')\n",
    "                errorRecord = 'other'\n",
    "        elif nLine <= 5:\n",
    "           #print(fileName.split(\"/\")[-2],fileName.split(\"/\")[-1], \"error 2\")\n",
    "            #print(lines)\n",
    "       \n",
    "            errorType = 'Error 2'\n",
    "            for line in lines:\n",
    "                if \"Internal profiling error\" in line:\n",
    "                    errorType = \"Internal profiling error\"\n",
    "                    break\n",
    "                elif \"cannot be found\" in line:\n",
    "                    errorType = \"No metric\"\n",
    "                    break\n",
    "                elif \"No events/metrics were profiled\" in line:\n",
    "                    errorType = \"No metric\"\n",
    "                    break\n",
    "                else: \n",
    "                    pass\n",
    "                        \n",
    "            for i in range(0, n):\n",
    "                data.append(errorType)\n",
    "            errorRecord = errorType\n",
    "        else:\n",
    "            startX = 0\n",
    "            for line in lines:\n",
    "                if line.rstrip(\"\\r\\n\") == '\"Device\",\"Kernel\",\"Invocations\",\"Metric Name\",\"Metric Description\",\"Min\",\"Max\",\"Avg\"':\n",
    "                    break\n",
    "                startX += 1\n",
    "                \n",
    "            if startX == nLine:     \n",
    "                errorType = 'Error 3'\n",
    "                for line in lines:\n",
    "                    if \"No events/metrics were profiled\" in line:\n",
    "                        errorType = \"No metric\"\n",
    "                     \n",
    "                        break\n",
    "                for i in range(0, n):\n",
    "                    data.append(errorType)\n",
    "                errorRecord = errorType\n",
    "            else:\n",
    "                if nLine >= startX+1+n:\n",
    "                    for i in range(startX+1, startX+1+n):\n",
    "                        temp = list(reader([lines[i].rstrip(\"\\r\\n\")],delimiter=','))[0]\n",
    "                        if len(temp) != 8:\n",
    "                            if \"overflowed\" in lines[i]:\n",
    "                                data.append('overflowed')\n",
    "                                errorRecord =\"overflowed\"\n",
    "                            else:\n",
    "                                data.append('Error 4')\n",
    "                                errorRecord =\"Error 4\"\n",
    "                                \n",
    "                        else:\n",
    "                            data.append(list(reader([lines[i].rstrip(\"\\r\\n\")],delimiter=','))[0][7])\n",
    "                            errorRecord =\"No Error\"\n",
    "                else:\n",
    "                    for i in range(0, n):\n",
    "                        data.append(\"No enough kernels\")\n",
    "                    errorRecord =\"No enough kernels\"\n",
    "        f.close()\n",
    "    return data, errorRecord\n",
    "\n",
    "\n",
    "def process_Data(category,arch):\n",
    "    \n",
    "    pathfolder = \"/home/pzou/projects/Power_Signature/results/{}/{}/perf-combine\".format(category, arch)\n",
    "    app_list = get_app_list(\"/home/pzou/projects/Power_Signature/Scripts/applications_{}.csv\".format(category))\n",
    "    metrics = get_metrics_list(\"/home/pzou/projects/Power_Signature/Scripts/metrics.csv\")\n",
    "    outFile = \"perf-{}-{}.xlsx\".format( category,arch)\n",
    "    errorFile = \"perfError-{}-{}.csv\".format( category,arch)\n",
    "    print(\"start\")\n",
    "    perf_read(app_list, metrics, pathfolder,errorFile, outFile)\n",
    "    print(\"done\")\n",
    "    \n",
    "def transfer_Data(fileName, arch):\n",
    "    errorList = [\"Error 4\", \"Error 5\", \"Internal profiling error\", \"No metric\"]\n",
    "    nmList = []\n",
    "    if arch == \"p100\":\n",
    "        nmList = [\"tex_utilization\"]\n",
    "    if arch ==\"K40\":\n",
    "        nmList = [\"branch_efficiency\", \"global_hit_rate\", \"local_hit_rate\", \"l2_tex_write_hit_rate\", \"l2_tex_write_throughput\",\n",
    "         \"l2_tex_write_transactions\",\t\"flop_count_hp\",\t\"flop_count_hp_add\",\t\"flop_count_hp_mul\",\n",
    "         \t\"flop_count_hp_fma\",\t\"inst_fp_16\", \"shared_utilization\", \"special_fu_utilization\", \"half_precision_fu_utilization\", \n",
    "             \"single_precision_fu_utilization\", \"double_precision_fu_utilization\", \"flop_hp_efficiency\"] \n",
    "\n",
    "    data = pd.read_excel(fileName)\n",
    "    for col in nmList:\n",
    "        data = data.drop(columns=col)  #at least for p100\n",
    "    for col in data.columns:\n",
    "        data = data[~data[col].isin(errorList)]\n",
    "    for col in data.columns:\n",
    "        if col in [\"app\", \"kernel\"]:\n",
    "            continue\n",
    "        tempCol = []\n",
    "        for i in data[col]:\n",
    "            i = str(i)\n",
    "            x = float(rx.findall(i)[0])\n",
    "            if \"%\" in i:\n",
    "                pass  #do nothing\n",
    "            if \"MB\" in i:\n",
    "                pass  #do noting, the default is MB, MB/s\n",
    "            elif \"GB\" in i:\n",
    "                x = x * 1000.0\n",
    "            elif \"KB\" in i:\n",
    "                x = x / 1000.0\n",
    "            elif \"B\" in i:\n",
    "                x = x /1000000.0\n",
    "            else:\n",
    "                pass #do nothing\n",
    "            tempCol.append(x)\n",
    "        data[col] = tempCol\n",
    "\n",
    "    outFile = fileName.replace('.xlsx', 'fine.csv')\n",
    "    data.to_csv(outFile, index=False)\n",
    " \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print(\"start\")\n",
    "    #process_Data()\n",
    "    category=\"risky\"\n",
    "    arch=\"k40\"\n",
    "    process_Data(category,arch)\n",
    "    #fileName = 'perf-mybench-%s.xlsx'%arch\n",
    "    #transfer_Data(fileName, arch)\n",
    "    print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5.1.0)",
   "language": "python",
   "name": "anaconda3-5.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
