{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from decimal import Decimal\n",
    "import glob\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.svm \n",
    "import sklearn.metrics\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "\n",
    "def get_app_list(fileName):\n",
    "    \"\"\"get metrics list\n",
    "\n",
    "    Arguments:\n",
    "        fileName {string} -- the file name of application file with absolute path\n",
    "\n",
    "    Returns:\n",
    "        app {list} -- the app  list\n",
    "    \"\"\"\n",
    "    apps = []\n",
    "    with open(fileName) as f:\n",
    "        for line in f.readlines():\n",
    "            if not line.startswith('#'):\n",
    "                words = line.strip().split(',')\n",
    "                app = words[0].strip()\n",
    "                app_num = words[1].strip()\n",
    "                apps.append(app+app_num)\n",
    "        f.close()\n",
    "    return apps\n",
    "\n",
    "def load_file(filepath):\n",
    "    max_len = 1800\n",
    "    dataframe = pd.read_csv(filepath, index_col=0)\n",
    "    if (dataframe.shape[1] == 4 and dataframe.shape[0] > 1800):\n",
    "        if dataframe[\"u_gpu\"].sum() == 0:\n",
    "            #os.remove(filepath)\n",
    "            print(filepath)\n",
    "        else:\n",
    "            return dataframe.values[:max_len,:]\n",
    "    else:\n",
    "        print(filepath)\n",
    "        \n",
    "def load_group():\n",
    "    arch = \"p100\"\n",
    "    \n",
    "    y_label = []\n",
    "    data_group = []\n",
    "    category = \"mybench\"\n",
    "    pathfolder = '/home/pzou/projects/Power_Signature/results/%s/%s/power-combine'%(category, arch)\n",
    "    app_list = app_list = get_app_list(\"/home/pzou/projects/Power_Signature/Scripts/applications_%s.csv\"%(category))\n",
    "    for app in app_list:\n",
    "        fileName =app+\".pwr.csv\"\n",
    "        data = load_file(os.path.join(pathfolder, fileName))\n",
    "        data_group.append(data)\n",
    "        y_label.append(0)\n",
    "    print(\"normal count\", len(data_group))\n",
    "    \n",
    "    normal_count =len(data_group)\n",
    "    category = \"risky\"\n",
    "    pathfolder = '/home/pzou/projects/Power_Signature/results/%s/%s/power-combine'%(category, arch)\n",
    "    app_list = app_list = get_app_list(\"/home/pzou/projects/Power_Signature/Scripts/applications_%s.csv\"%(category))\n",
    "    for app in app_list:\n",
    "        fileName =app+\".pwr.csv\"\n",
    "        data = load_file(os.path.join(pathfolder, fileName))\n",
    "        data_group.append(data)\n",
    "       \n",
    "        y_label.append(1)\n",
    "        \n",
    "    print(\"risk count\", len(data_group)-normal_count)\n",
    "    data_group = np.asarray(data_group)    \n",
    "    return data_group, y_label\n",
    "\n",
    "\n",
    "print(\"start loading\")\n",
    "data_group, y_label = load_group()\n",
    "print(\"Done loading\")\n",
    "#%%\n",
    "\n",
    "checkpoint_path = \"%s/resourceAll-%s.hdf5\"%(arch,arch)\n",
    "model = tf.keras.models.load_model (checkpoint_path)\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5.1.0)",
   "language": "python",
   "name": "anaconda3-5.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
